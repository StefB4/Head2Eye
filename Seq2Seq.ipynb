{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, BatchNormalization, \\\n",
    "    multiply, concatenate, Flatten, Activation, dot\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pydot as pyd\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "keras.utils.vis_utils.pydot = pyd\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from scipy import signal \n",
    "\n",
    "import glob\n",
    "\n",
    "from DataManager import ParticipantData, MeasurementData\n",
    "from Helpers import read_normalized_json_to_df, save_to_disk, load_from_disk, create_rolling_windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "configured-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_some_failed_save_path = \"./post_recorded_reference_data/reference_some_events_failed.pickle\"\n",
    "reference_data_all_failed_save_path = \"./post_recorded_reference_data/reference_all_events_failed.pickle\"\n",
    "\n",
    "REFERENCE_DATA_SOME_EVENTS_FAILED = load_from_disk(reference_data_some_failed_save_path)\n",
    "REFERENCE_DATA_ALL_EVENTS_FAILED = load_from_disk(reference_data_all_failed_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "measured-result",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CarPosition.x', 'CarPosition.y', 'CarPosition.z', 'LocalCarPosition.x',\n",
      "       'LocalCarPosition.y', 'LocalCarPosition.z', 'CarRotation.x',\n",
      "       'CarRotation.y', 'CarRotation.z', 'CarRotationQuaternion.x',\n",
      "       'CarRotationQuaternion.y', 'CarRotationQuaternion.z',\n",
      "       'CarRotationQuaternion.w', 'resampled_timestamp', 'is_interpolated'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(REFERENCE_DATA_ALL_EVENTS_FAILED[\"Westbrueck\"][0].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-inspection",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "charged-ground",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeasurementData: Found files for participant 0d0d7bd79b1a48d4ad5e757cdbfc15c9.\n",
      "Input data files: ['./data/Input/0d0d7bd79b1a48d4ad5e757cdbfc15c9_Input_TrainingScene.txt', './data/Input/0d0d7bd79b1a48d4ad5e757cdbfc15c9_Input_Westbrueck.txt', './data/Input/0d0d7bd79b1a48d4ad5e757cdbfc15c9_Input_CountryRoad.txt', './data/Input/0d0d7bd79b1a48d4ad5e757cdbfc15c9_Input_Autobahn.txt', './data/Input/0d0d7bd79b1a48d4ad5e757cdbfc15c9_Input_MountainRoad.txt']\n",
      "Eyetracking data files: ['./data/EyeTracking/0d0d7bd79b1a48d4ad5e757cdbfc15c9_EyeTracking_Westbrueck.txt', './data/EyeTracking/0d0d7bd79b1a48d4ad5e757cdbfc15c9_EyeTracking_Autobahn.txt', './data/EyeTracking/0d0d7bd79b1a48d4ad5e757cdbfc15c9_EyeTracking_MountainRoad.txt', './data/EyeTracking/0d0d7bd79b1a48d4ad5e757cdbfc15c9_EyeTracking_TrainingScene.txt', './data/EyeTracking/0d0d7bd79b1a48d4ad5e757cdbfc15c9_EyeTracking_CountryRoad.txt']\n",
      "Calibration data files: ['./data/ParticipantCalibrationData/0d0d7bd79b1a48d4ad5e757cdbfc15c9_ParticipantCalibrationData.txt']\n",
      "Scene data files: ['./data/SceneData/0d0d7bd79b1a48d4ad5e757cdbfc15c9_SceneData_CountryRoad.txt', './data/SceneData/0d0d7bd79b1a48d4ad5e757cdbfc15c9_SceneData_Westbrueck.txt', './data/SceneData/0d0d7bd79b1a48d4ad5e757cdbfc15c9_SceneData_MountainRoad.txt', './data/SceneData/0d0d7bd79b1a48d4ad5e757cdbfc15c9_SceneData_Autobahn.txt', './data/SceneData/0d0d7bd79b1a48d4ad5e757cdbfc15c9_SceneData_TrainingScene.txt']\n",
      "\n",
      "MeasurementData: Found files for participant 0bc17d704fec4a9eb892d905fc2e5da9.\n",
      "Input data files: ['./data/Input/0bc17d704fec4a9eb892d905fc2e5da9_Input_Autobahn.txt', './data/Input/0bc17d704fec4a9eb892d905fc2e5da9_Input_Westbrueck.txt', './data/Input/0bc17d704fec4a9eb892d905fc2e5da9_Input_TrainingScene.txt', './data/Input/0bc17d704fec4a9eb892d905fc2e5da9_Input_MountainRoad.txt', './data/Input/0bc17d704fec4a9eb892d905fc2e5da9_Input_CountryRoad.txt']\n",
      "Eyetracking data files: ['./data/EyeTracking/0bc17d704fec4a9eb892d905fc2e5da9_EyeTracking_MountainRoad.txt', './data/EyeTracking/0bc17d704fec4a9eb892d905fc2e5da9_EyeTracking_Westbrueck.txt', './data/EyeTracking/0bc17d704fec4a9eb892d905fc2e5da9_EyeTracking_TrainingScene.txt', './data/EyeTracking/0bc17d704fec4a9eb892d905fc2e5da9_EyeTracking_Autobahn.txt', './data/EyeTracking/0bc17d704fec4a9eb892d905fc2e5da9_EyeTracking_CountryRoad.txt']\n",
      "Calibration data files: ['./data/ParticipantCalibrationData/0bc17d704fec4a9eb892d905fc2e5da9_ParticipantCalibrationData.txt']\n",
      "Scene data files: ['./data/SceneData/0bc17d704fec4a9eb892d905fc2e5da9_SceneData_MountainRoad.txt', './data/SceneData/0bc17d704fec4a9eb892d905fc2e5da9_SceneData_CountryRoad.txt', './data/SceneData/0bc17d704fec4a9eb892d905fc2e5da9_SceneData_Westbrueck.txt', './data/SceneData/0bc17d704fec4a9eb892d905fc2e5da9_SceneData_TrainingScene.txt', './data/SceneData/0bc17d704fec4a9eb892d905fc2e5da9_SceneData_Autobahn.txt']\n",
      "\n",
      "ParticipantData: Initialising participant 0d0d7bd79b1a48d4ad5e757cdbfc15c9.\n",
      "ParticipantData: Loaded data (bootstrapped) for participant 0d0d7bd79b1a48d4ad5e757cdbfc15c9.\n",
      "ParticipantData: Initialising participant 0bc17d704fec4a9eb892d905fc2e5da9.\n",
      "ParticipantData: Loaded data (bootstrapped) for participant 0bc17d704fec4a9eb892d905fc2e5da9.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "participant_id = os.path.basename(glob.glob(\"./data/EyeTracking/*.txt\")[0]).split(\"_\")[0]\n",
    "eyes = glob.glob(\"./data/EyeTracking/\" + str(participant_id) + \"*.txt\")\n",
    "inputs = glob.glob(\"./data/Input/\" + str(participant_id) + \"*.txt\")\n",
    "calib = glob.glob(\"./data/ParticipantCalibrationData/\" + str(participant_id) + \"*.txt\")[0]\n",
    "scenes = glob.glob(\"./data/SceneData/\" + str(participant_id) + \"*.txt\")\n",
    "\n",
    "eyes_paths  = [\"./data/EyeTracking/\"]\n",
    "input_paths = [\"./data/Input/\"]\n",
    "calib_paths = [\"./data/ParticipantCalibrationData/\"]\n",
    "scene_paths = [\"./data/SceneData/\"]\n",
    "\n",
    "'''\n",
    "print(eyes)\n",
    "print(inputs)\n",
    "print(calib)\n",
    "print(scenes)\n",
    "'''\n",
    "\n",
    "#participant1 = ParticipantData(eyes, inputs, calib, scenes, True, True)\n",
    "\n",
    "measurement1 = MeasurementData(eyes_paths,input_paths,calib_paths,scene_paths,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pleased-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeasurementData: Applying reference data to all participants...\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 0. Number of datapoints used: 2457.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 1. Number of datapoints used: 2484.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 2. Number of datapoints used: 2935.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 3. Number of datapoints used: 2204.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 0. Number of datapoints used: 1990.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 1. Number of datapoints used: 3148.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 2. Number of datapoints used: 6041.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 3. Number of datapoints used: 1219.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 0. Number of datapoints used: 2165.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 1. Number of datapoints used: 3562.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 2. Number of datapoints used: 2984.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 3. Number of datapoints used: 4303.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 0. Number of datapoints used: 2806.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 1. Number of datapoints used: 1901.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 2. Number of datapoints used: 5214.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 3. Number of datapoints used: 237.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 0. Number of datapoints used: 2453.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 1. Number of datapoints used: 2484.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 2. Number of datapoints used: 2932.\n",
      "ParticipantData: Applying reference data to back of Westbrueck's segment 3. Number of datapoints used: 2259.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 0. Number of datapoints used: 1717.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 1. Number of datapoints used: 3696.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 2. Number of datapoints used: 5368.\n",
      "ParticipantData: Applying reference data to back of MountainRoad's segment 3. Number of datapoints used: 1219.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 0. Number of datapoints used: 2165.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 1. Number of datapoints used: 3569.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 2. Number of datapoints used: 3707.\n",
      "ParticipantData: Applying reference data to back of CountryRoad's segment 3. Number of datapoints used: 4398.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 0. Number of datapoints used: 2806.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 1. Number of datapoints used: 2003.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 2. Number of datapoints used: 5225.\n",
      "ParticipantData: Applying reference data to back of Autobahn's segment 3. Number of datapoints used: 468.\n"
     ]
    }
   ],
   "source": [
    "#print(participant1.get_event_info())\n",
    "#participant1.apply_reference_data(REFERENCE_DATA_ALL_EVENTS_FAILED)\n",
    "#print(participant1.get_segment_data(filter_data=True, get_first_segment=True, exclude_segments=[1,2], after_event_type_only=[True,False],exclude_areas=[\"Westbrueck\",\"Autobahn\"]))\n",
    "\n",
    "measurement1.apply_reference_data(REFERENCE_DATA_ALL_EVENTS_FAILED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "willing-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(participant1.get_segment_data(filter_data=True, get_first_segment=True, exclude_segments=[1,2], after_event_type_only=[True,False],exclude_areas=[\"Westbrueck\",\"Autobahn\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-hunter",
   "metadata": {},
   "source": [
    "# Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "julian-singing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HmdPosition.x', 'HmdPosition.y', 'HmdPosition.z', 'NoseVector.x',\n",
      "       'NoseVector.y', 'NoseVector.z', 'EyePosWorldCombined.x',\n",
      "       'EyePosWorldCombined.y', 'EyePosWorldCombined.z',\n",
      "       'EyeDirWorldCombined.x', 'EyeDirWorldCombined.y',\n",
      "       'EyeDirWorldCombined.z', 'resampled_timestamp', 'is_interpolated'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Wanted filtering, very much data\n",
    "'''\n",
    "filtered_data = measurement1.get_data(use_vanilla = False, filter_data=True, get_first_segment = False, after_event_type_only=[False], exclude_segments=[], exclude_areas = [], exclude_participants=[])\n",
    "res = measurement1.truncate_data(filtered_data,200)\n",
    "print(np.shape(res))\n",
    "# save_to_disk(res,\"./truncated_data.pickle\")\n",
    "'''\n",
    "\n",
    "\n",
    "# some test filtering\n",
    "#filtered_data = measurement1.get_data(use_vanilla = False, filter_data=True, get_first_segment = False, after_event_type_only=[False], exclude_segments=[3], exclude_areas = [\"CountryRoad\",\"Autobahn\",\"MountainRoad\"], exclude_participants=[\"0bc17d704fec4a9eb892d905fc2e5da9\"])\n",
    "#filtered_data = measurement1.get_data(use_vanilla = False, filter_data=True, get_first_segment = True, after_event_type_only=[True,False], exclude_segments=[], exclude_areas = [], exclude_participants=[])\n",
    "filtered_data = measurement1.get_data(use_vanilla = False, filter_data=True, get_first_segment = False, after_event_type_only=[False], exclude_segments=[3], exclude_areas = [\"CountryRoad\",\"Autobahn\"], exclude_participants=[\"0bc17d704fec4a9eb892d905fc2e5da9\"])\n",
    "\n",
    "\n",
    "\n",
    "#print(filtered_data)\n",
    "print(filtered_data['0d0d7bd79b1a48d4ad5e757cdbfc15c9'][\"Westbrueck\"][2].columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afraid-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average data over multiple sessions per segment\n",
    "average = measurement1.average_data(filtered_data)\n",
    "\n",
    "# combine ALL data into one dataframe \n",
    "#combined = measurement1.combine_data(filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-moore",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exciting-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the net should do \n",
    "# Input: HmdPosition & NoseVector\n",
    "# Output: EyePosWorld & EyeDirWorldCombined\n",
    "\n",
    "# Get truncated data \n",
    "truncated = measurement1.truncate_data(filtered_data, 200, method = \"numpy\")\n",
    "\n",
    "# Available data:\n",
    "# HmdPosition.x  HmdPosition.y  HmdPosition.z  NoseVector.x  NoseVector.y NoseVector.z  EyePosWorldCombined.x  EyePosWorldCombined.y EyePosWorldCombined.z  EyeDirWorldCombined.x  EyeDirWorldCombined.y  EyeDirWorldCombined.z  resampled_timestamp  is_interpolated  \n",
    "\n",
    "# Drop last two columns of unneeded data \n",
    "truncated = np.delete(truncated,[12,13],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sufficient-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datapoints: 8578 For training: 6862 For testing: 1716\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find max(abs(value))\n",
    "scaling_factor = np.ceil(np.max(np.abs(truncated)))\n",
    "\n",
    "# Train and test split \n",
    "train_test_ratio = 0.8\n",
    "split_idx = int(len(truncated) * train_test_ratio)\n",
    "train_set = truncated[:split_idx]\n",
    "test_set = truncated[split_idx:]\n",
    "print(\"Total datapoints: \" + str(len(truncated)) + \" For training: \" + str(train_set.shape[0]) + \" For testing: \" + str(test_set.shape[0]))\n",
    "\n",
    "plt.plot(range(len(train_set[3950])), train_set[3950], label=[\"HmdPosition.x\",  \"HmdPosition.y\",  \"HmdPosition.z\",  \"NoseVector.x\",  \"NoseVector.y\", \"NoseVector.z\",  \"EyePosWorldCombined.x\",  \"EyePosWorldCombined.y\", \"EyePosWorldCombined.z\",  \"EyeDirWorldCombined.x\",  \"EyeDirWorldCombined.y\",  \"EyeDirWorldCombined.z\"])\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Input and output split, apply scaling factor\n",
    "train_set_source = train_set[:,:,:6] / scaling_factor\n",
    "train_set_target = train_set[:,:,6:] / scaling_factor\n",
    "test_set_source = test_set[:,:,:6] / scaling_factor\n",
    "test_set_target = test_set[:,:,6:] / scaling_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DNN\n",
    "\n",
    "n_hidden = 100\n",
    "\n",
    "input_train = Input(shape=(train_set_source.shape[1], train_set_source.shape[2]))\n",
    "output_train = Input(shape=(train_set_target.shape[1], train_set_target.shape[2]))\n",
    "print(input_train)\n",
    "print(output_train)\n",
    "\n",
    "\n",
    "encoder_last_h1, encoder_last_h2, encoder_last_c = LSTM(\n",
    " n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, \n",
    " return_sequences=False, return_state=True)(input_train)\n",
    "print(encoder_last_h1)\n",
    "print(encoder_last_h2)\n",
    "print(encoder_last_c)\n",
    "\n",
    "#encoder_last_h1 = BatchNormalization(momentum=0.6)(encoder_last_h1)\n",
    "#encoder_last_c = BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "\n",
    "decoder = RepeatVector(output_train.shape[1])(encoder_last_h1)\n",
    "decoder = LSTM(n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, return_state=False, return_sequences=True)(\n",
    "    decoder, initial_state=[encoder_last_h1, encoder_last_c])\n",
    "print(decoder)\n",
    "\n",
    "\n",
    "out = TimeDistributed(Dense(output_train.shape[2]))(decoder)\n",
    "print(out)\n",
    "\n",
    "model = Model(inputs=input_train, outputs=out)\n",
    "opt = Adam(lr=0.01, clipnorm=1)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None\n",
    "epc = 20\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "history = model.fit(train_set_source, train_set_target, validation_split=0.2, \n",
    "                    epochs=epc, verbose=1, callbacks=[es], \n",
    "                    batch_size=100)\n",
    "train_mae = history.history['mae']\n",
    "valid_mae = history.history['val_mae']\n",
    " \n",
    "model.save('model_forecasting_seq2seq.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_mae, label='train mae'), \n",
    "plt.plot(valid_mae, label='validation mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('train vs. validation accuracy (mae)')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_pred = model.predict(test_set_source)\n",
    "#test_true = test_set_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_pred[:,:,2], label=\"pred\")\n",
    "plt.plot(test_true[:,:,2], label=\"true\")\n",
    "plt.legend(loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-agenda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-windows",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-sheriff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data \n",
    "# format, full array with columns holding the data: \n",
    "# IN: HmdPosition.x, HmdPosition.y, HmdPosition.z, NoseVector.x, NoseVector.y, NoseVector.z\n",
    "# OUT: EyeDirWorldCombined.x, EyeDirWorldCombined.y, EyeDirWorldCombined.z\n",
    "\n",
    "\n",
    "#### HMDPosition is affected by moving car!\n",
    "# \"HmdPosition.x\",\"HmdPosition.y\",\"HmdPosition.z\"\n",
    "# Possibly detrend? Over all subjects? \n",
    "\n",
    "\n",
    "train_and_test_in = reduced_df[[\"NoseVector.x\",\"NoseVector.y\",\"NoseVector.z\"]].to_numpy()\n",
    "train_and_test_target = reduced_df[[\"EyeDirWorldCombined.x\",\"EyeDirWorldCombined.y\",\"EyeDirWorldCombined.z\"]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_and_test_in)), train_and_test_in, label=[\"NoseVector.x\",\"NoseVector.y\",\"NoseVector.z\"])\n",
    "plt.plot(range(len(train_and_test_target)), train_and_test_target, label=[\"EyeDirWorldCombined.x\",\"EyeDirWorldCombined.y\",\"EyeDirWorldCombined.z\"])\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things todo \n",
    "# Possibly detrend\n",
    "# Normalize (between -1 and 1), already the case. \n",
    "\n",
    "train_test_ratio = 0.8\n",
    "split_idx_in = int(len(train_and_test_in) * train_test_ratio)\n",
    "split_idx_target = int(len(train_and_test_target) * train_test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset \n",
    "\n",
    "train_in = train_and_test_in[0:split_idx_in]\n",
    "test_in = train_and_test_in[split_idx_in:]\n",
    "train_target = train_and_test_target[0:split_idx_target]\n",
    "test_target = train_and_test_target[split_idx_target:]\n",
    "\n",
    "print(train_and_test_in.shape)\n",
    "print(train_in.shape, test_in.shape)\n",
    "print(train_and_test_target.shape)\n",
    "print(train_target.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate dataset \n",
    "\n",
    "def truncate(data, window_size):\n",
    "    result = []\n",
    "    i = 0\n",
    "    while (i + window_size) <= len(data):\n",
    "        result.append(data[i:i+window_size])\n",
    "        i += 1\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "truncated_train_in = truncate(train_in,200) # use 200 data points for training input\n",
    "truncated_train_target = truncate(train_target,200) # use same number (200) for training output, i.e. generated\n",
    "truncated_test_in = truncate(test_in,200)\n",
    "truncated_test_target = truncate(test_target,200)\n",
    "\n",
    "print(truncated_train_in.shape)\n",
    "print(truncated_train_target.shape)\n",
    "print(truncated_test_in.shape)\n",
    "print(truncated_test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DNN\n",
    "\n",
    "n_hidden = 100\n",
    "\n",
    "input_train = Input(shape=(truncated_train_in.shape[1], truncated_train_in.shape[2]))\n",
    "output_train = Input(shape=(truncated_train_target.shape[1], truncated_train_target.shape[2]))\n",
    "print(input_train)\n",
    "print(output_train)\n",
    "\n",
    "\n",
    "encoder_last_h1, encoder_last_h2, encoder_last_c = LSTM(\n",
    " n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, \n",
    " return_sequences=False, return_state=True)(input_train)\n",
    "print(encoder_last_h1)\n",
    "print(encoder_last_h2)\n",
    "print(encoder_last_c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_last_h1 = BatchNormalization(momentum=0.6)(encoder_last_h1)\n",
    "#encoder_last_c = BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "\n",
    "decoder = RepeatVector(output_train.shape[1])(encoder_last_h1)\n",
    "decoder = LSTM(n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, return_state=False, return_sequences=True)(\n",
    "    decoder, initial_state=[encoder_last_h1, encoder_last_c])\n",
    "print(decoder)\n",
    "\n",
    "\n",
    "out = TimeDistributed(Dense(output_train.shape[2]))(decoder)\n",
    "print(out)\n",
    "\n",
    "model = Model(inputs=input_train, outputs=out)\n",
    "opt = Adam(lr=0.01, clipnorm=1)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None\n",
    "epc = 2\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "history = model.fit(truncated_train_in, truncated_train_target, validation_split=0.2, \n",
    "                    epochs=epc, verbose=1, callbacks=[es], \n",
    "                    batch_size=100)\n",
    "train_mae = history.history['mae']\n",
    "valid_mae = history.history['val_mae']\n",
    " \n",
    "model.save('model_forecasting_seq2seq.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_mae, label='train mae'), \n",
    "plt.plot(valid_mae, label='validation mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('train vs. validation accuracy (mae)')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly detrend etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(truncated_train_in)\n",
    "test_pred = model.predict(truncated_test_in)\n",
    "print(train_pred.shape, test_pred.shape)\n",
    "train_true = truncated_train_target\n",
    "test_true = truncated_test_target\n",
    "print(train_true.shape, test_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = train_pred[~np.isnan(train_pred)]\n",
    "train_true = train_true[~np.isnan(train_true)]\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.hist(train_pred.flatten(), bins=100, color='orange', alpha=0.5, label='trainpred')\n",
    "plt.hist(train_true.flatten(), bins=100, color='green', alpha=0.5, label='traintrue')\n",
    "plt.legend()\n",
    "plt.title('value distribution: train')\n",
    "plt.show()\n",
    "\n",
    "print(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-blast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-client",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-development",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ = 1000\n",
    "t = np.linspace(0, 50*np.pi, n_)\n",
    "# pattern + trend + noise\n",
    "x1 = sum([20*np.sin(i*t+np.pi) for i in range(5)]) + 0.01*(t**2) + np.random.normal(0, 6, n_)\n",
    "x2 = sum([15*np.sin(2*i*t+np.pi) for i in range(5)]) + 0.5*t + np.random.normal(0, 6, n_)\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(range(len(x1)), x1, label='x1')\n",
    "plt.plot(range(len(x2)), x2, label='x2')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_len = int(train_ratio * t.shape[0])\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trend\n",
    "\n",
    "x_index = np.array(range(len(t)))\n",
    "\n",
    "x1_trend_param = np.polyfit(x_index[:train_len], x1[:train_len], 2)\n",
    "x2_trend_param = np.polyfit(x_index[:train_len], x2[:train_len], 1)\n",
    "print(x1_trend_param)\n",
    "print(x2_trend_param)\n",
    "\n",
    "\n",
    "x1_trend = (x_index**2)*x1_trend_param[0]+x_index*x1_trend_param[1]+x1_trend_param[2]\n",
    "x2_trend = x_index*x2_trend_param[0]+x2_trend_param[1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(range(len(x1)), x1, label='x1')\n",
    "plt.plot(range(len(x1_trend)), x1_trend, linestyle='--', label='x1_trend')\n",
    "plt.plot(range(len(x2)), x2, label='x2')\n",
    "plt.plot(range(len(x2_trend)), x2_trend, linestyle='--', label='x2_trend')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend\n",
    "\n",
    "x1_detrend = x1 - x1_trend\n",
    "x2_detrend = x2 - x2_trend\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(range(len(x1_detrend)), x1_detrend, label='x2_detrend')\n",
    "plt.plot(range(len(x2_detrend)), x2_detrend, label='x2_detrend')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sequences\n",
    "\n",
    "x_lbl = np.column_stack([x1_detrend, x2_detrend, x_index, [1]*train_len+[0]*(len(x_index)-train_len)])\n",
    "print(x_lbl.shape)\n",
    "print(x_lbl)\n",
    "\n",
    "# Calculate maxs \n",
    "x_train_max = x_lbl[x_lbl[:, 3]==1, :2].max(axis=0)\n",
    "x_train_max = x_train_max.tolist()+[1]*2  # only normalize for the first 2 columns\n",
    "print(x_train_max)\n",
    "\n",
    "# Normalize \n",
    "x_normalize = np.divide(x_lbl, x_train_max)\n",
    "print(x_normalize)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(range(train_len), x_normalize[:train_len, 0], label='x1_train_normalized')\n",
    "plt.plot(range(train_len), x_normalize[:train_len, 1], label='x2_train_normalized')\n",
    "plt.plot(range(train_len, len(x_normalize)), x_normalize[train_len:, 0], label='x1_test_normalized')\n",
    "plt.plot(range(train_len, len(x_normalize)), x_normalize[train_len:, 1], label='x2_test_normalized')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def truncate(x, feature_cols=range(3), target_cols=range(3), label_col=3, train_len=100, test_len=20):\n",
    "    in_, out_, lbl = [], [], []\n",
    "    for i in range(len(x)-train_len-test_len+1):\n",
    "        in_.append(x[i:(i+train_len), feature_cols].tolist())\n",
    "        out_.append(x[(i+train_len):(i+train_len+test_len), target_cols].tolist())\n",
    "        lbl.append(x[i+train_len, label_col])\n",
    "    return np.array(in_), np.array(out_), np.array(lbl)\n",
    "X_in, X_out, lbl = truncate(x_normalize, feature_cols=range(3), target_cols=range(3), \n",
    "                            label_col=3, train_len=200, test_len=20)\n",
    "print(X_in.shape, X_out.shape, lbl.shape)\n",
    "\n",
    "\n",
    "X_input_train = X_in[np.where(lbl==1)]\n",
    "X_output_train = X_out[np.where(lbl==1)]\n",
    "X_input_test = X_in[np.where(lbl==0)]\n",
    "X_output_test = X_out[np.where(lbl==0)]\n",
    "print(X_input_train.shape, X_output_train.shape)\n",
    "print(X_input_test.shape, X_output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 100\n",
    "\n",
    "input_train = Input(shape=(X_input_train.shape[1], X_input_train.shape[2]-1))\n",
    "output_train = Input(shape=(X_output_train.shape[1], X_output_train.shape[2]-1))\n",
    "print(input_train)\n",
    "print(output_train)\n",
    "\n",
    "\n",
    "encoder_last_h1, encoder_last_h2, encoder_last_c = LSTM(\n",
    " n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, \n",
    " return_sequences=False, return_state=True)(input_train)\n",
    "print(encoder_last_h1)\n",
    "print(encoder_last_h2)\n",
    "print(encoder_last_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_last_h1 = BatchNormalization(momentum=0.6)(encoder_last_h1)\n",
    "encoder_last_c = BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "\n",
    "decoder = RepeatVector(output_train.shape[1])(encoder_last_h1)\n",
    "decoder = LSTM(n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, return_state=False, return_sequences=True)(\n",
    "    decoder, initial_state=[encoder_last_h1, encoder_last_c])\n",
    "print(decoder)\n",
    "\n",
    "\n",
    "out = TimeDistributed(Dense(output_train.shape[2]))(decoder)\n",
    "print(out)\n",
    "\n",
    "model = Model(inputs=input_train, outputs=out)\n",
    "opt = Adam(lr=0.01, clipnorm=1)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "epc = 100\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "history = model.fit(X_input_train[:, :, :2], X_output_train[:, :, :2], validation_split=0.2, \n",
    "                    epochs=epc, verbose=1, callbacks=[es], \n",
    "                    batch_size=100)\n",
    "train_mae = history.history['mae']\n",
    "valid_mae = history.history['val_mae']\n",
    " \n",
    "model.save('model_forecasting_seq2seq.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train_mae, label='train mae'), \n",
    "plt.plot(valid_mae, label='validation mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('train vs. validation accuracy (mae)')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_detrend = model.predict(X_input_train[:, :, :2])*x_train_max[:2]\n",
    "test_pred_detrend = model.predict(X_input_test[:, :, :2])*x_train_max[:2]\n",
    "print(train_pred_detrend.shape, test_pred_detrend.shape)\n",
    "train_true_detrend = X_output_train[:, :, :2]*x_train_max[:2]\n",
    "test_true_detrend = X_output_test[:, :, :2]*x_train_max[:2]\n",
    "print(train_true_detrend.shape, test_true_detrend.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_detrend = np.concatenate([train_pred_detrend, np.expand_dims(X_output_train[:, :, 2], axis=2)], axis=2)\n",
    "test_pred_detrend = np.concatenate([test_pred_detrend, np.expand_dims(X_output_test[:, :, 2], axis=2)], axis=2)\n",
    "print(train_pred_detrend.shape, test_pred_detrend.shape)\n",
    "train_true_detrend = np.concatenate([train_true_detrend, np.expand_dims(X_output_train[:, :, 2], axis=2)], axis=2)\n",
    "test_true_detrend = np.concatenate([test_true_detrend, np.expand_dims(X_output_test[:, :, 2], axis=2)], axis=2)\n",
    "print(train_pred_detrend.shape, test_pred_detrend.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_final = dict()\n",
    "for dt, lb in zip([train_pred_detrend, train_true_detrend, test_pred_detrend, test_true_detrend], \n",
    "                  ['train_pred', 'train_true', 'test_pred', 'test_true']):\n",
    "    dt_x1 = dt[:, :, 0] + (dt[:, :, 2]**2)*x1_trend_param[0] + dt[:, :, 2]*x1_trend_param[1] + x1_trend_param[2]\n",
    "    dt_x2 = dt[:, :, 1] + dt[:, :, 2]*x2_trend_param[0] + x2_trend_param[1]\n",
    "    data_final[lb] = np.concatenate(\n",
    "        [np.expand_dims(dt_x1, axis=2), np.expand_dims(dt_x2, axis=2)], axis=2)\n",
    "    print(lb+': {}'.format(data_final[lb].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for lb in ['train', 'test']:\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.hist(data_final[lb+'_pred'].flatten(), bins=100, color='orange', alpha=0.5, label=lb+' pred')\n",
    "    plt.hist(data_final[lb+'_true'].flatten(), bins=100, color='green', alpha=0.5, label=lb+' true')\n",
    "    plt.legend()\n",
    "    plt.title('value distribution: '+lb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for lb in ['train', 'test']:\n",
    "    MAE_overall = abs(data_final[lb+'_pred'] - data_final[lb+'_true']).mean()\n",
    "    MAE_ = abs(data_final[lb+'_pred'] - data_final[lb+'_true']).mean(axis=(1, 2))\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(MAE_)\n",
    "    plt.title('MAE '+lb+': overall MAE = '+str(MAE_overall))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "ith_timestep = random.choice(range(data_final[lb+'_pred'].shape[1]))\n",
    "plt.figure(figsize=(15, 5))\n",
    "train_start_t = 0\n",
    "test_start_t = data_final['train_pred'].shape[0]\n",
    "for lb, tm, clrs in zip(['train', 'test'], [train_start_t, test_start_t], [['green', 'red'], ['blue', 'orange']]):\n",
    "    for i, x_lbl in zip([0, 1], ['x1', 'x2']):\n",
    "        plt.plot(range(tm, tm+data_final[lb+'_pred'].shape[0]), \n",
    "                 data_final[lb+'_pred'][:, ith_timestep, i], \n",
    "                 linestyle='--', linewidth=1, color=clrs[0], label='pred '+x_lbl)\n",
    "        plt.plot(range(tm, tm+data_final[lb+'_pred'].shape[0]), \n",
    "                 data_final[lb+'_true'][:, ith_timestep, i], \n",
    "                 linestyle='-', linewidth=1, color=clrs[1], label='true '+x_lbl)\n",
    "    \n",
    "plt.title('{}th time step in all samples'.format(ith_timestep))\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb = 'test'\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, x_lbl, clr in zip([0, 1], ['x1', 'x2'], ['green', 'blue']):\n",
    "    plt.plot(data_final[lb+'_pred'][:, ith_timestep, i], linestyle='--', color=clr, label='pred '+x_lbl)\n",
    "    plt.plot(data_final[lb+'_true'][:, ith_timestep, i], linestyle='-', color=clr, label='true '+x_lbl)\n",
    "plt.title('({}): {}th time step in all samples'.format(lb, ith_timestep))\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-father",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-condition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-contractor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-fiction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class ParticipantData:\n",
    "    '''\n",
    "    Class for data of an individual participant.\n",
    "    (Data includes eyetracking, input, participantcalibrationdata and scenedata)\n",
    "    '''\n",
    "   \n",
    "    def __init__(self, eyetracking_filepaths, input_filepaths, calibration_filepath, scenedata_filepaths, bootstrap_file_loading=False, verbose = False):\n",
    "        '''\n",
    "        Constructor.\n",
    "        @ Paths to the relevant files \n",
    "        '''\n",
    "        \n",
    "        # sanity checks \n",
    "        # after this, we can be sure, that all paths exist, the files have labels corresponding to what they should contain\n",
    "        # the participant id is always the same, the number of files per list corresponds and there is one calibration path \n",
    "        # the lists are lists of strings and the calibration data is a string \n",
    "        if (eyetracking_filepaths is None or input_filepaths is None or calibration_filepath is None or scenedata_filepaths is None):\n",
    "            raise AssertionError(\"Some of the supplied paths are None! Exiting.\")\n",
    "        if (not isinstance(eyetracking_filepaths, list) or not isinstance(input_filepaths, list) or not isinstance(calibration_filepath, str) or not isinstance(scenedata_filepaths, list)):\n",
    "            raise AssertionError(\"Some of the paths are not supplied in the correct format! Exiting.\")\n",
    "        if (len(eyetracking_filepaths) != len(input_filepaths) or len(eyetracking_filepaths) != len(scenedata_filepaths)):\n",
    "            raise AssertionError(\"The number of supplied paths per category does not match! Exiting.\")\n",
    "        if (len(eyetracking_filepaths) < 1):\n",
    "            raise AssertionError(\"Some supplied path lists have less than one element! Exiting.\")\n",
    "        if (not all(isinstance(elem,str) for elem in eyetracking_filepaths) or not all(isinstance(elem,str) for elem in input_filepaths) or not all(isinstance(elem,str) for elem in scenedata_filepaths)):\n",
    "            raise AssertionError(\"The supplied path lists do not contain string contents! Exiting.\")\n",
    "        participant_id = \"-8\"\n",
    "        for elem in eyetracking_filepaths + input_filepaths + [calibration_filepath] + scenedata_filepaths:\n",
    "            if not os.path.isfile(elem):\n",
    "                raise AssertionError(\"Some of the supplied paths do not link to existing files! Exiting.\")\n",
    "            try:\n",
    "                if (participant_id == \"-8\"):\n",
    "                    participant_id = os.path.basename(elem).split(\"_\")[0]\n",
    "                else:\n",
    "                    next_participant_id = os.path.basename(elem).split(\"_\")[0]\n",
    "                    if next_participant_id != participant_id:\n",
    "                        raise AssertionError(\"Some of the supplied paths do not link to files of the same participant! Exiting.\")\n",
    "                    else:\n",
    "                        participant_id = next_participant_id \n",
    "            except:\n",
    "                raise AssertionError(\"Some of the supplied paths do not link to files of the same participant! Exiting.\")\n",
    "        for elem in eyetracking_filepaths:\n",
    "            if not \"_EyeTracking_\" in elem:\n",
    "                raise AssertionError(\"Some of the supplied paths for eye tracking data link to files that are labeled for something else! Exiting.\")\n",
    "        for elem in input_filepaths:\n",
    "            if not \"_Input_\" in elem:\n",
    "                raise AssertionError(\"Some of the supplied paths for input data link to files that are labeled for something else! Exiting.\")\n",
    "        if not \"_ParticipantCalibrationData\" in calibration_filepath:\n",
    "            raise AssertionError(\"The supplied path for participant calibration data links to a file that is labeled for something else! Exiting.\")\n",
    "        for elem in scenedata_filepaths:\n",
    "            if not \"_SceneData_\" in elem:\n",
    "                raise AssertionError(\"Some of the supplied paths for scene data link to files that are labeled for something else! Exiting.\")\n",
    "        \n",
    "        \n",
    "        # store filepaths\n",
    "        self.eyetracking_filepaths = eyetracking_filepaths\n",
    "        self.input_filepaths = input_filepaths\n",
    "        self.calibration_filepath = calibration_filepath\n",
    "        self.scenedata_filepaths = scenedata_filepaths\n",
    "        \n",
    "        # store participant id and number of recorded areas and verbosity and whether reference data has been applied\n",
    "        self.participant_id = os.path.basename(eyetracking_filepaths[0]).split(\"_\")[0]\n",
    "        self.number_of_recorded_areas = len(eyetracking_filepaths)\n",
    "        self.verbose = verbose\n",
    "        self.reference_data_applied = False \n",
    "        \n",
    "        # init data dictionaries \n",
    "        self.eyetracking_data = {}\n",
    "        self.input_data = {}\n",
    "        self.calibration_data = {}\n",
    "        self.scene_data = {} \n",
    "        self.golden_segment_data = {}\n",
    "        self.golden_event_info = {}\n",
    "        \n",
    "        # bootstrap file loading\n",
    "        if bootstrap_file_loading and os.path.isfile(os.path.join(BOOTSTRAP_BASEPATH, \"./bootstrap_\" + str(self.participant_id) + \".pickle\")):\n",
    "            bootstrap_data = load_from_disk(os.path.join(BOOTSTRAP_BASEPATH, \"./bootstrap_\" + str(self.participant_id) + \".pickle\"))\n",
    "            self.participant_id = bootstrap_data[\"participant_id\"]\n",
    "            self.eyetracking_data = bootstrap_data[\"eyetracking_data\"]\n",
    "            self.input_data = bootstrap_data[\"input_data\"]\n",
    "            self.calibration_data = bootstrap_data[\"calibration_data\"]\n",
    "            self.scene_data = bootstrap_data[\"scene_data\"]\n",
    "            self.golden_segment_data = bootstrap_data[\"golden_segment_data\"]\n",
    "            self.golden_event_info = bootstrap_data[\"golden_event_info\"] \n",
    "            print(\"ParticipantData: Loaded data (bootstrapped) for participant \" + str(self.participant_id) + \".\")\n",
    "    \n",
    "        else:\n",
    "            # process raw data \n",
    "            self._load_raw_data()\n",
    "            self._extract_event_information()\n",
    "            self._extract_path_segments()\n",
    "            self._resample_path_segments()  \n",
    "            self._construct_segment_data()\n",
    "            self._construct_event_info()\n",
    "            print(\"ParticipantData: Loaded data (raw) for participant \" + str(self.participant_id) + \".\")\n",
    "            \n",
    "            # save to disk \n",
    "            if bootstrap_file_loading:\n",
    "                bootstrap_data = {}\n",
    "                bootstrap_data[\"participant_id\"] = self.participant_id\n",
    "                bootstrap_data[\"eyetracking_data\"] = self.eyetracking_data\n",
    "                bootstrap_data[\"input_data\"] = self.input_data\n",
    "                bootstrap_data[\"calibration_data\"] = self.calibration_data\n",
    "                bootstrap_data[\"scene_data\"] = self.scene_data\n",
    "                bootstrap_data[\"golden_segment_data\"] = self.golden_segment_data\n",
    "                bootstrap_data[\"golden_event_info\"] = self.golden_event_info\n",
    "                save_to_disk(bootstrap_data,os.path.join(BOOTSTRAP_BASEPATH, \"./bootstrap_\" + str(self.participant_id) + \".pickle\"))\n",
    "\n",
    "    \n",
    "    def _read_raw_data(self, filepaths):\n",
    "        '''\n",
    "        Read raw files into dictionary. \n",
    "        '''\n",
    "        \n",
    "        data = {}\n",
    "        \n",
    "        for idx, filename in enumerate(filepaths):\n",
    "            if self.verbose: \n",
    "                print(\"ParticipantData: Loading \" + filename + \" (file \" + str(idx+1) + \"/\" + str(len(filepaths)) + \")...\")\n",
    "            \n",
    "            if \"Westbrueck\" in filename:\n",
    "                token = \"Westbrueck\"\n",
    "            elif \"MountainRoad\" in filename:\n",
    "                token = \"MountainRoad\"\n",
    "            elif \"CountryRoad\" in filename:\n",
    "                token = \"CountryRoad\"\n",
    "            elif \"Autobahn\" in filename:\n",
    "                token = \"Autobahn\"  \n",
    "            elif \"TrainingScene\" in filename:\n",
    "                token = \"TrainingScene\"\n",
    "            else:  # not defined \n",
    "                print(\"ParticipantData: Found undefined area token in filename\" + filename + \"!\")\n",
    "                continue # in the loop     \n",
    "            data[token] = {}\n",
    "            data[token][\"filename\"] = filename\n",
    "            data[token][\"full_df\"] = read_normalized_json_to_df(filename)\n",
    "        \n",
    "        return data \n",
    "    \n",
    "    def _load_raw_data(self):\n",
    "        \n",
    "        # Eye tracking data\n",
    "        if self.verbose: \n",
    "            print(\"ParticipantData: Loading raw eyetracking data files...\")\n",
    "        self.eyetracking_data = self._read_raw_data(self.eyetracking_filepaths)\n",
    "        \n",
    "        # Input data \n",
    "        if self.verbose: \n",
    "            print(\"ParticipantData: Loading raw input data files...\")\n",
    "        self.input_data = self._read_raw_data(self.input_filepaths)\n",
    "        \n",
    "        # Scene data  \n",
    "        if self.verbose: \n",
    "            print(\"ParticipantData: Loading raw scene data files...\")\n",
    "        self.scene_data = self._read_raw_data(self.scenedata_filepaths)\n",
    "\n",
    "        # Calibration data  \n",
    "        if self.verbose:\n",
    "            print(\"ParticipantData: Loading raw calibration data...\")\n",
    "        self.calibration_data = {}\n",
    "        self.calibration_data['filename'] = self.calibration_filepath\n",
    "        self.calibration_data['full_df'] = read_normalized_json_to_df(self.calibration_filepath)\n",
    "        \n",
    "        print(\"Calib\")\n",
    "        print(self.calibration_data)\n",
    "        \n",
    "        \n",
    "    def _extract_event_information(self):\n",
    "        \n",
    "        # Extract most important event information \n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\",\"TrainingScene\"]:\n",
    "            self.scene_data[area][\"number_of_events\"] = len(self.scene_data[area][\"full_df\"][\"EventBehavior\"][0])\n",
    "            self.scene_data[area][\"events\"] = {}\n",
    "            for idx, event in enumerate(self.scene_data[area][\"full_df\"][\"EventBehavior\"][0]):\n",
    "                self.scene_data[area][\"events\"][idx] = {'name':event[\"EventName\"],'start':event[\"StartofEventTimeStamp\"],'stop':event[\"EndOfEventTimeStamp\"],'succeeded':event[\"SuccessfulCompletionState\"]}\n",
    "        \n",
    "        print(\"Event info\")\n",
    "        print(self.scene_data)\n",
    "        \n",
    "    \n",
    "    def _extract_path_segments(self):\n",
    "        '''\n",
    "        Extract the path segments. \n",
    "        Skip the TrainingScene, no relevant data. \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # Copy of entire dataframe input dataframe to prepare processing\n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "            self.input_data[area][\"processed_df\"] = self.input_data[area][\"full_df\"].copy(deep=True)\n",
    "            self.input_data[area][\"processed_df\"].drop(columns=[\"ReceivedInput\",\"SteeringInput\",\"AcellerationInput\",\"BrakeInput\"],inplace=True)\n",
    "            self.input_data[area][\"processed_df\"][\"path_segment_label\"] = -9 # event label \n",
    "\n",
    "        # Give label to individual path segments, -9 is event label \n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "            for event_idx in range(len(self.scene_data[area][\"events\"]) + 1):\n",
    "                cond = None \n",
    "                if event_idx == 0: # find all datapoints with timestamps before event start timestamp \n",
    "                    cond = (self.input_data[area][\"processed_df\"][\"TimeStamp\"] < self.scene_data[area][\"events\"][event_idx][\"start\"])\n",
    "                elif event_idx < len(self.scene_data[area][\"events\"]): # find all datapoints with timestamp between prev and next event \n",
    "                    cond = (self.input_data[area][\"processed_df\"][\"TimeStamp\"] > self.scene_data[area][\"events\"][event_idx - 1][\"stop\"]) & (self.input_data[area][\"processed_df\"][\"TimeStamp\"] < self.scene_data[area][\"events\"][event_idx][\"start\"])\n",
    "                elif event_idx == len(self.scene_data[area][\"events\"]): # find all datapoints with timestamp after last event\n",
    "                    cond = (self.input_data[area][\"processed_df\"][\"TimeStamp\"] > self.scene_data[area][\"events\"][event_idx - 1][\"stop\"])\n",
    "\n",
    "                # Filter     \n",
    "                self.input_data[area][\"processed_df\"].loc[cond, \"path_segment_label\"] = event_idx\n",
    "\n",
    "        # Extract path segments, add timestamps beginning at zero \n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "            self.input_data[area][\"path_segments_no_resample\"] = {}\n",
    "            for label in self.input_data[area][\"processed_df\"][\"path_segment_label\"].unique():\n",
    "                if (label != -9):\n",
    "\n",
    "                    # copy segment data \n",
    "                    cond = (self.input_data[area][\"processed_df\"][\"path_segment_label\"] == label)\n",
    "                    self.input_data[area][\"path_segments_no_resample\"][label] = self.input_data[area][\"processed_df\"].loc[cond].copy(deep=True)\n",
    "\n",
    "                    # add timestamp starting at zero \n",
    "                    if label == 0: # take first recorded datapoint as base timestamp \n",
    "                        ref_timestamp = self.input_data[area][\"path_segments_no_resample\"][label][\"TimeStamp\"].iloc[0]\n",
    "                    else: # take last event's stop time as base timestamp \n",
    "                        ref_timestamp = self.scene_data[area][\"events\"][label - 1][\"stop\"]\n",
    "\n",
    "                    self.input_data[area][\"path_segments_no_resample\"][label][\"rebased_timestamp\"] = self.input_data[area][\"path_segments_no_resample\"][label][\"TimeStamp\"] - ref_timestamp\n",
    "\n",
    "                else: # skip events \n",
    "                    pass \n",
    "         \n",
    "        print(\"path segment\")\n",
    "        print(self.input_data)\n",
    "    \n",
    "    \n",
    "    def _resample_path_segments(self):\n",
    "        '''\n",
    "        Resample the path segments.\n",
    "        Exclude TrainingScene, no relevant data. \n",
    "        '''\n",
    "        \n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"ParticipantData: Resampled path segments (excl. events):\")\n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "\n",
    "            self.input_data[area][\"path_segments_resampled\"] = {}\n",
    "            for segment in self.input_data[area][\"path_segments_no_resample\"]:\n",
    "                # copy segments \n",
    "                self.input_data[area][\"path_segments_resampled\"][segment] = self.input_data[area][\"path_segments_no_resample\"][segment].copy(deep=True)\n",
    "\n",
    "                # Hard match datapoints to closest timebin and fill arising holes by forward fill \n",
    "                if RESAMPLE_STRATEGY == \"FILL\":\n",
    "\n",
    "                    # round the timestamps to specified number of decimals \n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_timestamp_rounded\"] = self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_timestamp\"].round(TIMESTAMP_DECIMALS)\n",
    "\n",
    "                    # \"resample\" timestamps by reindexing with time delta (default 0.01s) steps and filling holes; first drop duplicate timestamps\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"resampled_timestamp\"] = self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_timestamp_rounded\"] \n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment].drop_duplicates(subset=\"resampled_timestamp\",keep=\"first\", inplace=True)\n",
    "                    start_time = 0\n",
    "                    end_time = self.input_data[area][\"path_segments_resampled\"][segment][\"resampled_timestamp\"].iloc[-1]\n",
    "                    time_delta = TIME_DELTA \n",
    "                    new_index = pd.Index(np.arange(start_time,end_time,time_delta), name=\"resampled_timestamp\")\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment] = self.input_data[area][\"path_segments_resampled\"][segment].set_index(\"resampled_timestamp\").reindex(new_index).reset_index()\n",
    "\n",
    "                    # keep track of where data was interpolated \n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"is_interpolated\"] = self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_timestamp\"].isnull()\n",
    "\n",
    "                    # fill nans (\"interpolate\") \n",
    "                    exclude_columns = [\"rebased_timestamp\",\"rebased_timestamp_rounded\",\"is_interpolated\",\"TimeStamp\",\"resampled_timestamp\"]\n",
    "                    for column in self.input_data[area][\"path_segments_resampled\"][segment].columns:  \n",
    "                        if column not in exclude_columns:\n",
    "                            self.input_data[area][\"path_segments_resampled\"][segment][column].fillna(method='ffill', inplace = True)\n",
    "                            self.input_data[area][\"path_segments_resampled\"][segment][column].fillna(method='bfill', inplace = True)\n",
    "\n",
    "                    # drop unneeded columns\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment].drop(columns=[\"TimeStamp\",\"rebased_timestamp\",\"rebased_timestamp_rounded\",\"path_segment_label\"], inplace = True)\n",
    "\n",
    "\n",
    "                # Resample using pandas' resample, fill with mean \n",
    "                if RESAMPLE_STRATEGY == \"MEAN\":\n",
    "\n",
    "                    # copy timestamp \n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"resampled_timestamp\"] = self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_timestamp\"] \n",
    "\n",
    "                    # create datetime from rebased timestamp\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_datetime\"] = pd.to_datetime(self.input_data[area][\"path_segments_resampled\"][segment]['resampled_timestamp'],unit='s')\n",
    "\n",
    "                    # resample with time delta (default 0.01s) interval and keep track of holes in the data before interpolation\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment] = self.input_data[area][\"path_segments_resampled\"][segment].resample(str(TIME_DELTA) + 'S',on=\"rebased_datetime\").mean()\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"is_interpolated\"] = self.input_data[area][\"path_segments_resampled\"][segment][\"resampled_timestamp\"].isnull()\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment].reset_index(inplace=True)\n",
    "\n",
    "                    # interpolate linearly\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment].interpolate(method=\"linear\",inplace=True)\n",
    "\n",
    "                    # get resampled_timestamp from rebased_datetime again \n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment][\"resampled_timestamp\"] = (self.input_data[area][\"path_segments_resampled\"][segment][\"rebased_datetime\"] - pd.Timestamp(\"1970-01-01\")) / pd.Timedelta('1s')\n",
    "\n",
    "                    # drop unneeded columns\n",
    "                    self.input_data[area][\"path_segments_resampled\"][segment].drop(columns=[\"rebased_datetime\",\"TimeStamp\",\"rebased_timestamp\",\"path_segment_label\"], inplace = True)\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(\"Area: \" + area + \" Segment: \" + str(segment) + \" Total datapoints (incl. resampled): \" + str(len(self.input_data[area][\"path_segments_resampled\"][segment][\"is_interpolated\"]))  + \" Filled NaNs: \" + str(self.input_data[area][\"path_segments_resampled\"][segment][\"is_interpolated\"].values.sum()))\n",
    "        \n",
    "        print(\"resample\")\n",
    "        print(self.input_data)\n",
    "        \n",
    "\n",
    "    def _construct_segment_data(self):\n",
    "        \n",
    "        # extract most important infos\n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "            self.golden_segment_data[area] = {}\n",
    "            for segment in self.input_data[area][\"path_segments_resampled\"]:\n",
    "                self.golden_segment_data[area][segment] = self.input_data[area][\"path_segments_resampled\"][segment].copy(deep = True)\n",
    "            \n",
    "                \n",
    "    def _construct_event_info(self):\n",
    "    \n",
    "        # extract event infos \n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "            self.golden_event_info[area] = {}\n",
    "            for event in self.scene_data[area][\"events\"]:\n",
    "                self.golden_event_info[area][event] = {}\n",
    "                self.golden_event_info[area][event]['name'] = self.scene_data[area][\"events\"][event]['name']\n",
    "                self.golden_event_info[area][event]['start'] = self.scene_data[area][\"events\"][event]['start']\n",
    "                self.golden_event_info[area][event]['stop'] = self.scene_data[area][\"events\"][event]['stop']\n",
    "                self.golden_event_info[area][event]['succeeded'] = self.scene_data[area][\"events\"][event]['succeeded']\n",
    "    \n",
    "    def apply_reference_data(self, ref_data_dict):\n",
    "        \n",
    "        for area in [\"Westbrueck\",\"MountainRoad\",\"CountryRoad\",\"Autobahn\"]:\n",
    "            for segment in self.golden_segment_data[area]:\n",
    "                max_len = len(self.golden_segment_data[area][segment])\n",
    "                if len(ref_data_dict[area][segment]) < max_len:\n",
    "                    max_len = len(ref_data_dict[area][segment])\n",
    "                if self.verbose:\n",
    "                    print(\"ParticipantData: Measured df length is \" + str(len(self.golden_segment_data[area][segment])) \\\n",
    "                        + \", reference df length is \" + str(len(ref_data_dict[area][segment])) \\\n",
    "                        + \", max length is \" + str(max_len))\n",
    "                    \n",
    "                # potentially cut length of data if reference data is shorter\n",
    "                self.golden_segment_data[area][segment] = self.golden_segment_data[area][segment].iloc[0:max_len]\n",
    "                \n",
    "                # apply reference data values \n",
    "                print(self.golden_segment_data[area][segment].columns)\n",
    "                print(ref_data_dict[area][segment].columns)\n",
    "                    \n",
    "                    \n",
    "                #print(len(self.golden_segment_data[area][segment]))\n",
    "                #print(reference_paths_all_events_failed[\"Westbrueck\"][3].iloc[0:2422])\n",
    "                \n",
    "    def set_verbosity(self,verbosity):\n",
    "        self.verbosity = verbosity \n",
    "                \n",
    "    def get_segment_data(self):\n",
    "        return self.golden_segment_data\n",
    "    \n",
    "    def get_event_info(self):\n",
    "        return self.golden_event_info\n",
    "    \n",
    "    def get_participant_id(self):\n",
    "        return self.participant_id \n",
    "        \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Stuff\n",
    "'''\n",
    "\n",
    "# TODO Resample to constant time bins for proper FFT \n",
    "# Use Lomb-Scargle Periodogram to compare to spectogram of resample data \n",
    "\n",
    "\n",
    "f = np.linspace(0.01, 1000, 1000000) # start, stop, number of pts; modify this! \n",
    "pgram = signal.lombscargle(reduced_df[\"UnixTimeStamp\"], reduced_df[\"HmdPosition.x\"], f) # f, normalize=True\n",
    "\n",
    "plt.plot(f, pgram)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
