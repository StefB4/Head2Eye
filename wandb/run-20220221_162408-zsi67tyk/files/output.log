Positional Embedding Return Value
Tensor("positional_embedding_13/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_13/add_1:0', description="created by layer 'positional_embedding_13'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_7/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_7/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_14/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_14/add_1:0', description="created by layer 'positional_embedding_14'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_8/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_8/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_15/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_15/add_1:0', description="created by layer 'positional_embedding_15'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_9/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_9/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_16/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_16/add_1:0', description="created by layer 'positional_embedding_16'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_10/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_10/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_17/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_17/add_1:0', description="created by layer 'positional_embedding_17'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_11/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_11/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_11/layer_normalization_40/add:0", shape=(64, 200, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_11/sequential_17/dense_35/BiasAdd:0", shape=(64, 200, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_11/layer_normalization_41/add:0", shape=(64, 200, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(64, 40000), dtype=tf.float32, name=None), name='flatten_12/Reshape:0', description="created by layer 'flatten_12'")
Positional Embedding Return Value
Tensor("positional_embedding_18/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_18/add_1:0', description="created by layer 'positional_embedding_18'")
Decoder Inputs:
Tensor("transformer_decoder_6/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_6/multi_head_attention_24/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_6/layer_normalization_42/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_6/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_6/layer_normalization_44/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_13/Reshape:0', description="created by layer 'flatten_13'")
WARNING:tensorflow:Model was constructed with shape (None, 200) for input KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'"), but it was called on an input with incompatible shape (64, 40000).
Positional Embedding Return Value
Tensor("model_13/positional_embedding_18/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_13/transformer_decoder_6/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_13/transformer_decoder_6/multi_head_attention_24/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_13/transformer_decoder_6/layer_normalization_42/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("model_13/transformer_decoder_6/strided_slice_1:0", shape=(64, 1, 40000), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_19/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_19/add_1:0', description="created by layer 'positional_embedding_19'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_12/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_12/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_20/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_20/add_1:0', description="created by layer 'positional_embedding_20'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_13/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_13/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_13/layer_normalization_47/add:0", shape=(64, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_13/sequential_20/dense_41/BiasAdd:0", shape=(64, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_13/layer_normalization_48/add:0", shape=(64, 1, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(64, 200), dtype=tf.float32, name=None), name='flatten_14/Reshape:0', description="created by layer 'flatten_14'")
Positional Embedding Return Value
Tensor("positional_embedding_21/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_21/add_1:0', description="created by layer 'positional_embedding_21'")
Decoder Inputs:
Tensor("transformer_decoder_7/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_7/multi_head_attention_28/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_7/layer_normalization_49/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_7/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_7/layer_normalization_51/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_15/Reshape:0', description="created by layer 'flatten_15'")
Positional Embedding Return Value
Tensor("model_15/positional_embedding_21/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_15/transformer_decoder_7/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_15/transformer_decoder_7/multi_head_attention_28/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_15/transformer_decoder_7/layer_normalization_49/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("model_15/transformer_decoder_7/strided_slice_1:0", shape=(64, 1, 200), dtype=float32)
Decoder Shape
Tensor("model_15/transformer_decoder_7/layer_normalization_51/add:0", shape=(64, 1, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_20 (Positi (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_13 (Transfo (64, 1, 200)         2107248     positional_embedding_20[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_14 (Flatten)            (64, 200)            0           transformer_encoder_13[0][0]
__________________________________________________________________________________________________
model_15 (Functional)           (None, 200)          3392648     decoder_inputs[0][0]
                                                                 flatten_14[0][0]
==================================================================================================
Total params: 5,499,896
Trainable params: 5,499,896
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_20/add:0", shape=(None, 200), dtype=float64)
Tensor("transformer/positional_embedding_20/NotEqual:0", shape=(None, 200), dtype=bool)
Tensor("transformer/transformer_encoder_13/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_13/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_13/layer_normalization_47/add:0", shape=(64, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_13/sequential_20/dense_41/BiasAdd:0", shape=(64, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_13/layer_normalization_48/add:0", shape=(64, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_15/positional_embedding_21/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_15/transformer_decoder_7/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_15/transformer_decoder_7/multi_head_attention_28/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_15/transformer_decoder_7/layer_normalization_49/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_15/transformer_decoder_7/strided_slice_1:0", shape=(64, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_15/transformer_decoder_7/layer_normalization_51/add:0", shape=(64, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_20/add:0", shape=(None, 200), dtype=float64)
Tensor("transformer/positional_embedding_20/NotEqual:0", shape=(None, 200), dtype=bool)
Tensor("transformer/transformer_encoder_13/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_13/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_13/layer_normalization_47/add:0", shape=(64, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_13/sequential_20/dense_41/BiasAdd:0", shape=(64, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_13/layer_normalization_48/add:0", shape=(64, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_15/positional_embedding_21/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_15/transformer_decoder_7/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_15/transformer_decoder_7/multi_head_attention_28/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_15/transformer_decoder_7/layer_normalization_49/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_15/transformer_decoder_7/strided_slice_1:0", shape=(64, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_15/transformer_decoder_7/layer_normalization_51/add:0", shape=(64, 1, 200), dtype=float32)
1/9 [==>...........................] - ETA: 15s - loss: 2.4294 - mean_squared_error: 2.4294 - mean_absolute_error: 1.2385 - mean_absolute_percentage_error: 186.4427 - cosine_proximity: 0.0429
Positional Embedding Return Value
Tensor("positional_embedding_22/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_22/add_1:0', description="created by layer 'positional_embedding_22'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_14/Cast:0", shape=(None, 200, 1, 1), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_14/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_23/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_23/add_1:0', description="created by layer 'positional_embedding_23'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_15/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_15/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_24/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_24/add_1:0', description="created by layer 'positional_embedding_24'")
Encoder reshaped inputs
Tensor("transformer_encoder_16/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_25/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_25/add_1:0', description="created by layer 'positional_embedding_25'")
Encoder reshaped inputs
Tensor("transformer_encoder_17/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_17/layer_normalization_58/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_17/sequential_25/dense_51/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_17/layer_normalization_59/add:0", shape=(None, 1, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_16/Reshape:0', description="created by layer 'flatten_16'")
Positional Embedding Return Value
Tensor("positional_embedding_26/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_26/add_1:0', description="created by layer 'positional_embedding_26'")
Decoder Inputs:
Tensor("transformer_decoder_8/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_8/multi_head_attention_34/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_8/layer_normalization_60/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_8/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_8/layer_normalization_62/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_17/Reshape:0', description="created by layer 'flatten_17'")
Positional Embedding Return Value
Tensor("model_17/positional_embedding_26/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_17/transformer_decoder_8/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_17/transformer_decoder_8/multi_head_attention_34/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_17/transformer_decoder_8/layer_normalization_60/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("model_17/transformer_decoder_8/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("model_17/transformer_decoder_8/layer_normalization_62/add:0", shape=(None, 1, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_25 (Positi (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_17 (Transfo (None, 1, 200)       2107248     positional_embedding_25[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 200)          0           transformer_encoder_17[0][0]
__________________________________________________________________________________________________
model_17 (Functional)           (None, 200)          3392648     decoder_inputs[0][0]
                                                                 flatten_16[0][0]
==================================================================================================
Total params: 5,499,896
Trainable params: 5,499,896
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_25/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_17/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_17/layer_normalization_58/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_17/sequential_25/dense_51/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_17/layer_normalization_59/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_17/positional_embedding_26/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_17/transformer_decoder_8/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_17/transformer_decoder_8/multi_head_attention_34/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_17/transformer_decoder_8/layer_normalization_60/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_17/transformer_decoder_8/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_17/transformer_decoder_8/layer_normalization_62/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_25/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_17/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_17/layer_normalization_58/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_17/sequential_25/dense_51/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_17/layer_normalization_59/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_17/positional_embedding_26/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_17/transformer_decoder_8/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_17/transformer_decoder_8/multi_head_attention_34/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_17/transformer_decoder_8/layer_normalization_60/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_17/transformer_decoder_8/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_17/transformer_decoder_8/layer_normalization_62/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - ETA: 0s - loss: 2.3840 - mean_squared_error: 2.3840 - mean_absolute_error: 1.1417 - mean_absolute_percentage_error: 174.4107 - cosine_proximity: 0.0696
Positional Embedding Return Value
Tensor("transformer/positional_embedding_25/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_17/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_17/layer_normalization_58/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_17/sequential_25/dense_51/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_17/layer_normalization_59/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_17/positional_embedding_26/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_17/transformer_decoder_8/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_17/transformer_decoder_8/multi_head_attention_34/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_17/transformer_decoder_8/layer_normalization_60/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_17/transformer_decoder_8/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Can't save model, h5py returned error: Layer TransformerEncoder has arguments in `__init__` and therefore must override `get_config`.
Tensor("transformer/model_17/transformer_decoder_8/layer_normalization_62/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - 4s 160ms/step - loss: 2.3764 - mean_squared_error: 2.3764 - mean_absolute_error: 1.1403 - mean_absolute_percentage_error: 174.4980 - cosine_proximity: 0.0731 - val_loss: 1.2230 - val_mean_squared_error: 1.2230 - val_mean_absolute_error: 0.8798 - val_mean_absolute_percentage_error: 152.4772 - val_cosine_proximity: 0.2140
Epoch 2/40
9/9 [==============================] - ETA: 0s - loss: 2.1762 - mean_squared_error: 2.1762 - mean_absolute_error: 1.1457 - mean_absolute_percentage_error: 183.5522 - cosine_proximity: 0.1569
Positional Embedding Return Value
Tensor("positional_embedding_27/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_27/add_1:0', description="created by layer 'positional_embedding_27'")
Encoder reshaped inputs
Tensor("transformer_encoder_18/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_18/layer_normalization_63/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_18/sequential_27/dense_55/BiasAdd:0", shape=(None, 200, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_18/layer_normalization_64/add:0", shape=(None, 200, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 40000), dtype=tf.float32, name=None), name='flatten_18/Reshape:0', description="created by layer 'flatten_18'")
Positional Embedding Return Value
Tensor("positional_embedding_28/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_28/add_1:0', description="created by layer 'positional_embedding_28'")
Decoder Inputs:
Tensor("transformer_decoder_9/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_9/multi_head_attention_37/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_9/layer_normalization_65/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_9/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_9/layer_normalization_67/add:0", shape=(None, 200, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 40000), dtype=tf.float32, name=None), name='flatten_19/Reshape:0', description="created by layer 'flatten_19'")
WARNING:tensorflow:Model was constructed with shape (None, 200) for input KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'"), but it was called on an input with incompatible shape (None, 40000).
Positional Embedding Return Value
Tensor("model_19/positional_embedding_28/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_19/transformer_decoder_9/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("model_19/transformer_decoder_9/multi_head_attention_37/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("model_19/transformer_decoder_9/layer_normalization_65/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("model_19/transformer_decoder_9/strided_slice_1:0", shape=(None, 40000, 1), dtype=float32)
Decoder Shape
Tensor("model_19/transformer_decoder_9/layer_normalization_67/add:0", shape=(None, 200, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_27 (Positi (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_18 (Transfo (None, 200, 200)     425499      positional_embedding_27[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 40000)        0           transformer_encoder_18[0][0]
__________________________________________________________________________________________________
model_19 (Functional)           (None, 40000)        436702      decoder_inputs[0][0]
                                                                 flatten_18[0][0]
==================================================================================================
Total params: 862,201
Trainable params: 862,201
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_27/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_18/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_18/layer_normalization_63/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_18/sequential_27/dense_55/BiasAdd:0", shape=(None, 200, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_18/layer_normalization_64/add:0", shape=(None, 200, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_29/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_29/add_1:0', description="created by layer 'positional_embedding_29'")
Encoder reshaped inputs
Tensor("transformer_encoder_19/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_19/layer_normalization_68/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_19/sequential_29/dense_59/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_19/layer_normalization_69/add:0", shape=(None, 200, 1), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_20/Reshape:0', description="created by layer 'flatten_20'")
Positional Embedding Return Value
Tensor("positional_embedding_30/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_30/add_1:0', description="created by layer 'positional_embedding_30'")
Decoder Inputs:
Tensor("transformer_decoder_10/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_10/multi_head_attention_40/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_10/layer_normalization_70/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_10/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_10/layer_normalization_72/add:0", shape=(None, 200, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 40000), dtype=tf.float32, name=None), name='flatten_21/Reshape:0', description="created by layer 'flatten_21'")
Positional Embedding Return Value
Tensor("model_21/positional_embedding_30/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_21/transformer_decoder_10/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("model_21/transformer_decoder_10/multi_head_attention_40/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("model_21/transformer_decoder_10/layer_normalization_70/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("model_21/transformer_decoder_10/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("model_21/transformer_decoder_10/layer_normalization_72/add:0", shape=(None, 200, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_29 (Positi (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_19 (Transfo (None, 200, 1)       17350       positional_embedding_29[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 200)          0           transformer_encoder_19[0][0]
__________________________________________________________________________________________________
model_21 (Functional)           (None, 40000)        436702      decoder_inputs[0][0]
                                                                 flatten_20[0][0]
==================================================================================================
Total params: 454,052
Trainable params: 454,052
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_29/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_19/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_19/layer_normalization_68/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_19/sequential_29/dense_59/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_19/layer_normalization_69/add:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_21/positional_embedding_30/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_21/transformer_decoder_10/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_21/transformer_decoder_10/multi_head_attention_40/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer/model_21/transformer_decoder_10/layer_normalization_70/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_21/transformer_decoder_10/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer/model_21/transformer_decoder_10/layer_normalization_72/add:0", shape=(None, 200, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_31/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_31/add_1:0', description="created by layer 'positional_embedding_31'")
Encoder reshaped inputs
Tensor("transformer_encoder_20/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_20/layer_normalization_73/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_20/sequential_31/dense_63/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_20/layer_normalization_74/add:0", shape=(None, 200, 1), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_22/Reshape:0', description="created by layer 'flatten_22'")
Positional Embedding Return Value
Tensor("positional_embedding_32/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_32/add_1:0', description="created by layer 'positional_embedding_32'")
Decoder Inputs:
Tensor("transformer_decoder_11/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_11/multi_head_attention_43/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_11/layer_normalization_75/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_11/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_11/layer_normalization_77/add:0", shape=(None, 200, 1), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_23/Reshape:0', description="created by layer 'flatten_23'")
Positional Embedding Return Value
Tensor("model_23/positional_embedding_32/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_23/transformer_decoder_11/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("model_23/transformer_decoder_11/multi_head_attention_43/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("model_23/transformer_decoder_11/layer_normalization_75/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("model_23/transformer_decoder_11/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("model_23/transformer_decoder_11/layer_normalization_77/add:0", shape=(None, 200, 1), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_31 (Positi (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_20 (Transfo (None, 200, 1)       17350       positional_embedding_31[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 200)          0           transformer_encoder_20[0][0]
__________________________________________________________________________________________________
model_23 (Functional)           (None, 200)          28553       decoder_inputs[0][0]
                                                                 flatten_22[0][0]
==================================================================================================
Total params: 45,903
Trainable params: 45,903
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_31/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_20/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_20/layer_normalization_73/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_20/sequential_31/dense_63/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_20/layer_normalization_74/add:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_23/positional_embedding_32/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_23/transformer_decoder_11/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_23/transformer_decoder_11/multi_head_attention_43/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_75/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_23/transformer_decoder_11/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_77/add:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_31/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_20/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_20/layer_normalization_73/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_20/sequential_31/dense_63/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_20/layer_normalization_74/add:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_23/positional_embedding_32/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_23/transformer_decoder_11/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_23/transformer_decoder_11/multi_head_attention_43/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_75/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_23/transformer_decoder_11/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_77/add:0", shape=(None, 200, 1), dtype=float32)







9/9 [==============================] - ETA: 0s - loss: 0.5441 - mean_squared_error: 0.5441 - mean_absolute_error: 0.7094 - mean_absolute_percentage_error: 99.6879 - cosine_proximity: 0.4553
Positional Embedding Return Value
Tensor("transformer/positional_embedding_31/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_20/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_20/layer_normalization_73/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_20/sequential_31/dense_63/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_20/layer_normalization_74/add:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_23/positional_embedding_32/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_23/transformer_decoder_11/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_23/transformer_decoder_11/multi_head_attention_43/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_75/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_23/transformer_decoder_11/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_77/add:0", shape=(None, 200, 1), dtype=float32)
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Can't save model, h5py returned error: Layer TransformerEncoder has arguments in `__init__` and therefore must override `get_config`.
9/9 [==============================] - 36s 4s/step - loss: 0.5439 - mean_squared_error: 0.5439 - mean_absolute_error: 0.7093 - mean_absolute_percentage_error: 99.6568 - cosine_proximity: 0.4700 - val_loss: 0.5411 - val_mean_squared_error: 0.5411 - val_mean_absolute_error: 0.7074 - val_mean_absolute_percentage_error: 98.6315 - val_cosine_proximity: 0.9636
Epoch 2/40








9/9 [==============================] - 32s 4s/step - loss: 0.5313 - mean_squared_error: 0.5313 - mean_absolute_error: 0.7003 - mean_absolute_percentage_error: 98.2710 - cosine_proximity: 0.6823 - val_loss: 0.5285 - val_mean_squared_error: 0.5285 - val_mean_absolute_error: 0.6984 - val_mean_absolute_percentage_error: 97.2670 - val_cosine_proximity: 0.9636
Epoch 3/40








9/9 [==============================] - 31s 4s/step - loss: 0.5191 - mean_squared_error: 0.5191 - mean_absolute_error: 0.6913 - mean_absolute_percentage_error: 96.9009 - cosine_proximity: 0.6817 - val_loss: 0.5162 - val_mean_squared_error: 0.5162 - val_mean_absolute_error: 0.6895 - val_mean_absolute_percentage_error: 95.9129 - val_cosine_proximity: 0.9636
Epoch 4/40









9/9 [==============================] - 34s 4s/step - loss: 0.5075 - mean_squared_error: 0.5075 - mean_absolute_error: 0.6826 - mean_absolute_percentage_error: 95.5566 - cosine_proximity: 0.6802 - val_loss: 0.5041 - val_mean_squared_error: 0.5041 - val_mean_absolute_error: 0.6807 - val_mean_absolute_percentage_error: 94.5744 - val_cosine_proximity: 0.9636
Epoch 5/40








9/9 [==============================] - 33s 4s/step - loss: 0.4961 - mean_squared_error: 0.4961 - mean_absolute_error: 0.6736 - mean_absolute_percentage_error: 94.1821 - cosine_proximity: 0.6808 - val_loss: 0.4924 - val_mean_squared_error: 0.4924 - val_mean_absolute_error: 0.6720 - val_mean_absolute_percentage_error: 93.2511 - val_cosine_proximity: 0.9636
Epoch 6/40








9/9 [==============================] - 33s 4s/step - loss: 0.4858 - mean_squared_error: 0.4858 - mean_absolute_error: 0.6654 - mean_absolute_percentage_error: 92.9211 - cosine_proximity: 0.6774 - val_loss: 0.4809 - val_mean_squared_error: 0.4809 - val_mean_absolute_error: 0.6635 - val_mean_absolute_percentage_error: 91.9483 - val_cosine_proximity: 0.9636
Epoch 7/40








9/9 [==============================] - 34s 4s/step - loss: 0.4756 - mean_squared_error: 0.4756 - mean_absolute_error: 0.6571 - mean_absolute_percentage_error: 91.6403 - cosine_proximity: 0.6771 - val_loss: 0.4698 - val_mean_squared_error: 0.4698 - val_mean_absolute_error: 0.6551 - val_mean_absolute_percentage_error: 90.6658 - val_cosine_proximity: 0.9636
Epoch 8/40








9/9 [==============================] - 37s 4s/step - loss: 0.4648 - mean_squared_error: 0.4648 - mean_absolute_error: 0.6480 - mean_absolute_percentage_error: 90.2623 - cosine_proximity: 0.6811 - val_loss: 0.4590 - val_mean_squared_error: 0.4590 - val_mean_absolute_error: 0.6467 - val_mean_absolute_percentage_error: 89.3987 - val_cosine_proximity: 0.9636
Epoch 9/40








9/9 [==============================] - 35s 4s/step - loss: 0.4553 - mean_squared_error: 0.4553 - mean_absolute_error: 0.6397 - mean_absolute_percentage_error: 88.9796 - cosine_proximity: 0.6809 - val_loss: 0.4485 - val_mean_squared_error: 0.4485 - val_mean_absolute_error: 0.6385 - val_mean_absolute_percentage_error: 88.1490 - val_cosine_proximity: 0.9636
Epoch 10/40








9/9 [==============================] - 36s 4s/step - loss: 0.4458 - mean_squared_error: 0.4458 - mean_absolute_error: 0.6312 - mean_absolute_percentage_error: 87.6663 - cosine_proximity: 0.6819 - val_loss: 0.4382 - val_mean_squared_error: 0.4382 - val_mean_absolute_error: 0.6304 - val_mean_absolute_percentage_error: 86.9160 - val_cosine_proximity: 0.9636
Epoch 11/40








9/9 [==============================] - 32s 4s/step - loss: 0.4384 - mean_squared_error: 0.4384 - mean_absolute_error: 0.6242 - mean_absolute_percentage_error: 86.5908 - cosine_proximity: 0.6770 - val_loss: 0.4282 - val_mean_squared_error: 0.4282 - val_mean_absolute_error: 0.6225 - val_mean_absolute_percentage_error: 85.7060 - val_cosine_proximity: 0.9636
Epoch 12/40








9/9 [==============================] - 31s 3s/step - loss: 0.4283 - mean_squared_error: 0.4283 - mean_absolute_error: 0.6152 - mean_absolute_percentage_error: 85.2476 - cosine_proximity: 0.6831 - val_loss: 0.4185 - val_mean_squared_error: 0.4185 - val_mean_absolute_error: 0.6147 - val_mean_absolute_percentage_error: 84.5137 - val_cosine_proximity: 0.9636
Epoch 13/40








9/9 [==============================] - 31s 4s/step - loss: 0.4208 - mean_squared_error: 0.4208 - mean_absolute_error: 0.6075 - mean_absolute_percentage_error: 84.0291 - cosine_proximity: 0.6809 - val_loss: 0.4091 - val_mean_squared_error: 0.4091 - val_mean_absolute_error: 0.6069 - val_mean_absolute_percentage_error: 83.3391 - val_cosine_proximity: 0.9636
Epoch 14/40








9/9 [==============================] - 33s 4s/step - loss: 0.4136 - mean_squared_error: 0.4136 - mean_absolute_error: 0.6003 - mean_absolute_percentage_error: 82.9456 - cosine_proximity: 0.6800 - val_loss: 0.4000 - val_mean_squared_error: 0.4000 - val_mean_absolute_error: 0.5994 - val_mean_absolute_percentage_error: 82.1840 - val_cosine_proximity: 0.9636
Epoch 15/40








9/9 [==============================] - 32s 4s/step - loss: 0.4063 - mean_squared_error: 0.4063 - mean_absolute_error: 0.5926 - mean_absolute_percentage_error: 81.7261 - cosine_proximity: 0.6803 - val_loss: 0.3911 - val_mean_squared_error: 0.3911 - val_mean_absolute_error: 0.5919 - val_mean_absolute_percentage_error: 81.0502 - val_cosine_proximity: 0.9636
Epoch 16/40








9/9 [==============================] - 37s 4s/step - loss: 0.3991 - mean_squared_error: 0.3991 - mean_absolute_error: 0.5854 - mean_absolute_percentage_error: 80.6874 - cosine_proximity: 0.6814 - val_loss: 0.3825 - val_mean_squared_error: 0.3825 - val_mean_absolute_error: 0.5846 - val_mean_absolute_percentage_error: 79.9367 - val_cosine_proximity: 0.9636
Epoch 17/40








9/9 [==============================] - 32s 4s/step - loss: 0.3925 - mean_squared_error: 0.3925 - mean_absolute_error: 0.5779 - mean_absolute_percentage_error: 79.5201 - cosine_proximity: 0.6812 - val_loss: 0.3741 - val_mean_squared_error: 0.3741 - val_mean_absolute_error: 0.5774 - val_mean_absolute_percentage_error: 78.8433 - val_cosine_proximity: 0.9636
Epoch 18/40








9/9 [==============================] - 31s 3s/step - loss: 0.3869 - mean_squared_error: 0.3869 - mean_absolute_error: 0.5710 - mean_absolute_percentage_error: 78.4171 - cosine_proximity: 0.6793 - val_loss: 0.3661 - val_mean_squared_error: 0.3661 - val_mean_absolute_error: 0.5704 - val_mean_absolute_percentage_error: 77.7723 - val_cosine_proximity: 0.9636
Epoch 19/40








9/9 [==============================] - 36s 4s/step - loss: 0.3809 - mean_squared_error: 0.3809 - mean_absolute_error: 0.5645 - mean_absolute_percentage_error: 77.4761 - cosine_proximity: 0.6799 - val_loss: 0.3582 - val_mean_squared_error: 0.3582 - val_mean_absolute_error: 0.5635 - val_mean_absolute_percentage_error: 76.7222 - val_cosine_proximity: 0.9636
Epoch 20/40








9/9 [==============================] - 36s 4s/step - loss: 0.3747 - mean_squared_error: 0.3747 - mean_absolute_error: 0.5569 - mean_absolute_percentage_error: 76.2855 - cosine_proximity: 0.6810 - val_loss: 0.3507 - val_mean_squared_error: 0.3507 - val_mean_absolute_error: 0.5567 - val_mean_absolute_percentage_error: 75.6927 - val_cosine_proximity: 0.9636
Epoch 21/40








9/9 [==============================] - 36s 4s/step - loss: 0.3693 - mean_squared_error: 0.3693 - mean_absolute_error: 0.5499 - mean_absolute_percentage_error: 75.1894 - cosine_proximity: 0.6812 - val_loss: 0.3433 - val_mean_squared_error: 0.3433 - val_mean_absolute_error: 0.5501 - val_mean_absolute_percentage_error: 74.6837 - val_cosine_proximity: 0.9636
Epoch 22/40








9/9 [==============================] - 32s 4s/step - loss: 0.3646 - mean_squared_error: 0.3646 - mean_absolute_error: 0.5437 - mean_absolute_percentage_error: 74.2596 - cosine_proximity: 0.6801 - val_loss: 0.3362 - val_mean_squared_error: 0.3362 - val_mean_absolute_error: 0.5436 - val_mean_absolute_percentage_error: 73.6956 - val_cosine_proximity: 0.9636
Epoch 23/40








9/9 [==============================] - 33s 4s/step - loss: 0.3596 - mean_squared_error: 0.3596 - mean_absolute_error: 0.5370 - mean_absolute_percentage_error: 73.2241 - cosine_proximity: 0.6808 - val_loss: 0.3294 - val_mean_squared_error: 0.3294 - val_mean_absolute_error: 0.5373 - val_mean_absolute_percentage_error: 72.7278 - val_cosine_proximity: 0.9636
Epoch 24/40








9/9 [==============================] - 36s 4s/step - loss: 0.3557 - mean_squared_error: 0.3557 - mean_absolute_error: 0.5311 - mean_absolute_percentage_error: 72.3013 - cosine_proximity: 0.6797 - val_loss: 0.3227 - val_mean_squared_error: 0.3227 - val_mean_absolute_error: 0.5310 - val_mean_absolute_percentage_error: 71.7808 - val_cosine_proximity: 0.9636
Epoch 25/40








9/9 [==============================] - 37s 4s/step - loss: 0.3512 - mean_squared_error: 0.3512 - mean_absolute_error: 0.5251 - mean_absolute_percentage_error: 71.4337 - cosine_proximity: 0.6802 - val_loss: 0.3163 - val_mean_squared_error: 0.3163 - val_mean_absolute_error: 0.5250 - val_mean_absolute_percentage_error: 70.8545 - val_cosine_proximity: 0.9636
Epoch 26/40








9/9 [==============================] - 35s 4s/step - loss: 0.3471 - mean_squared_error: 0.3471 - mean_absolute_error: 0.5187 - mean_absolute_percentage_error: 70.4365 - cosine_proximity: 0.6806 - val_loss: 0.3101 - val_mean_squared_error: 0.3101 - val_mean_absolute_error: 0.5190 - val_mean_absolute_percentage_error: 69.9491 - val_cosine_proximity: 0.9636
Epoch 27/40








9/9 [==============================] - 39s 4s/step - loss: 0.3421 - mean_squared_error: 0.3421 - mean_absolute_error: 0.5120 - mean_absolute_percentage_error: 69.4447 - cosine_proximity: 0.6825 - val_loss: 0.3041 - val_mean_squared_error: 0.3041 - val_mean_absolute_error: 0.5132 - val_mean_absolute_percentage_error: 69.0634 - val_cosine_proximity: 0.9636
Epoch 28/40








9/9 [==============================] - 38s 4s/step - loss: 0.3404 - mean_squared_error: 0.3404 - mean_absolute_error: 0.5077 - mean_absolute_percentage_error: 68.7435 - cosine_proximity: 0.6794 - val_loss: 0.2983 - val_mean_squared_error: 0.2983 - val_mean_absolute_error: 0.5075 - val_mean_absolute_percentage_error: 68.2000 - val_cosine_proximity: 0.9636
Epoch 29/40








9/9 [==============================] - 32s 4s/step - loss: 0.3362 - mean_squared_error: 0.3362 - mean_absolute_error: 0.5011 - mean_absolute_percentage_error: 67.7143 - cosine_proximity: 0.6807 - val_loss: 0.2927 - val_mean_squared_error: 0.2927 - val_mean_absolute_error: 0.5020 - val_mean_absolute_percentage_error: 67.3566 - val_cosine_proximity: 0.9636
Epoch 30/40








9/9 [==============================] - 32s 4s/step - loss: 0.3329 - mean_squared_error: 0.3329 - mean_absolute_error: 0.4960 - mean_absolute_percentage_error: 66.9961 - cosine_proximity: 0.6811 - val_loss: 0.2873 - val_mean_squared_error: 0.2873 - val_mean_absolute_error: 0.4966 - val_mean_absolute_percentage_error: 66.5345 - val_cosine_proximity: 0.9636
Epoch 31/40








9/9 [==============================] - 31s 3s/step - loss: 0.3299 - mean_squared_error: 0.3299 - mean_absolute_error: 0.4909 - mean_absolute_percentage_error: 66.2226 - cosine_proximity: 0.6811 - val_loss: 0.2821 - val_mean_squared_error: 0.2821 - val_mean_absolute_error: 0.4913 - val_mean_absolute_percentage_error: 65.7340 - val_cosine_proximity: 0.9636
Epoch 32/40








9/9 [==============================] - 31s 4s/step - loss: 0.3268 - mean_squared_error: 0.3268 - mean_absolute_error: 0.4864 - mean_absolute_percentage_error: 65.6215 - cosine_proximity: 0.6813 - val_loss: 0.2771 - val_mean_squared_error: 0.2771 - val_mean_absolute_error: 0.4862 - val_mean_absolute_percentage_error: 64.9545 - val_cosine_proximity: 0.9636
Epoch 33/40








9/9 [==============================] - 34s 4s/step - loss: 0.3258 - mean_squared_error: 0.3258 - mean_absolute_error: 0.4843 - mean_absolute_percentage_error: 65.3734 - cosine_proximity: 0.6789 - val_loss: 0.2723 - val_mean_squared_error: 0.2723 - val_mean_absolute_error: 0.4812 - val_mean_absolute_percentage_error: 64.1970 - val_cosine_proximity: 0.9636
Epoch 34/40








9/9 [==============================] - 32s 3s/step - loss: 0.3220 - mean_squared_error: 0.3220 - mean_absolute_error: 0.4800 - mean_absolute_percentage_error: 64.9008 - cosine_proximity: 0.6812 - val_loss: 0.2677 - val_mean_squared_error: 0.2677 - val_mean_absolute_error: 0.4764 - val_mean_absolute_percentage_error: 63.4579 - val_cosine_proximity: 0.9636
Epoch 35/40








9/9 [==============================] - 31s 4s/step - loss: 0.3205 - mean_squared_error: 0.3205 - mean_absolute_error: 0.4772 - mean_absolute_percentage_error: 64.5460 - cosine_proximity: 0.6800 - val_loss: 0.2632 - val_mean_squared_error: 0.2632 - val_mean_absolute_error: 0.4717 - val_mean_absolute_percentage_error: 62.7410 - val_cosine_proximity: 0.9636
Epoch 36/40








9/9 [==============================] - 31s 3s/step - loss: 0.3195 - mean_squared_error: 0.3195 - mean_absolute_error: 0.4760 - mean_absolute_percentage_error: 64.5224 - cosine_proximity: 0.6782 - val_loss: 0.2589 - val_mean_squared_error: 0.2589 - val_mean_absolute_error: 0.4671 - val_mean_absolute_percentage_error: 62.0458 - val_cosine_proximity: 0.9636
Epoch 37/40








9/9 [==============================] - 35s 4s/step - loss: 0.3172 - mean_squared_error: 0.3172 - mean_absolute_error: 0.4738 - mean_absolute_percentage_error: 64.3914 - cosine_proximity: 0.6790 - val_loss: 0.2548 - val_mean_squared_error: 0.2548 - val_mean_absolute_error: 0.4627 - val_mean_absolute_percentage_error: 61.3703 - val_cosine_proximity: 0.9636
Epoch 38/40








9/9 [==============================] - 32s 4s/step - loss: 0.3155 - mean_squared_error: 0.3155 - mean_absolute_error: 0.4717 - mean_absolute_percentage_error: 64.2240 - cosine_proximity: 0.6790 - val_loss: 0.2508 - val_mean_squared_error: 0.2508 - val_mean_absolute_error: 0.4583 - val_mean_absolute_percentage_error: 60.7136 - val_cosine_proximity: 0.9636
Epoch 39/40








9/9 [==============================] - 32s 4s/step - loss: 0.3110 - mean_squared_error: 0.3110 - mean_absolute_error: 0.4667 - mean_absolute_percentage_error: 63.5945 - cosine_proximity: 0.6828 - val_loss: 0.2470 - val_mean_squared_error: 0.2470 - val_mean_absolute_error: 0.4542 - val_mean_absolute_percentage_error: 60.0748 - val_cosine_proximity: 0.9636
Epoch 40/40









9/9 [==============================] - 32s 4s/step - loss: 0.3124 - mean_squared_error: 0.3124 - mean_absolute_error: 0.4673 - mean_absolute_percentage_error: 63.7553 - cosine_proximity: 0.6785 - val_loss: 0.2433 - val_mean_squared_error: 0.2433 - val_mean_absolute_error: 0.4501 - val_mean_absolute_percentage_error: 59.4580 - val_cosine_proximity: 0.9636
Positional Embedding Return Value
Tensor("transformer/positional_embedding_31/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_20/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_20/layer_normalization_73/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_20/sequential_31/dense_63/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_20/layer_normalization_74/add:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_23/positional_embedding_32/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_23/transformer_decoder_11/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_23/transformer_decoder_11/multi_head_attention_43/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_75/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_23/transformer_decoder_11/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer/model_23/transformer_decoder_11/layer_normalization_77/add:0", shape=(None, 200, 1), dtype=float32)
******dsadsdas
Tensor("positional_embedding_33/dense_66/Tanh:0", shape=(None, 60), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_33/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_33/add_1:0', description="created by layer 'positional_embedding_33'")
Encoder reshaped inputs
Tensor("transformer_encoder_21/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_21/layer_normalization_78/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_21/sequential_33/dense_68/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_21/layer_normalization_79/add:0", shape=(None, 200, 1), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_24/Reshape:0', description="created by layer 'flatten_24'")
******dsadsdas
Tensor("positional_embedding_34/dense_69/Tanh:0", shape=(None, 60), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_34/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_34/add_1:0', description="created by layer 'positional_embedding_34'")
Decoder Inputs:
Tensor("transformer_decoder_12/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_12/multi_head_attention_46/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_12/layer_normalization_80/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_12/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_12/layer_normalization_82/add:0", shape=(None, 200, 1), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_25/Reshape:0', description="created by layer 'flatten_25'")
******dsadsdas
Tensor("model_25/positional_embedding_34/dense_69/Tanh:0", shape=(None, 60), dtype=float32)
Positional Embedding Return Value
Tensor("model_25/positional_embedding_34/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_25/transformer_decoder_12/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("model_25/transformer_decoder_12/multi_head_attention_46/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("model_25/transformer_decoder_12/layer_normalization_80/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("model_25/transformer_decoder_12/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("model_25/transformer_decoder_12/layer_normalization_82/add:0", shape=(None, 200, 1), dtype=float32)
******dsadsdas
Tensor("positional_embedding_36/sequential_35/reshape/Reshape:0", shape=(None, 200, 60), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_36/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_36/add_1:0', description="created by layer 'positional_embedding_36'")
Encoder reshaped inputs
Tensor("transformer_encoder_22/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_22/layer_normalization_83/add:0", shape=(None, 200, 1), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_22/sequential_36/dense_75/BiasAdd:0", shape=(None, 200, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_22/layer_normalization_84/add:0", shape=(None, 200, 1), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_26/Reshape:0', description="created by layer 'flatten_26'")
******dsadsdas
Tensor("positional_embedding_37/sequential_37/reshape_1/Reshape:0", shape=(None, 200, 60), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_37/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_37/add_1:0', description="created by layer 'positional_embedding_37'")
Decoder Inputs:
Tensor("transformer_decoder_13/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_13/multi_head_attention_49/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_13/layer_normalization_85/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_13/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_13/layer_normalization_87/add:0", shape=(None, 200, 1), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_27/Reshape:0', description="created by layer 'flatten_27'")
******dsadsdas
Tensor("model_27/positional_embedding_37/sequential_37/reshape_1/Reshape:0", shape=(None, 200, 60), dtype=float32)
Positional Embedding Return Value
Tensor("model_27/positional_embedding_37/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_27/transformer_decoder_13/strided_slice:0", shape=(None, 200, 1), dtype=float32)
Decoder attention_output_1
Tensor("model_27/transformer_decoder_13/multi_head_attention_49/attention_output/add:0", shape=(None, 200, 1), dtype=float32)
Decoder out_1
Tensor("model_27/transformer_decoder_13/layer_normalization_85/add:0", shape=(None, 200, 1), dtype=float32)
Decoder encoder_outputs
Tensor("model_27/transformer_decoder_13/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Decoder Shape
Tensor("model_27/transformer_decoder_13/layer_normalization_87/add:0", shape=(None, 200, 1), dtype=float32)
tf.Tensor(
[[ 0.00000000e+00  8.41470985e-01  9.09297427e-01 ...  7.95805843e-01
  -7.95785917e-02 -8.81798836e-01]
 [ 1.00000000e+00  5.97375325e-01 -2.86285442e-01 ...  4.44376523e-01
  -4.52969974e-01 -9.85562694e-01]
 [ 0.00000000e+00  7.61720408e-01  9.87046251e-01 ...  8.12815013e-01
   9.70346434e-01  4.44571293e-01]
 ...
 [ 1.00000000e+00  1.00000000e+00  1.00000000e+00 ...  1.00000000e+00
   1.00000000e+00  1.00000000e+00]
 [ 0.00000000e+00  1.15478198e-08  2.30956397e-08 ...  2.27492051e-06
   2.28646833e-06  2.29801615e-06]
 [ 1.00000000e+00  1.00000000e+00  1.00000000e+00 ...  1.00000000e+00
   1.00000000e+00  1.00000000e+00]], shape=(256, 200), dtype=float64)
******dsadsdas
Tensor("positional_embedding_38/sequential_39/reshape_2/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
(256, 200)
******dsadsdas
Tensor("positional_embedding_39/sequential_40/reshape_3/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
(200, 256)
******dsadsdas
Tensor("positional_embedding_41/sequential_42/reshape_5/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
(200, 256)
******dsadsdas
Tensor("positional_embedding_42/sequential_43/reshape_6/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_43/sequential_44/reshape_7/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_45/sequential_46/reshape_9/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_45/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_45/add_1:0', description="created by layer 'positional_embedding_45'")
Encoder reshaped inputs
Tensor("transformer_encoder_23/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_23/layer_normalization_88/add:0", shape=(None, 200, 1, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_23/sequential_47/dense_88/BiasAdd:0", shape=(None, 200, 1, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_23/layer_normalization_89/add:0", shape=(None, 200, 1, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_28/Reshape:0', description="created by layer 'flatten_28'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_46/sequential_48/reshape_10/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_46/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_46/add_1:0', description="created by layer 'positional_embedding_46'")
Encoder reshaped inputs
Tensor("transformer_encoder_24/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_24/layer_normalization_90/add:0", shape=(None, 200, 1, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_24/sequential_49/dense_91/BiasAdd:0", shape=(None, 200, 1, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_24/layer_normalization_91/add:0", shape=(None, 200, 1, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_29/Reshape:0', description="created by layer 'flatten_29'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_47/sequential_50/reshape_11/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_47/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_47/add_1:0', description="created by layer 'positional_embedding_47'")
Decoder Inputs:
Tensor("transformer_decoder_14/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_14/multi_head_attention_53/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_14/layer_normalization_92/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_14/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_48/sequential_52/reshape_12/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_48/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_48/add_1:0', description="created by layer 'positional_embedding_48'")
Encoder reshaped inputs
Tensor("transformer_encoder_25/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_25/layer_normalization_95/add:0", shape=(None, 200, 1, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_25/sequential_53/dense_97/BiasAdd:0", shape=(None, 200, 1, 1), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_25/layer_normalization_96/add:0", shape=(None, 200, 1, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_30/Reshape:0', description="created by layer 'flatten_30'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_49/sequential_54/reshape_13/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_49/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_49/add_1:0', description="created by layer 'positional_embedding_49'")
Decoder Inputs:
Tensor("transformer_decoder_15/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_15/multi_head_attention_56/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_15/layer_normalization_97/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_15/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_50/sequential_56/reshape_14/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_50/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_50/add_1:0', description="created by layer 'positional_embedding_50'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_26/layer_normalization_100/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_26/sequential_57/dense_103/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_26/layer_normalization_101/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_31/Reshape:0', description="created by layer 'flatten_31'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_51/sequential_58/reshape_15/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_51/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_51/add_1:0', description="created by layer 'positional_embedding_51'")
Decoder Inputs:
Tensor("transformer_decoder_16/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_16/multi_head_attention_59/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_16/layer_normalization_102/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_16/strided_slice_1:0", shape=(None, 200, 1), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_52/sequential_60/reshape_16/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_52/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_52/add_1:0', description="created by layer 'positional_embedding_52'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_27/layer_normalization_105/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_27/sequential_61/dense_109/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_27/layer_normalization_106/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_32/Reshape:0', description="created by layer 'flatten_32'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_53/sequential_62/reshape_17/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_53/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_53/add_1:0', description="created by layer 'positional_embedding_53'")
Decoder Inputs:
Tensor("transformer_decoder_17/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_17/multi_head_attention_62/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_17/layer_normalization_107/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_17/strided_slice_1:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_17/layer_normalization_109/add:0", shape=(None, 200, 1, 256), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_33/Reshape:0', description="created by layer 'flatten_33'")
WARNING:tensorflow:Model was constructed with shape (None, 200, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'"), but it was called on an input with incompatible shape (None, 51200).
Positional Embedding dense projection of inputs:
Tensor("model_33/positional_embedding_53/sequential_62/reshape_17/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("model_33/positional_embedding_53/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("model_33/transformer_decoder_17/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("model_33/transformer_decoder_17/multi_head_attention_62/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("model_33/transformer_decoder_17/layer_normalization_107/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("model_33/transformer_decoder_17/strided_slice_1:0", shape=(None, 51200, 1), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_54/sequential_64/reshape_18/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_54/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_54/add_1:0', description="created by layer 'positional_embedding_54'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_28/layer_normalization_110/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_28/sequential_65/dense_115/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_28/layer_normalization_111/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name=None), name='transformer_encoder_28/layer_normalization_111/add_1:0', description="created by layer 'transformer_encoder_28'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_55/sequential_66/reshape_19/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_55/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_55/add_1:0', description="created by layer 'positional_embedding_55'")
Decoder Inputs:
Tensor("transformer_decoder_18/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_18/multi_head_attention_65/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_18/layer_normalization_112/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_18/strided_slice_1:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_18/layer_normalization_114/add:0", shape=(None, 200, 1, 256), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_34/Reshape:0', description="created by layer 'flatten_34'")
Positional Embedding dense projection of inputs:
Tensor("model_35/positional_embedding_55/sequential_66/reshape_19/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("model_35/positional_embedding_55/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("model_35/transformer_decoder_18/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("model_35/transformer_decoder_18/multi_head_attention_65/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("model_35/transformer_decoder_18/layer_normalization_112/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("model_35/transformer_decoder_18/strided_slice_1:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder Shape
Tensor("model_35/transformer_decoder_18/layer_normalization_114/add:0", shape=(None, 200, 1, 256), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_54 (Positi (None, 200, 256)     10291200    encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_28 (Transfo (None, 200, 256)     2695360     positional_embedding_54[0][0]
__________________________________________________________________________________________________
model_35 (Functional)           (None, 51200)        14108033    decoder_inputs[0][0]
                                                                 transformer_encoder_28[0][0]
==================================================================================================
Total params: 27,094,593
Trainable params: 27,094,593
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_54/sequential_64/reshape_18/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_54/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_28/layer_normalization_110/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_28/sequential_65/dense_115/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_28/layer_normalization_111/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_35/positional_embedding_55/sequential_66/reshape_19/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_35/positional_embedding_55/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_35/transformer_decoder_18/strided_slice:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_35/transformer_decoder_18/multi_head_attention_65/attention_output/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_35/transformer_decoder_18/layer_normalization_112/add:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_35/transformer_decoder_18/strided_slice_1:0", shape=(None, 200, 1, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_35/transformer_decoder_18/layer_normalization_114/add:0", shape=(None, 200, 1, 256), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_56/sequential_68/reshape_20/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_56/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_56/add_1:0', description="created by layer 'positional_embedding_56'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_29/layer_normalization_115/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_29/sequential_69/dense_121/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_29/layer_normalization_116/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name=None), name='transformer_encoder_29/layer_normalization_116/add_1:0', description="created by layer 'transformer_encoder_29'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_57/sequential_70/reshape_21/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_57/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_57/add_1:0', description="created by layer 'positional_embedding_57'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_58/sequential_71/reshape_22/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_58/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_58/add_1:0', description="created by layer 'positional_embedding_58'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_30/layer_normalization_117/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_30/sequential_72/dense_125/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_30/layer_normalization_118/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name=None), name='transformer_encoder_30/layer_normalization_118/add_1:0', description="created by layer 'transformer_encoder_30'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_59/sequential_73/reshape_23/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_59/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_59/add_1:0', description="created by layer 'positional_embedding_59'")
Decoder Inputs:
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_19/multi_head_attention_69/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_19/layer_normalization_119/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_19/layer_normalization_121/add:0", shape=(None, 200, 256), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 51200), dtype=tf.float32, name=None), name='flatten_35/Reshape:0', description="created by layer 'flatten_35'")
Positional Embedding dense projection of inputs:
Tensor("model_38/positional_embedding_59/sequential_73/reshape_23/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("model_38/positional_embedding_59/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("model_38/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("model_38/transformer_decoder_19/multi_head_attention_69/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("model_38/transformer_decoder_19/layer_normalization_119/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("model_38/transformer_decoder_19/layer_normalization_121/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_60/sequential_75/reshape_24/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_60/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_60/add_1:0', description="created by layer 'positional_embedding_60'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_31/layer_normalization_122/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_31/sequential_76/dense_131/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_31/layer_normalization_123/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name=None), name='transformer_encoder_31/layer_normalization_123/add_1:0', description="created by layer 'transformer_encoder_31'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_61/sequential_77/reshape_25/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_61/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_61/add_1:0', description="created by layer 'positional_embedding_61'")
Decoder Inputs:
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_20/multi_head_attention_72/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_20/layer_normalization_124/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_20/layer_normalization_126/add:0", shape=(None, 200, 256), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_135/BiasAdd:0', description="created by layer 'dense_135'")
Positional Embedding dense projection of inputs:
Tensor("model_40/positional_embedding_61/sequential_77/reshape_25/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("model_40/positional_embedding_61/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("model_40/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("model_40/transformer_decoder_20/multi_head_attention_72/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("model_40/transformer_decoder_20/layer_normalization_124/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("model_40/transformer_decoder_20/layer_normalization_126/add:0", shape=(None, 200, 256), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_60 (Positi (None, 200, 256)     10291200    encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_31 (Transfo (None, 200, 256)     2695360     positional_embedding_60[0][0]
__________________________________________________________________________________________________
model_40 (Functional)           (None, 200)          25790920    decoder_inputs[0][0]
                                                                 transformer_encoder_31[0][0]
==================================================================================================
Total params: 38,777,480
Trainable params: 38,777,480
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_60/sequential_75/reshape_24/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_60/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_31/layer_normalization_122/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_31/sequential_76/dense_131/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_40/positional_embedding_61/sequential_77/reshape_25/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_40/positional_embedding_61/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_40/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_40/transformer_decoder_20/multi_head_attention_72/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_124/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_126/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_60/sequential_75/reshape_24/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_60/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_31/layer_normalization_122/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_31/sequential_76/dense_131/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_40/positional_embedding_61/sequential_77/reshape_25/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_40/positional_embedding_61/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_40/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_40/transformer_decoder_20/multi_head_attention_72/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_124/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_126/add:0", shape=(None, 200, 256), dtype=float32)







9/9 [==============================] - ETA: 0s - loss: 303.4809 - mean_squared_error: 303.4809 - mean_absolute_error: 12.9223 - mean_absolute_percentage_error: 1985.2251 - cosine_proximity: 0.0656Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_60/sequential_75/reshape_24/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_60/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_31/layer_normalization_122/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_31/sequential_76/dense_131/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_40/positional_embedding_61/sequential_77/reshape_25/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_40/positional_embedding_61/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_40/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_40/transformer_decoder_20/multi_head_attention_72/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_124/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_126/add:0", shape=(None, 200, 256), dtype=float32)
9/9 [==============================] - 66s 7s/step - loss: 301.1535 - mean_squared_error: 301.1535 - mean_absolute_error: 12.9662 - mean_absolute_percentage_error: 1991.1560 - cosine_proximity: 0.0682 - val_loss: 5.6288 - val_mean_squared_error: 5.6288 - val_mean_absolute_error: 1.2987 - val_mean_absolute_percentage_error: 192.0577 - val_cosine_proximity: 0.0216
Epoch 2/40








9/9 [==============================] - 347s 42s/step - loss: 75.3430 - mean_squared_error: 75.3430 - mean_absolute_error: 6.9749 - mean_absolute_percentage_error: 1070.1156 - cosine_proximity: 0.0811 - val_loss: 19.9851 - val_mean_squared_error: 19.9851 - val_mean_absolute_error: 4.1048 - val_mean_absolute_percentage_error: 623.2211 - val_cosine_proximity: -0.3477
Epoch 3/40








9/9 [==============================] - 63s 7s/step - loss: 33.3145 - mean_squared_error: 33.3145 - mean_absolute_error: 5.1334 - mean_absolute_percentage_error: 786.2097 - cosine_proximity: -0.0298 - val_loss: 2.1239 - val_mean_squared_error: 2.1239 - val_mean_absolute_error: 1.1313 - val_mean_absolute_percentage_error: 167.0173 - val_cosine_proximity: -0.0601
Epoch 4/40








9/9 [==============================] - 60s 7s/step - loss: 11.7785 - mean_squared_error: 11.7785 - mean_absolute_error: 2.8434 - mean_absolute_percentage_error: 434.0263 - cosine_proximity: -0.0048 - val_loss: 2.1550 - val_mean_squared_error: 2.1550 - val_mean_absolute_error: 1.2283 - val_mean_absolute_percentage_error: 189.0846 - val_cosine_proximity: 0.5536
Epoch 5/40








9/9 [==============================] - 71s 8s/step - loss: 5.6658 - mean_squared_error: 5.6658 - mean_absolute_error: 1.9417 - mean_absolute_percentage_error: 296.7510 - cosine_proximity: 0.1798 - val_loss: 1.7613 - val_mean_squared_error: 1.7613 - val_mean_absolute_error: 1.1827 - val_mean_absolute_percentage_error: 182.5861 - val_cosine_proximity: 0.7002
Epoch 6/40








9/9 [==============================] - 71s 8s/step - loss: 3.6416 - mean_squared_error: 3.6416 - mean_absolute_error: 1.5391 - mean_absolute_percentage_error: 235.9737 - cosine_proximity: 0.3203 - val_loss: 0.9384 - val_mean_squared_error: 0.9384 - val_mean_absolute_error: 0.8271 - val_mean_absolute_percentage_error: 128.7886 - val_cosine_proximity: 0.7769
Epoch 7/40








9/9 [==============================] - 67s 8s/step - loss: 2.8483 - mean_squared_error: 2.8483 - mean_absolute_error: 1.3515 - mean_absolute_percentage_error: 207.7211 - cosine_proximity: 0.3911 - val_loss: 0.3495 - val_mean_squared_error: 0.3495 - val_mean_absolute_error: 0.4655 - val_mean_absolute_percentage_error: 74.3967 - val_cosine_proximity: 0.8627
Epoch 8/40








9/9 [==============================] - 67s 8s/step - loss: 2.3614 - mean_squared_error: 2.3614 - mean_absolute_error: 1.2278 - mean_absolute_percentage_error: 188.3585 - cosine_proximity: 0.4209 - val_loss: 0.1972 - val_mean_squared_error: 0.1972 - val_mean_absolute_error: 0.3437 - val_mean_absolute_percentage_error: 54.8882 - val_cosine_proximity: 0.8802
Epoch 9/40
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Can't save model, h5py returned error: Layer TransformerEncoder has arguments in `__init__` and therefore must override `get_config`.








9/9 [==============================] - 85s 10s/step - loss: 2.1807 - mean_squared_error: 2.1807 - mean_absolute_error: 1.1788 - mean_absolute_percentage_error: 180.9624 - cosine_proximity: 0.4289 - val_loss: 0.2025 - val_mean_squared_error: 0.2025 - val_mean_absolute_error: 0.3591 - val_mean_absolute_percentage_error: 55.9733 - val_cosine_proximity: 0.8547
Epoch 10/40








9/9 [==============================] - 74s 8s/step - loss: 2.1216 - mean_squared_error: 2.1216 - mean_absolute_error: 1.1603 - mean_absolute_percentage_error: 177.9258 - cosine_proximity: 0.4302 - val_loss: 0.2346 - val_mean_squared_error: 0.2346 - val_mean_absolute_error: 0.3897 - val_mean_absolute_percentage_error: 60.0678 - val_cosine_proximity: 0.8296
Epoch 11/40








9/9 [==============================] - 74s 8s/step - loss: 2.1101 - mean_squared_error: 2.1101 - mean_absolute_error: 1.1582 - mean_absolute_percentage_error: 177.8778 - cosine_proximity: 0.4312 - val_loss: 0.2102 - val_mean_squared_error: 0.2102 - val_mean_absolute_error: 0.3711 - val_mean_absolute_percentage_error: 57.5082 - val_cosine_proximity: 0.8485
Epoch 12/40








9/9 [==============================] - 70s 8s/step - loss: 2.0719 - mean_squared_error: 2.0719 - mean_absolute_error: 1.1501 - mean_absolute_percentage_error: 176.5204 - cosine_proximity: 0.4358 - val_loss: 0.1935 - val_mean_squared_error: 0.1935 - val_mean_absolute_error: 0.3585 - val_mean_absolute_percentage_error: 56.1343 - val_cosine_proximity: 0.8640
Epoch 13/40








9/9 [==============================] - 72s 8s/step - loss: 2.0150 - mean_squared_error: 2.0150 - mean_absolute_error: 1.1323 - mean_absolute_percentage_error: 173.8828 - cosine_proximity: 0.4429 - val_loss: 0.2033 - val_mean_squared_error: 0.2033 - val_mean_absolute_error: 0.3657 - val_mean_absolute_percentage_error: 57.3042 - val_cosine_proximity: 0.8617
Epoch 14/40








9/9 [==============================] - 73s 8s/step - loss: 2.0429 - mean_squared_error: 2.0429 - mean_absolute_error: 1.1410 - mean_absolute_percentage_error: 175.3748 - cosine_proximity: 0.4429 - val_loss: 0.1818 - val_mean_squared_error: 0.1818 - val_mean_absolute_error: 0.3467 - val_mean_absolute_percentage_error: 54.0726 - val_cosine_proximity: 0.8691
Epoch 15/40








9/9 [==============================] - 88s 10s/step - loss: 1.9984 - mean_squared_error: 1.9984 - mean_absolute_error: 1.1286 - mean_absolute_percentage_error: 173.1343 - cosine_proximity: 0.4395 - val_loss: 0.1477 - val_mean_squared_error: 0.1477 - val_mean_absolute_error: 0.3090 - val_mean_absolute_percentage_error: 47.5621 - val_cosine_proximity: 0.8761
Epoch 16/40








9/9 [==============================] - 78s 9s/step - loss: 1.9759 - mean_squared_error: 1.9759 - mean_absolute_error: 1.1201 - mean_absolute_percentage_error: 171.7643 - cosine_proximity: 0.4357 - val_loss: 0.1582 - val_mean_squared_error: 0.1582 - val_mean_absolute_error: 0.3197 - val_mean_absolute_percentage_error: 47.9771 - val_cosine_proximity: 0.8594
Epoch 17/40








9/9 [==============================] - 84s 9s/step - loss: 1.9545 - mean_squared_error: 1.9545 - mean_absolute_error: 1.1154 - mean_absolute_percentage_error: 170.9203 - cosine_proximity: 0.4333 - val_loss: 0.1654 - val_mean_squared_error: 0.1654 - val_mean_absolute_error: 0.3291 - val_mean_absolute_percentage_error: 50.1084 - val_cosine_proximity: 0.8581
Epoch 18/40








9/9 [==============================] - 73s 8s/step - loss: 1.9344 - mean_squared_error: 1.9344 - mean_absolute_error: 1.1102 - mean_absolute_percentage_error: 170.3443 - cosine_proximity: 0.4403 - val_loss: 0.1605 - val_mean_squared_error: 0.1605 - val_mean_absolute_error: 0.3222 - val_mean_absolute_percentage_error: 49.8272 - val_cosine_proximity: 0.8637
Epoch 19/40








9/9 [==============================] - 73s 8s/step - loss: 1.9403 - mean_squared_error: 1.9403 - mean_absolute_error: 1.1121 - mean_absolute_percentage_error: 170.4552 - cosine_proximity: 0.4431 - val_loss: 0.1722 - val_mean_squared_error: 0.1722 - val_mean_absolute_error: 0.3352 - val_mean_absolute_percentage_error: 52.1896 - val_cosine_proximity: 0.8703
Epoch 20/40








9/9 [==============================] - 73s 8s/step - loss: 1.8990 - mean_squared_error: 1.8990 - mean_absolute_error: 1.0999 - mean_absolute_percentage_error: 168.9220 - cosine_proximity: 0.4539 - val_loss: 0.1807 - val_mean_squared_error: 0.1807 - val_mean_absolute_error: 0.3403 - val_mean_absolute_percentage_error: 53.5614 - val_cosine_proximity: 0.8700
Epoch 21/40








9/9 [==============================] - 73s 8s/step - loss: 1.8818 - mean_squared_error: 1.8818 - mean_absolute_error: 1.0935 - mean_absolute_percentage_error: 167.9665 - cosine_proximity: 0.4550 - val_loss: 0.1781 - val_mean_squared_error: 0.1781 - val_mean_absolute_error: 0.3375 - val_mean_absolute_percentage_error: 51.3915 - val_cosine_proximity: 0.8454
Epoch 22/40








9/9 [==============================] - 71s 8s/step - loss: 1.8917 - mean_squared_error: 1.8917 - mean_absolute_error: 1.0967 - mean_absolute_percentage_error: 168.0848 - cosine_proximity: 0.4412 - val_loss: 0.1847 - val_mean_squared_error: 0.1847 - val_mean_absolute_error: 0.3486 - val_mean_absolute_percentage_error: 54.1952 - val_cosine_proximity: 0.8669
Epoch 23/40








9/9 [==============================] - 75s 8s/step - loss: 1.8667 - mean_squared_error: 1.8667 - mean_absolute_error: 1.0903 - mean_absolute_percentage_error: 167.2422 - cosine_proximity: 0.4552 - val_loss: 0.1955 - val_mean_squared_error: 0.1955 - val_mean_absolute_error: 0.3523 - val_mean_absolute_percentage_error: 53.8297 - val_cosine_proximity: 0.8434
Epoch 24/40








9/9 [==============================] - 67s 8s/step - loss: 1.8511 - mean_squared_error: 1.8511 - mean_absolute_error: 1.0854 - mean_absolute_percentage_error: 166.4598 - cosine_proximity: 0.4495 - val_loss: 0.1927 - val_mean_squared_error: 0.1927 - val_mean_absolute_error: 0.3481 - val_mean_absolute_percentage_error: 53.3209 - val_cosine_proximity: 0.8463
Epoch 25/40








9/9 [==============================] - 70s 8s/step - loss: 1.8471 - mean_squared_error: 1.8471 - mean_absolute_error: 1.0833 - mean_absolute_percentage_error: 166.2891 - cosine_proximity: 0.4550 - val_loss: 0.1817 - val_mean_squared_error: 0.1817 - val_mean_absolute_error: 0.3443 - val_mean_absolute_percentage_error: 52.3430 - val_cosine_proximity: 0.8498
Epoch 26/40








9/9 [==============================] - 68s 8s/step - loss: 1.8289 - mean_squared_error: 1.8289 - mean_absolute_error: 1.0769 - mean_absolute_percentage_error: 165.1169 - cosine_proximity: 0.4496 - val_loss: 0.1931 - val_mean_squared_error: 0.1931 - val_mean_absolute_error: 0.3510 - val_mean_absolute_percentage_error: 55.3420 - val_cosine_proximity: 0.8629
Epoch 27/40








9/9 [==============================] - 66s 7s/step - loss: 1.7944 - mean_squared_error: 1.7944 - mean_absolute_error: 1.0684 - mean_absolute_percentage_error: 164.2346 - cosine_proximity: 0.4661 - val_loss: 0.1745 - val_mean_squared_error: 0.1745 - val_mean_absolute_error: 0.3350 - val_mean_absolute_percentage_error: 51.4006 - val_cosine_proximity: 0.8594
Epoch 28/40








9/9 [==============================] - 66s 7s/step - loss: 1.7783 - mean_squared_error: 1.7783 - mean_absolute_error: 1.0645 - mean_absolute_percentage_error: 162.9741 - cosine_proximity: 0.4584 - val_loss: 0.1922 - val_mean_squared_error: 0.1922 - val_mean_absolute_error: 0.3482 - val_mean_absolute_percentage_error: 53.7441 - val_cosine_proximity: 0.8518
Epoch 29/40








9/9 [==============================] - 66s 7s/step - loss: 1.7755 - mean_squared_error: 1.7755 - mean_absolute_error: 1.0642 - mean_absolute_percentage_error: 163.2533 - cosine_proximity: 0.4672 - val_loss: 0.1808 - val_mean_squared_error: 0.1808 - val_mean_absolute_error: 0.3433 - val_mean_absolute_percentage_error: 53.7276 - val_cosine_proximity: 0.8644
Epoch 30/40








9/9 [==============================] - 65s 7s/step - loss: 1.7520 - mean_squared_error: 1.7520 - mean_absolute_error: 1.0546 - mean_absolute_percentage_error: 161.7534 - cosine_proximity: 0.4620 - val_loss: 0.1805 - val_mean_squared_error: 0.1805 - val_mean_absolute_error: 0.3419 - val_mean_absolute_percentage_error: 52.7017 - val_cosine_proximity: 0.8550
Epoch 31/40








9/9 [==============================] - 66s 7s/step - loss: 1.7435 - mean_squared_error: 1.7435 - mean_absolute_error: 1.0549 - mean_absolute_percentage_error: 162.1794 - cosine_proximity: 0.4677 - val_loss: 0.2297 - val_mean_squared_error: 0.2297 - val_mean_absolute_error: 0.3851 - val_mean_absolute_percentage_error: 58.9416 - val_cosine_proximity: 0.8236
Epoch 32/40








9/9 [==============================] - 69s 8s/step - loss: 1.7264 - mean_squared_error: 1.7264 - mean_absolute_error: 1.0478 - mean_absolute_percentage_error: 160.9722 - cosine_proximity: 0.4615 - val_loss: 0.2362 - val_mean_squared_error: 0.2362 - val_mean_absolute_error: 0.3948 - val_mean_absolute_percentage_error: 59.6451 - val_cosine_proximity: 0.8127
Epoch 33/40








9/9 [==============================] - 66s 7s/step - loss: 1.7249 - mean_squared_error: 1.7249 - mean_absolute_error: 1.0472 - mean_absolute_percentage_error: 160.4777 - cosine_proximity: 0.4674 - val_loss: 0.1806 - val_mean_squared_error: 0.1806 - val_mean_absolute_error: 0.3408 - val_mean_absolute_percentage_error: 52.8094 - val_cosine_proximity: 0.8572
Epoch 34/40








9/9 [==============================] - 66s 7s/step - loss: 1.6618 - mean_squared_error: 1.6618 - mean_absolute_error: 1.0281 - mean_absolute_percentage_error: 157.5906 - cosine_proximity: 0.4700 - val_loss: 0.2090 - val_mean_squared_error: 0.2090 - val_mean_absolute_error: 0.3650 - val_mean_absolute_percentage_error: 55.7629 - val_cosine_proximity: 0.8417
Epoch 35/40








9/9 [==============================] - 67s 7s/step - loss: 1.6600 - mean_squared_error: 1.6600 - mean_absolute_error: 1.0284 - mean_absolute_percentage_error: 157.9159 - cosine_proximity: 0.4739 - val_loss: 0.1860 - val_mean_squared_error: 0.1860 - val_mean_absolute_error: 0.3487 - val_mean_absolute_percentage_error: 52.8269 - val_cosine_proximity: 0.8472
Epoch 36/40








9/9 [==============================] - 68s 8s/step - loss: 1.6172 - mean_squared_error: 1.6172 - mean_absolute_error: 1.0142 - mean_absolute_percentage_error: 155.4043 - cosine_proximity: 0.4730 - val_loss: 0.1918 - val_mean_squared_error: 0.1918 - val_mean_absolute_error: 0.3554 - val_mean_absolute_percentage_error: 54.4125 - val_cosine_proximity: 0.8495
Epoch 37/40








9/9 [==============================] - 64s 7s/step - loss: 1.6061 - mean_squared_error: 1.6061 - mean_absolute_error: 1.0099 - mean_absolute_percentage_error: 155.0527 - cosine_proximity: 0.4796 - val_loss: 0.2050 - val_mean_squared_error: 0.2050 - val_mean_absolute_error: 0.3603 - val_mean_absolute_percentage_error: 55.4374 - val_cosine_proximity: 0.8473
Epoch 38/40








9/9 [==============================] - 67s 7s/step - loss: 1.5844 - mean_squared_error: 1.5844 - mean_absolute_error: 1.0036 - mean_absolute_percentage_error: 154.1577 - cosine_proximity: 0.4845 - val_loss: 0.2057 - val_mean_squared_error: 0.2057 - val_mean_absolute_error: 0.3644 - val_mean_absolute_percentage_error: 55.9887 - val_cosine_proximity: 0.8410
Epoch 39/40








9/9 [==============================] - 60s 7s/step - loss: 1.5712 - mean_squared_error: 1.5712 - mean_absolute_error: 1.0001 - mean_absolute_percentage_error: 153.5065 - cosine_proximity: 0.4815 - val_loss: 0.2207 - val_mean_squared_error: 0.2207 - val_mean_absolute_error: 0.3774 - val_mean_absolute_percentage_error: 58.5887 - val_cosine_proximity: 0.8446
Epoch 40/40









9/9 [==============================] - 66s 8s/step - loss: 1.5518 - mean_squared_error: 1.5518 - mean_absolute_error: 0.9952 - mean_absolute_percentage_error: 152.8049 - cosine_proximity: 0.4926 - val_loss: 0.2089 - val_mean_squared_error: 0.2089 - val_mean_absolute_error: 0.3678 - val_mean_absolute_percentage_error: 55.7856 - val_cosine_proximity: 0.8217
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_60/sequential_75/reshape_24/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_60/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_3:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_31/layer_normalization_122/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_31/sequential_76/dense_131/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_40/positional_embedding_61/sequential_77/reshape_25/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_40/positional_embedding_61/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_40/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_40/transformer_decoder_20/multi_head_attention_72/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_124/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_31/layer_normalization_123/add_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_40/transformer_decoder_20/layer_normalization_126/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_62/sequential_79/reshape_26/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_62/add:0", shape=(None, 200, 256), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_62/add_1:0', description="created by layer 'positional_embedding_62'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_32/layer_normalization_127/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_32/sequential_80/dense_138/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_32/layer_normalization_128/add:0", shape=(None, 200, 256), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name=None), name='transformer_encoder_32/layer_normalization_128/add_1:0', description="created by layer 'transformer_encoder_32'")
Positional Embedding Shape:
(200, 256)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_63/sequential_81/reshape_27/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_63/add:0", shape=(None, 200, 256), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 256), dtype=tf.float64, name=None), name='positional_embedding_63/add_1:0', description="created by layer 'positional_embedding_63'")
Decoder Inputs:
Tensor("Cast:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_21/multi_head_attention_75/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_21/layer_normalization_129/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_21/layer_normalization_131/add:0", shape=(None, 200, 256), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_142/BiasAdd:0', description="created by layer 'dense_142'")
Positional Embedding dense projection of inputs:
Tensor("model_42/positional_embedding_63/sequential_81/reshape_27/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("model_42/positional_embedding_63/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("model_42/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("model_42/transformer_decoder_21/multi_head_attention_75/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("model_42/transformer_decoder_21/layer_normalization_129/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("model_42/transformer_decoder_21/layer_normalization_131/add:0", shape=(None, 200, 256), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_62 (Positi (None, 200, 256)     10291200    encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_32 (Transfo (None, 200, 256)     17878528    positional_embedding_62[0][0]
__________________________________________________________________________________________________
model_42 (Functional)           (None, 200)          25790920    decoder_inputs[0][0]
                                                                 transformer_encoder_32[0][0]
==================================================================================================
Total params: 53,960,648
Trainable params: 53,960,648
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/4
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_62/sequential_79/reshape_26/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_62/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_32/layer_normalization_127/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_32/sequential_80/dense_138/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_32/layer_normalization_128/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_42/positional_embedding_63/sequential_81/reshape_27/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_42/positional_embedding_63/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_42/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_42/transformer_decoder_21/multi_head_attention_75/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_42/transformer_decoder_21/layer_normalization_129/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_32/layer_normalization_128/add_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_42/transformer_decoder_21/layer_normalization_131/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_62/sequential_79/reshape_26/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_62/add:0", shape=(None, 200, 256), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_32/layer_normalization_127/add:0", shape=(None, 200, 256), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_32/sequential_80/dense_138/BiasAdd:0", shape=(None, 200, 256), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_32/layer_normalization_128/add:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_42/positional_embedding_63/sequential_81/reshape_27/Reshape:0", shape=(None, 200, 256), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_42/positional_embedding_63/add:0", shape=(None, 200, 256), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_42/Cast_1:0", shape=(None, 200, 256), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_42/transformer_decoder_21/multi_head_attention_75/attention_output/add:0", shape=(None, 200, 256), dtype=float32)
Decoder out_1
Tensor("transformer/model_42/transformer_decoder_21/layer_normalization_129/add:0", shape=(None, 200, 256), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_32/layer_normalization_128/add_1:0", shape=(None, 200, 256), dtype=float32)
Decoder Shape
Tensor("transformer/model_42/transformer_decoder_21/layer_normalization_131/add:0", shape=(None, 200, 256), dtype=float32)
1/9 [==>...........................] - ETA: 4:42 - loss: 4.8610 - mean_squared_error: 4.8610 - mean_absolute_error: 1.7516 - mean_absolute_percentage_error: 266.4549 - cosine_proximity: -0.0270
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 388, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 114, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 378, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
1/9 [==>...........................] - ETA: 4:42 - loss: 4.8610 - mean_squared_error: 4.8610 - mean_absolute_error: 1.7516 - mean_absolute_percentage_error: 266.4549 - cosine_proximity: -0.0270Positional Embedding Shape:
(200, 32)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_64/sequential_83/reshape_28/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_64/add:0", shape=(None, 200, 32), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float64, name=None), name='positional_embedding_64/add_1:0', description="created by layer 'positional_embedding_64'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_33/layer_normalization_132/add:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_33/sequential_84/dense_145/BiasAdd:0", shape=(None, 200, 32), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_33/layer_normalization_133/add:0", shape=(None, 200, 32), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float32, name=None), name='transformer_encoder_33/layer_normalization_133/add_1:0', description="created by layer 'transformer_encoder_33'")
Positional Embedding Shape:
(200, 32)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_65/sequential_85/reshape_29/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_65/add:0", shape=(None, 200, 32), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float64, name=None), name='positional_embedding_65/add_1:0', description="created by layer 'positional_embedding_65'")
Decoder Inputs:
Tensor("Cast:0", shape=(None, 200, 32), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_22/multi_head_attention_78/attention_output/add:0", shape=(None, 200, 32), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_22/layer_normalization_134/add:0", shape=(None, 200, 32), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 32), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_22/layer_normalization_136/add:0", shape=(None, 200, 32), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_149/BiasAdd:0', description="created by layer 'dense_149'")
Positional Embedding dense projection of inputs:
Tensor("model_44/positional_embedding_65/sequential_85/reshape_29/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("model_44/positional_embedding_65/add:0", shape=(None, 200, 32), dtype=float64)
Decoder Inputs:
Tensor("model_44/Cast_1:0", shape=(None, 200, 32), dtype=float32)
Decoder attention_output_1
Tensor("model_44/transformer_decoder_22/multi_head_attention_78/attention_output/add:0", shape=(None, 200, 32), dtype=float32)
Decoder out_1
Tensor("model_44/transformer_decoder_22/layer_normalization_134/add:0", shape=(None, 200, 32), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 32), dtype=float32)
Decoder Shape
Tensor("model_44/transformer_decoder_22/layer_normalization_136/add:0", shape=(None, 200, 32), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_64 (Positi (None, 200, 32)      1286400     encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_33 (Transfo (None, 200, 32)      2279616     positional_embedding_64[0][0]
__________________________________________________________________________________________________
model_44 (Functional)           (None, 200)          2767080     decoder_inputs[0][0]
                                                                 transformer_encoder_33[0][0]
==================================================================================================
Total params: 6,333,096
Trainable params: 6,333,096
Non-trainable params: 0
__________________________________________________________________________________________________