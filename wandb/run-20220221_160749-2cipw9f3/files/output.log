Shape surrogate pairs: (800, 2, 201)
Shape surrogate quadrupels: (800, 4, 201)
800 total pairs
560 training pairs
120 validation pairs
120 test pairs
(560, 201)
(560, 201)
(120, 201)
(120, 201)
inputs["encoder_inputs"].shape: (48, 200)
inputs["decoder_inputs"].shape: (48, 200)
targets.shape: (48, 200)
Positional Embedding Return Value
Tensor("positional_embedding/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding/add_1:0', description="created by layer 'positional_embedding'")
Encoder reshaped inputs
Tensor("transformer_encoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder/layer_normalization/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder/sequential/dense_1/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder/layer_normalization_1/add:0", shape=(None, 1, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten/Reshape:0', description="created by layer 'flatten'")
Positional Embedding Return Value
Tensor("positional_embedding_1/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_1/add_1:0', description="created by layer 'positional_embedding_1'")
Decoder Inputs:
Tensor("transformer_decoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder/multi_head_attention_1/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder/layer_normalization_2/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder/layer_normalization_4/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description="created by layer 'flatten_1'")
Positional Embedding Return Value
Tensor("model_1/positional_embedding_1/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_1/transformer_decoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_1/transformer_decoder/multi_head_attention_1/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_1/transformer_decoder/layer_normalization_2/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("model_1/transformer_decoder/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("model_1/transformer_decoder/layer_normalization_4/add:0", shape=(None, 1, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding (Positiona (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder (Transforme (None, 1, 200)       2107248     positional_embedding[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten (Flatten)               (None, 200)          0           transformer_encoder[0][0]
__________________________________________________________________________________________________
model_1 (Functional)            (None, 200)          3392648     decoder_inputs[0][0]
                                                                 flatten[0][0]
==================================================================================================
Total params: 5,499,896
Trainable params: 5,499,896
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder/layer_normalization/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder/sequential/dense_1/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder/layer_normalization_1/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_1/positional_embedding_1/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_1/transformer_decoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_1/transformer_decoder/multi_head_attention_1/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_1/transformer_decoder/layer_normalization_2/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_1/transformer_decoder/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_1/transformer_decoder/layer_normalization_4/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder/layer_normalization/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder/sequential/dense_1/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder/layer_normalization_1/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_1/positional_embedding_1/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_1/transformer_decoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_1/transformer_decoder/multi_head_attention_1/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_1/transformer_decoder/layer_normalization_2/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_1/transformer_decoder/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_1/transformer_decoder/layer_normalization_4/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - ETA: 0s - loss: 2.3972 - mean_squared_error: 2.3972 - mean_absolute_error: 1.1677 - mean_absolute_percentage_error: 178.6898 - cosine_proximity: 0.0715
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Can't save model, h5py returned error: Layer TransformerEncoder has arguments in `__init__` and therefore must override `get_config`.
Positional Embedding Return Value
Tensor("transformer/positional_embedding/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder/layer_normalization/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder/sequential/dense_1/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder/layer_normalization_1/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_1/positional_embedding_1/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_1/transformer_decoder/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_1/transformer_decoder/multi_head_attention_1/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_1/transformer_decoder/layer_normalization_2/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_1/transformer_decoder/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_1/transformer_decoder/layer_normalization_4/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - 4s 236ms/step - loss: 2.3900 - mean_squared_error: 2.3900 - mean_absolute_error: 1.1666 - mean_absolute_percentage_error: 178.7647 - cosine_proximity: 0.0746 - val_loss: 1.2116 - val_mean_squared_error: 1.2116 - val_mean_absolute_error: 0.8819 - val_mean_absolute_percentage_error: 153.6738 - val_cosine_proximity: 0.2221
Epoch 2/40
9/9 [==============================] - 1s 64ms/step - loss: 2.1821 - mean_squared_error: 2.1821 - mean_absolute_error: 1.1481 - mean_absolute_percentage_error: 184.4687 - cosine_proximity: 0.1551 - val_loss: 1.1805 - val_mean_squared_error: 1.1805 - val_mean_absolute_error: 0.8625 - val_mean_absolute_percentage_error: 152.6275 - val_cosine_proximity: 0.2351
Epoch 3/40
9/9 [==============================] - 0s 53ms/step - loss: 2.1275 - mean_squared_error: 2.1275 - mean_absolute_error: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
Epoch 4/40
9/9 [==============================] - 1s 63ms/step - loss: 2.0880 - mean_squared_error: 2.0880 - mean_absolute_error: 1.1393 - mean_absolute_percentage_error: 183.5480 - cosine_proximity: 0.1804 - val_loss: 1.1101 - val_mean_squared_error: 1.1101 - val_mean_absolute_error: 0.8470 - val_mean_absolute_percentage_error: 152.5255 - val_cosine_proximity: 0.2671
Epoch 5/40
9/9 [==============================] - 0s 49ms/step - loss: 2.0320 - mean_squared_error: 2.0320 - mean_absolute_error: 1.1323 - mean_absolute_percentage_error: 183.7711 - cosine_proximity: 0.1895 - val_loss: 1.0904 - val_mean_squared_error: 1.0904 - val_mean_absolute_error: 0.8399 - val_mean_absolute_percentage_error: 151.1392 - val_cosine_proximity: 0.2722
Epoch 6/40
9/9 [==============================] - 1s 78ms/step - loss: 1.9895 - mean_squared_error: 1.9895 - mean_absolute_error: 1.1290 - mean_absolute_percentage_error: 183.0323 - cosine_proximity: 0.1950 - val_loss: 1.0648 - val_mean_squared_error: 1.0648 - val_mean_absolute_error: 0.8365 - val_mean_absolute_percentage_error: 150.4667 - val_cosine_proximity: 0.2818
Epoch 7/40
1/9 [==>...........................] - ETA: 0s - loss: 1.9816 - mean_squared_error: 1.9816 - mean_absolute_error: 1.1295 - mean_absolute_percentage_error: 182.6429 - cosine_proximity: 0.1967
9/9 [==============================] - 0s 53ms/step - loss: 2.1275 - mean_squared_error: 2.1275 - mean_absolute_error: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
9/9 [==============================] - 0s 53ms/step - loss: 2.1275 - mean_squared_error: 2.1275 - mean_absolute_error: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
Decoder out_1former_encoder_1/layer_normalization_5/add:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
Encoder Shapeformer"encoder_1/layer_normalization_5/add:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
Tensor("transformer/transformer_encoder_1/layer_normalization_6/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_3/positional_embedding_3/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_3/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_3/transformer_decoder_1/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_3/transformer_decoder_1/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_3/transformer_decoder_1/concat:0", shape=(3,), dtype=int32)
Decoder Inputs:
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_5:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_3/transformer_decoder_1/multi_head_attention_4/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_7/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_9/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_inputr"encoder_1/layer_normalization_5/add:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
Tensor("transformer/transformer_encoder_1/layer_normalization_5/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_1/sequential_2/dense_5/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_1/layer_normalization_6/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_3/positional_embedding_3/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_3/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_3/transformer_decoder_1/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_3/transformer_decoder_1/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_3/transformer_decoder_1/concat:0", shape=(3,), dtype=int32)
Decoder Inputs:
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_5:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_3/transformer_decoder_1/multi_head_attention_4/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_7/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_9/add:0", shape=(None, 1, 200), dtype=float32)
5/9 [===============>..............] - ETA: 0s - loss: 2.4420 - mean_squared_error: 2.4420 - mean_absolute_error: 1.1722 - mean_absolute_percentage_error: 176.8770 - cosine_proximity: 0.0525
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_9/add:0", shape=(None, 1, 200), dtype=float32)r: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_1/layer_normalization_5/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_1/sequential_2/dense_5/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_1/layer_normalization_6/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_3/positional_embedding_3/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_3/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_3/transformer_decoder_1/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_3/transformer_decoder_1/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_3/transformer_decoder_1/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_3/transformer_decoder_1/concat:0", shape=(3,), dtype=int32)
Decoder Inputs:
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_5:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_3/transformer_decoder_1/multi_head_attention_4/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_7/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_3/transformer_decoder_1/layer_normalization_9/add:0", shape=(None, 1, 200), dtype=float32)r: 1.1442 - mean_absolute_percentage_error: 184.0230 - cosine_proximity: 0.1708 - val_loss: 1.1543 - val_mean_squared_error: 1.1543 - val_mean_absolute_error: 0.8660 - val_mean_absolute_percentage_error: 152.5440 - val_cosine_proximity: 0.2447
9/9 [==============================] - 3s 154ms/step - loss: 2.3981 - mean_squared_error: 2.3981 - mean_absolute_error: 1.1627 - mean_absolute_percentage_error: 177.3851 - cosine_proximity: 0.0724 - val_loss: 1.2320 - val_mean_squared_error: 1.2320 - val_mean_absolute_error: 0.8956 - val_mean_absolute_percentage_error: 153.8824 - val_cosine_proximity: 0.2081
Epoch 2/40
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 3/40
9/9 [==============================] - 0s 51ms/step - loss: 2.1249 - mean_squared_error: 2.1249 - mean_absolute_error: 1.1519 - mean_absolute_percentage_error: 185.7031 - cosine_proximity: 0.1727 - val_loss: 1.1323 - val_mean_squared_error: 1.1323 - val_mean_absolute_error: 0.8626 - val_mean_absolute_percentage_error: 154.4860 - val_cosine_proximity: 0.2596
Epoch 4/40
9/9 [==============================] - 1s 68ms/step - loss: 2.0640 - mean_squared_error: 2.0640 - mean_absolute_error: 1.1405 - mean_absolute_percentage_error: 184.8670 - cosine_proximity: 0.1862 - val_loss: 1.1105 - val_mean_squared_error: 1.1105 - val_mean_absolute_error: 0.8527 - val_mean_absolute_percentage_error: 153.0061 - val_cosine_proximity: 0.2661
Epoch 5/40
9/9 [==============================] - 1s 57ms/step - loss: 2.0415 - mean_squared_error: 2.0415 - mean_absolute_error: 1.1382 - mean_absolute_percentage_error: 184.5773 - cosine_proximity: 0.1910 - val_loss: 1.0876 - val_mean_squared_error: 1.0876 - val_mean_absolute_error: 0.8439 - val_mean_absolute_percentage_error: 151.8194 - val_cosine_proximity: 0.2739
Epoch 6/40
6/9 [===================>..........] - ETA: 0s - loss: 2.0064 - mean_squared_error: 2.0064 - mean_absolute_error: 1.1293 - mean_absolute_percentage_error: 183.3832 - cosine_proximity: 0.1873
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Can't save model, h5py returned error: Layer TransformerEncoder has arguments in `__init__` and therefore must override `get_config`.
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
9/9 [==============================] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Decoder attention_output_1=========] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Decoder attention_output_1=========] - 1s 78ms/step - loss: 2.1952 - mean_squared_error: 2.1952 - mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("transformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("transformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("transformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Can't save model, h5py returned error: Layer TransformerEncoder has arguments in `__init__` and therefore must override `get_config`.
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Epoch 4/100nsformer/transformer_encoder_1/strided_slice:0", shape=(None, 1, 200), dtype=float32)- mean_absolute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("transformer/model_3/transformer_decoder_1/strided_slice_5:0", shape=(None, 1, 200), dtype=float32)olute_error: 1.1615 - mean_absolute_percentage_error: 185.7405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("model_5/transformer_decoder_2/Cast:0", shape=(None, None), dtype=float64)er_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("model_5/transformer_decoder_2/Cast:0", shape=(None, None), dtype=float64)er_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Positional Embedding Return Value
Tensor("transformer/positional_embedding_4/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_2/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_2/layer_normalization_10/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_2/sequential_4/dense_9/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_2/layer_normalization_11/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_5/positional_embedding_5/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_5/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_5/transformer_decoder_2/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_5/transformer_decoder_2/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_5/transformer_decoder_2/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_5/transformer_decoder_2/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_5/transformer_decoder_2/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_5/transformer_decoder_2/concat:0", shape=(3,), dtype=int32)
Decoder Inputs:
Tensor("transformer/model_5/transformer_decoder_2/strided_slice_5:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_5/transformer_decoder_2/multi_head_attention_7/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_5/transformer_decoder_2/layer_normalization_12/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_5/transformer_decoder_2/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_5/transformer_decoder_2/layer_normalization_14/add:0", shape=(None, None, 200), dtype=float32)
Tensor("model_5/transformer_decoder_2/Cast:0", shape=(None, None), dtype=float64)er_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Positional Embedding Return Value
Tensor("positional_embedding_6/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_6/add_1:0', description="created by layer 'positional_embedding_6'")
Encoder reshaped inputs
Tensor("transformer_encoder_3/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_3/layer_normalization_15/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_3/sequential_6/dense_13/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("model_7/transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)er_inputs', description="created by layer 'decoder_inputs'")405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Tensor("transformer_decoder_3/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer_decoder_3/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer_decoder_3/concat:0", shape=(3,), dtype=int32)
Tensor("Placeholder_2:0", shape=(None, 200), dtype=bool)
Decoder Inputs:
Tensor("transformer_decoder_3/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_3/multi_head_attention_10/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_3/strided_slice_7:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_3/layer_normalization_19/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_7/Reshape:0', description="created by layer 'flatten_7'")
Positional Embedding Return Value
Tensor("model_7/positional_embedding_7/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("model_7/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("model_7/transformer_decoder_3/Shape:0", shape=(2,), dtype=int32)
Tensor("model_7/transformer_decoder_3/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("model_7/transformer_decoder_3/range_1:0", shape=(None,), dtype=int32)
Tensor("model_7/transformer_decoder_3/Cast:0", shape=(None, None), dtype=float64)
Tensor("model_7/transformer_decoder_3/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("model_7/transformer_decoder_3/concat:0", shape=(3,), dtype=int32)
Tensor("model_7/positional_embedding_7/NotEqual:0", shape=(None, 200), dtype=bool)
Decoder Inputs:
Tensor("model_7/transformer_decoder_3/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_7/transformer_decoder_3/multi_head_attention_10/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_7/transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)er_inputs', description="created by layer 'decoder_inputs'")405 - cosine_proximity: 0.1555 - val_loss: 1.1878 - val_mean_squared_error: 1.1878 - val_mean_absolute_error: 0.8795 - val_mean_absolute_percentage_error: 153.8959 - val_cosine_proximity: 0.2306
Decoder encoder_outputs
Tensor("model_7/transformer_decoder_3/strided_slice_7:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("model_7/transformer_decoder_3/layer_normalization_19/add:0", shape=(None, 1, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_6 (Positio (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_3 (Transfor (None, 1, 200)       2107248     positional_embedding_6[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 200)          0           transformer_encoder_3[0][0]
__________________________________________________________________________________________________
model_7 (Functional)            (None, 200)          3392648     decoder_inputs[0][0]
                                                                 flatten_6[0][0]
==================================================================================================
Total params: 5,499,896
Trainable params: 5,499,896
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_6/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_3/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_3/layer_normalization_15/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_3/sequential_6/dense_13/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_3/layer_normalization_16/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_7/positional_embedding_7/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_7/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_7/transformer_decoder_3/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/concat:0", shape=(3,), dtype=int32)
Tensor("transformer/model_7/positional_embedding_7/NotEqual:0", shape=(None, 200), dtype=bool)
Decoder Inputs:
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_7/transformer_decoder_3/multi_head_attention_10/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_7:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_19/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_6/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_3/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_3/layer_normalization_15/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_3/sequential_6/dense_13/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_3/layer_normalization_16/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_7/positional_embedding_7/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_7/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_7/transformer_decoder_3/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/concat:0", shape=(3,), dtype=int32)
Tensor("transformer/model_7/positional_embedding_7/NotEqual:0", shape=(None, 200), dtype=bool)
Decoder Inputs:
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_7/transformer_decoder_3/multi_head_attention_10/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_7:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_19/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - ETA: 0s - loss: 2.3866 - mean_squared_error: 2.3866 - mean_absolute_error: 1.1732 - mean_absolute_percentage_error: 179.5798 - cosine_proximity: 0.0716
Positional Embedding Return Value
Tensor("transformer/positional_embedding_6/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_3/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_3/layer_normalization_15/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_3/sequential_6/dense_13/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_3/layer_normalization_16/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_7/positional_embedding_7/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_7/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_7/transformer_decoder_3/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/concat:0", shape=(3,), dtype=int32)
Tensor("transformer/model_7/positional_embedding_7/NotEqual:0", shape=(None, 200), dtype=bool)
Decoder Inputs:
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_7/transformer_decoder_3/multi_head_attention_10/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_7:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_19/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - 4s 150ms/step - loss: 2.3788 - mean_squared_error: 2.3788 - mean_absolute_error: 1.1707 - mean_absolute_percentage_error: 179.4593 - cosine_proximity: 0.0748 - val_loss: 1.2189 - val_mean_squared_error: 1.2189 - val_mean_absolute_error: 0.8798 - val_mean_absolute_percentage_error: 152.8657 - val_cosine_proximity: 0.2176
Epoch 2/40
9/9 [==============================] - 0s 47ms/step - loss: 2.1821 - mean_squared_error: 2.1821 - mean_absolute_error: 1.1468 - mean_absolute_percentage_error: 184.4867 - cosine_proximity: 0.1566 - val_loss: 1.1705 - val_mean_squared_error: 1.1705 - val_mean_absolute_error: 0.8724 - val_mean_absolute_percentage_error: 154.1528 - val_cosine_proximity: 0.2416
Epoch 3/40
9/9 [==============================] - 1s 63ms/step - loss: 2.1157 - mean_squared_error: 2.1157 - mean_absolute_error: 1.1407 - mean_absolute_percentage_error: 184.1598 - cosine_proximity: 0.1739 - val_loss: 1.1350 - val_mean_squared_error: 1.1350 - val_mean_absolute_error: 0.8568 - val_mean_absolute_percentage_error: 153.5617 - val_cosine_proximity: 0.2575
Epoch 4/40
9/9 [==============================] - 1s 64ms/step - loss: 2.0785 - mean_squared_error: 2.0785 - mean_absolute_error: 1.1336 - mean_absolute_percentage_error: 184.0302 - cosine_proximity: 0.1862 - val_loss: 1.1111 - val_mean_squared_error: 1.1111 - val_mean_absolute_error: 0.8502 - val_mean_absolute_percentage_error: 152.5378 - val_cosine_proximity: 0.2652
Epoch 5/40
9/9 [==============================] - 1s 61ms/step - loss: 2.0316 - mean_squared_error: 2.0316 - mean_absolute_error: 1.1258 - mean_absolute_percentage_error: 182.7759 - cosine_proximity: 0.1861 - val_loss: 1.0952 - val_mean_squared_error: 1.0952 - val_mean_absolute_error: 0.8447 - val_mean_absolute_percentage_error: 150.7846 - val_cosine_proximity: 0.2671
Epoch 6/40
9/9 [==============================] - 1s 70ms/step - loss: 1.9935 - mean_squared_error: 1.9935 - mean_absolute_error: 1.1213 - mean_absolute_percentage_error: 181.2729 - cosine_proximity: 0.1910 - val_loss: 1.0638 - val_mean_squared_error: 1.0638 - val_mean_absolute_error: 0.8334 - val_mean_absolute_percentage_error: 150.2843 - val_cosine_proximity: 0.2817
Epoch 7/40
9/9 [==============================] - 1s 59ms/step - loss: 1.9614 - mean_squared_error: 1.9614 - mean_absolute_error: 1.1165 - mean_absolute_percentage_error: 181.3244 - cosine_proximity: 0.1972 - val_loss: 1.0429 - val_mean_squared_error: 1.0429 - val_mean_absolute_error: 0.8230 - val_mean_absolute_percentage_error: 148.5882 - val_cosine_proximity: 0.2877
Epoch 8/40
9/9 [==============================] - 1s 64ms/step - loss: 1.9105 - mean_squared_error: 1.9105 - mean_absolute_error: 1.1031 - mean_absolute_percentage_error: 178.8975 - cosine_proximity: 0.2068 - val_loss: 1.0218 - val_mean_squared_error: 1.0218 - val_mean_absolute_error: 0.8154 - val_mean_absolute_percentage_error: 147.0765 - val_cosine_proximity: 0.2937
Epoch 9/40
9/9 [==============================] - 1s 63ms/step - loss: 1.8733 - mean_squared_error: 1.8733 - mean_absolute_error: 1.0937 - mean_absolute_percentage_error: 176.9880 - cosine_proximity: 0.2126 - val_loss: 1.0000 - val_mean_squared_error: 1.0000 - val_mean_absolute_error: 0.8065 - val_mean_absolute_percentage_error: 145.5891 - val_cosine_proximity: 0.3006
Epoch 10/40
9/9 [==============================] - 1s 56ms/step - loss: 1.8355 - mean_squared_error: 1.8355 - mean_absolute_error: 1.0836 - mean_absolute_percentage_error: 175.3313 - cosine_proximity: 0.2136 - val_loss: 0.9808 - val_mean_squared_error: 0.9808 - val_mean_absolute_error: 0.7985 - val_mean_absolute_percentage_error: 143.8191 - val_cosine_proximity: 0.3051
Epoch 11/40
9/9 [==============================] - 1s 70ms/step - loss: 1.8258 - mean_squared_error: 1.8258 - mean_absolute_error: 1.0797 - mean_absolute_percentage_error: 174.9568 - cosine_proximity: 0.2109 - val_loss: 0.9614 - val_mean_squared_error: 0.9614 - val_mean_absolute_error: 0.7980 - val_mean_absolute_percentage_error: 142.8443 - val_cosine_proximity: 0.3096
Epoch 12/40
9/9 [==============================] - 0s 52ms/step - loss: 1.7741 - mean_squared_error: 1.7741 - mean_absolute_error: 1.0675 - mean_absolute_percentage_error: 172.1610 - cosine_proximity: 0.2242 - val_loss: 0.9397 - val_mean_squared_error: 0.9397 - val_mean_absolute_error: 0.7857 - val_mean_absolute_percentage_error: 140.9870 - val_cosine_proximity: 0.3169
Epoch 13/40
9/9 [==============================] - 0s 54ms/step - loss: 1.7230 - mean_squared_error: 1.7230 - mean_absolute_error: 1.0448 - mean_absolute_percentage_error: 168.6531 - cosine_proximity: 0.2266 - val_loss: 0.9204 - val_mean_squared_error: 0.9204 - val_mean_absolute_error: 0.7792 - val_mean_absolute_percentage_error: 139.1785 - val_cosine_proximity: 0.3207
Epoch 14/40
9/9 [==============================] - 1s 69ms/step - loss: 1.6899 - mean_squared_error: 1.6899 - mean_absolute_error: 1.0284 - mean_absolute_percentage_error: 165.7671 - cosine_proximity: 0.2288 - val_loss: 0.9047 - val_mean_squared_error: 0.9047 - val_mean_absolute_error: 0.7767 - val_mean_absolute_percentage_error: 137.3586 - val_cosine_proximity: 0.3208
Epoch 15/40
9/9 [==============================] - 0s 53ms/step - loss: 1.6442 - mean_squared_error: 1.6442 - mean_absolute_error: 1.0116 - mean_absolute_percentage_error: 162.4960 - cosine_proximity: 0.2316 - val_loss: 0.8874 - val_mean_squared_error: 0.8874 - val_mean_absolute_error: 0.7697 - val_mean_absolute_percentage_error: 135.1713 - val_cosine_proximity: 0.3225
Epoch 16/40
9/9 [==============================] - 1s 68ms/step - loss: 1.6129 - mean_squared_error: 1.6129 - mean_absolute_error: 0.9895 - mean_absolute_percentage_error: 158.7672 - cosine_proximity: 0.2306 - val_loss: 0.8647 - val_mean_squared_error: 0.8647 - val_mean_absolute_error: 0.7625 - val_mean_absolute_percentage_error: 133.3570 - val_cosine_proximity: 0.3287
Epoch 17/40
9/9 [==============================] - 0s 52ms/step - loss: 1.5785 - mean_squared_error: 1.5785 - mean_absolute_error: 0.9646 - mean_absolute_percentage_error: 155.2316 - cosine_proximity: 0.2335 - val_loss: 0.8495 - val_mean_squared_error: 0.8495 - val_mean_absolute_error: 0.7528 - val_mean_absolute_percentage_error: 129.9694 - val_cosine_proximity: 0.3249
Epoch 18/40
9/9 [==============================] - 1s 57ms/step - loss: 1.5264 - mean_squared_error: 1.5264 - mean_absolute_error: 0.9288 - mean_absolute_percentage_error: 148.4973 - cosine_proximity: 0.2259 - val_loss: 0.8336 - val_mean_squared_error: 0.8336 - val_mean_absolute_error: 0.7442 - val_mean_absolute_percentage_error: 126.3762 - val_cosine_proximity: 0.3198
Epoch 19/40
9/9 [==============================] - 1s 67ms/step - loss: 1.4874 - mean_squared_error: 1.4874 - mean_absolute_error: 0.8950 - mean_absolute_percentage_error: 142.9025 - cosine_proximity: 0.2256 - val_loss: 0.8152 - val_mean_squared_error: 0.8152 - val_mean_absolute_error: 0.7340 - val_mean_absolute_percentage_error: 123.6838 - val_cosine_proximity: 0.3216
Epoch 20/40
9/9 [==============================] - 0s 55ms/step - loss: 1.4363 - mean_squared_error: 1.4363 - mean_absolute_error: 0.8630 - mean_absolute_percentage_error: 137.2610 - cosine_proximity: 0.2312 - val_loss: 0.7950 - val_mean_squared_error: 0.7950 - val_mean_absolute_error: 0.7219 - val_mean_absolute_percentage_error: 119.9767 - val_cosine_proximity: 0.3188
Epoch 21/40
9/9 [==============================] - 0s 52ms/step - loss: 1.3840 - mean_squared_error: 1.3840 - mean_absolute_error: 0.8245 - mean_absolute_percentage_error: 130.7735 - cosine_proximity: 0.2276 - val_loss: 0.7711 - val_mean_squared_error: 0.7711 - val_mean_absolute_error: 0.7106 - val_mean_absolute_percentage_error: 117.1194 - val_cosine_proximity: 0.3227
Epoch 22/40
9/9 [==============================] - 0s 53ms/step - loss: 1.3244 - mean_squared_error: 1.3244 - mean_absolute_error: 0.7958 - mean_absolute_percentage_error: 125.7092 - cosine_proximity: 0.2325 - val_loss: 0.7511 - val_mean_squared_error: 0.7511 - val_mean_absolute_error: 0.6980 - val_mean_absolute_percentage_error: 113.3037 - val_cosine_proximity: 0.3205
Epoch 23/40
9/9 [==============================] - 0s 49ms/step - loss: 1.2533 - mean_squared_error: 1.2533 - mean_absolute_error: 0.7642 - mean_absolute_percentage_error: 120.0533 - cosine_proximity: 0.2376 - val_loss: 0.7399 - val_mean_squared_error: 0.7399 - val_mean_absolute_error: 0.6826 - val_mean_absolute_percentage_error: 108.1786 - val_cosine_proximity: 0.3093
Epoch 24/40
9/9 [==============================] - 0s 48ms/step - loss: 1.1950 - mean_squared_error: 1.1950 - mean_absolute_error: 0.7251 - mean_absolute_percentage_error: 112.1905 - cosine_proximity: 0.2308 - val_loss: 0.7206 - val_mean_squared_error: 0.7206 - val_mean_absolute_error: 0.6737 - val_mean_absolute_percentage_error: 103.7390 - val_cosine_proximity: 0.3010
Epoch 25/40
9/9 [==============================] - 0s 48ms/step - loss: 1.1757 - mean_squared_error: 1.1757 - mean_absolute_error: 0.7024 - mean_absolute_percentage_error: 106.7396 - cosine_proximity: 0.2267 - val_loss: 0.6953 - val_mean_squared_error: 0.6953 - val_mean_absolute_error: 0.6599 - val_mean_absolute_percentage_error: 100.8641 - val_cosine_proximity: 0.3076
Epoch 26/40
9/9 [==============================] - 0s 48ms/step - loss: 1.1223 - mean_squared_error: 1.1223 - mean_absolute_error: 0.6855 - mean_absolute_percentage_error: 104.4578 - cosine_proximity: 0.2366 - val_loss: 0.6636 - val_mean_squared_error: 0.6636 - val_mean_absolute_error: 0.6475 - val_mean_absolute_percentage_error: 99.8292 - val_cosine_proximity: 0.3283
Epoch 27/40
9/9 [==============================] - 0s 57ms/step - loss: 1.0731 - mean_squared_error: 1.0731 - mean_absolute_error: 0.6702 - mean_absolute_percentage_error: 102.5587 - cosine_proximity: 0.2545 - val_loss: 0.6463 - val_mean_squared_error: 0.6463 - val_mean_absolute_error: 0.6341 - val_mean_absolute_percentage_error: 95.4508 - val_cosine_proximity: 0.3234
Epoch 28/40
9/9 [==============================] - 1s 68ms/step - loss: 0.9817 - mean_squared_error: 0.9817 - mean_absolute_error: 0.6418 - mean_absolute_percentage_error: 95.4703 - cosine_proximity: 0.2659 - val_loss: 0.6255 - val_mean_squared_error: 0.6255 - val_mean_absolute_error: 0.6198 - val_mean_absolute_percentage_error: 91.2339 - val_cosine_proximity: 0.3233
Epoch 29/40
9/9 [==============================] - 0s 57ms/step - loss: 0.9577 - mean_squared_error: 0.9577 - mean_absolute_error: 0.6268 - mean_absolute_percentage_error: 93.0048 - cosine_proximity: 0.2843 - val_loss: 0.5952 - val_mean_squared_error: 0.5952 - val_mean_absolute_error: 0.6065 - val_mean_absolute_percentage_error: 89.9057 - val_cosine_proximity: 0.3435
Epoch 30/40
9/9 [==============================] - 1s 57ms/step - loss: 0.9128 - mean_squared_error: 0.9128 - mean_absolute_error: 0.6100 - mean_absolute_percentage_error: 90.3374 - cosine_proximity: 0.3112 - val_loss: 0.5807 - val_mean_squared_error: 0.5807 - val_mean_absolute_error: 0.5957 - val_mean_absolute_percentage_error: 86.1487 - val_cosine_proximity: 0.3392
Epoch 31/40
9/9 [==============================] - 0s 52ms/step - loss: 0.8779 - mean_squared_error: 0.8779 - mean_absolute_error: 0.5962 - mean_absolute_percentage_error: 86.5750 - cosine_proximity: 0.3400 - val_loss: 0.5601 - val_mean_squared_error: 0.5601 - val_mean_absolute_error: 0.5924 - val_mean_absolute_percentage_error: 84.9058 - val_cosine_proximity: 0.3501
Epoch 32/40
9/9 [==============================] - 0s 52ms/step - loss: 0.7970 - mean_squared_error: 0.7970 - mean_absolute_error: 0.5864 - mean_absolute_percentage_error: 84.5772 - cosine_proximity: 0.3862 - val_loss: 0.5391 - val_mean_squared_error: 0.5391 - val_mean_absolute_error: 0.5893 - val_mean_absolute_percentage_error: 84.1902 - val_cosine_proximity: 0.3637
Epoch 33/40
9/9 [==============================] - 1s 69ms/step - loss: 0.8040 - mean_squared_error: 0.8040 - mean_absolute_error: 0.5886 - mean_absolute_percentage_error: 85.0550 - cosine_proximity: 0.3824 - val_loss: 0.5226 - val_mean_squared_error: 0.5226 - val_mean_absolute_error: 0.5915 - val_mean_absolute_percentage_error: 84.8192 - val_cosine_proximity: 0.3775
Epoch 34/40
9/9 [==============================] - 1s 56ms/step - loss: 0.7163 - mean_squared_error: 0.7163 - mean_absolute_error: 0.5779 - mean_absolute_percentage_error: 83.4973 - cosine_proximity: 0.4279 - val_loss: 0.4922 - val_mean_squared_error: 0.4922 - val_mean_absolute_error: 0.5783 - val_mean_absolute_percentage_error: 82.9914 - val_cosine_proximity: 0.4082
Epoch 35/40
9/9 [==============================] - 1s 65ms/step - loss: 0.6818 - mean_squared_error: 0.6818 - mean_absolute_error: 0.5691 - mean_absolute_percentage_error: 82.3095 - cosine_proximity: 0.4411 - val_loss: 0.4730 - val_mean_squared_error: 0.4730 - val_mean_absolute_error: 0.5697 - val_mean_absolute_percentage_error: 81.5497 - val_cosine_proximity: 0.4298
Epoch 36/40
9/9 [==============================] - 1s 58ms/step - loss: 0.6807 - mean_squared_error: 0.6807 - mean_absolute_error: 0.5643 - mean_absolute_percentage_error: 81.6493 - cosine_proximity: 0.4319 - val_loss: 0.4550 - val_mean_squared_error: 0.4550 - val_mean_absolute_error: 0.5660 - val_mean_absolute_percentage_error: 81.3159 - val_cosine_proximity: 0.4511
Epoch 37/40
9/9 [==============================] - 1s 64ms/step - loss: 0.6622 - mean_squared_error: 0.6622 - mean_absolute_error: 0.5618 - mean_absolute_percentage_error: 81.4481 - cosine_proximity: 0.4359 - val_loss: 0.4347 - val_mean_squared_error: 0.4347 - val_mean_absolute_error: 0.5550 - val_mean_absolute_percentage_error: 79.5624 - val_cosine_proximity: 0.4783
Epoch 38/40
9/9 [==============================] - 1s 60ms/step - loss: 0.6104 - mean_squared_error: 0.6104 - mean_absolute_error: 0.5481 - mean_absolute_percentage_error: 79.1042 - cosine_proximity: 0.4652 - val_loss: 0.4184 - val_mean_squared_error: 0.4184 - val_mean_absolute_error: 0.5451 - val_mean_absolute_percentage_error: 77.8524 - val_cosine_proximity: 0.5013
Epoch 39/40
9/9 [==============================] - 1s 69ms/step - loss: 0.6101 - mean_squared_error: 0.6101 - mean_absolute_error: 0.5420 - mean_absolute_percentage_error: 78.0275 - cosine_proximity: 0.4555 - val_loss: 0.4053 - val_mean_squared_error: 0.4053 - val_mean_absolute_error: 0.5400 - val_mean_absolute_percentage_error: 76.8993 - val_cosine_proximity: 0.5203
Epoch 40/40
9/9 [==============================] - 1s 62ms/step - loss: 0.5520 - mean_squared_error: 0.5520 - mean_absolute_error: 0.5314 - mean_absolute_percentage_error: 76.3561 - cosine_proximity: 0.4954 - val_loss: 0.3920 - val_mean_squared_error: 0.3920 - val_mean_absolute_error: 0.5376 - val_mean_absolute_percentage_error: 77.0261 - val_cosine_proximity: 0.5413
Positional Embedding Return Value
Tensor("transformer/positional_embedding_6/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_3/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_3/layer_normalization_15/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_3/sequential_6/dense_13/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_3/layer_normalization_16/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_7/positional_embedding_7/add:0", shape=(None, 200), dtype=float64)
causal mask
Tensor("transformer/model_7/Cast_1:0", shape=(None, 200), dtype=float32)
Tensor("transformer/model_7/transformer_decoder_3/Shape:0", shape=(2,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_2:0", shape=(None, 1), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/range_1:0", shape=(None,), dtype=int32)
Tensor("transformer/model_7/transformer_decoder_3/Cast:0", shape=(None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/Reshape:0", shape=(1, None, None), dtype=float64)
Tensor("transformer/model_7/transformer_decoder_3/concat:0", shape=(3,), dtype=int32)
Tensor("transformer/model_7/positional_embedding_7/NotEqual:0", shape=(None, 200), dtype=bool)
Decoder Inputs:
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_6:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_7/transformer_decoder_3/multi_head_attention_10/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_17/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_7/transformer_decoder_3/strided_slice_7:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_7/transformer_decoder_3/layer_normalization_19/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_8/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_8/add_1:0', description="created by layer 'positional_embedding_8'")
Encoder reshaped inputs
Tensor("transformer_encoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_4/layer_normalization_20/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_4/sequential_8/dense_17/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_4/layer_normalization_21/add:0", shape=(None, 1, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_8/Reshape:0', description="created by layer 'flatten_8'")
Positional Embedding Return Value
Tensor("positional_embedding_9/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_9/add_1:0', description="created by layer 'positional_embedding_9'")
Decoder Inputs:
Tensor("transformer_decoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_4/multi_head_attention_13/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_4/layer_normalization_22/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_4/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_4/layer_normalization_24/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_9/Reshape:0', description="created by layer 'flatten_9'")
Positional Embedding Return Value
Tensor("model_9/positional_embedding_9/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_9/transformer_decoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_9/transformer_decoder_4/multi_head_attention_13/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_9/transformer_decoder_4/layer_normalization_22/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("model_9/transformer_decoder_4/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("model_9/transformer_decoder_4/layer_normalization_24/add:0", shape=(None, 1, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_8 (Positio (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_4 (Transfor (None, 1, 200)       2107248     positional_embedding_8[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 200)          0           transformer_encoder_4[0][0]
__________________________________________________________________________________________________
model_9 (Functional)            (None, 200)          3392648     decoder_inputs[0][0]
                                                                 flatten_8[0][0]
==================================================================================================
Total params: 5,499,896
Trainable params: 5,499,896
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_8/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_4/layer_normalization_20/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_4/sequential_8/dense_17/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_4/layer_normalization_21/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_9/positional_embedding_9/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_9/transformer_decoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_9/transformer_decoder_4/multi_head_attention_13/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_22/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_9/transformer_decoder_4/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_24/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_8/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_4/layer_normalization_20/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_4/sequential_8/dense_17/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_4/layer_normalization_21/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_9/positional_embedding_9/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_9/transformer_decoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_9/transformer_decoder_4/multi_head_attention_13/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_22/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_9/transformer_decoder_4/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_24/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - ETA: 0s - loss: 2.3874 - mean_squared_error: 2.3874 - mean_absolute_error: 1.1587 - mean_absolute_percentage_error: 177.3730 - cosine_proximity: 0.0732
Positional Embedding Return Value
Tensor("transformer/positional_embedding_8/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_4/layer_normalization_20/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_4/sequential_8/dense_17/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_4/layer_normalization_21/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_9/positional_embedding_9/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_9/transformer_decoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_9/transformer_decoder_4/multi_head_attention_13/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_22/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_9/transformer_decoder_4/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_24/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - 3s 142ms/step - loss: 2.3795 - mean_squared_error: 2.3795 - mean_absolute_error: 1.1573 - mean_absolute_percentage_error: 177.4836 - cosine_proximity: 0.0766 - val_loss: 1.2096 - val_mean_squared_error: 1.2096 - val_mean_absolute_error: 0.8928 - val_mean_absolute_percentage_error: 154.8962 - val_cosine_proximity: 0.2238
Epoch 2/40
9/9 [==============================] - 1s 68ms/step - loss: 2.1684 - mean_squared_error: 2.1684 - mean_absolute_error: 1.1505 - mean_absolute_percentage_error: 184.8847 - cosine_proximity: 0.1662 - val_loss: 1.1767 - val_mean_squared_error: 1.1767 - val_mean_absolute_error: 0.8830 - val_mean_absolute_percentage_error: 154.6091 - val_cosine_proximity: 0.2373
Epoch 3/40
9/9 [==============================] - 1s 70ms/step - loss: 2.1033 - mean_squared_error: 2.1033 - mean_absolute_error: 1.1357 - mean_absolute_percentage_error: 182.3529 - cosine_proximity: 0.1751 - val_loss: 1.1496 - val_mean_squared_error: 1.1496 - val_mean_absolute_error: 0.8626 - val_mean_absolute_percentage_error: 152.5097 - val_cosine_proximity: 0.2466
Epoch 4/40
9/9 [==============================] - 1s 61ms/step - loss: 2.0714 - mean_squared_error: 2.0714 - mean_absolute_error: 1.1233 - mean_absolute_percentage_error: 181.5597 - cosine_proximity: 0.1822 - val_loss: 1.1100 - val_mean_squared_error: 1.1100 - val_mean_absolute_error: 0.8466 - val_mean_absolute_percentage_error: 152.2370 - val_cosine_proximity: 0.2660
Epoch 5/40
9/9 [==============================] - 1s 57ms/step - loss: 2.0149 - mean_squared_error: 2.0149 - mean_absolute_error: 1.1226 - mean_absolute_percentage_error: 181.9255 - cosine_proximity: 0.1924 - val_loss: 1.0867 - val_mean_squared_error: 1.0867 - val_mean_absolute_error: 0.8437 - val_mean_absolute_percentage_error: 151.6340 - val_cosine_proximity: 0.2740
Epoch 6/40
9/9 [==============================] - 1s 66ms/step - loss: 1.9902 - mean_squared_error: 1.9902 - mean_absolute_error: 1.1281 - mean_absolute_percentage_error: 182.6922 - cosine_proximity: 0.1987 - val_loss: 1.0748 - val_mean_squared_error: 1.0748 - val_mean_absolute_error: 0.8353 - val_mean_absolute_percentage_error: 149.3507 - val_cosine_proximity: 0.2738
Epoch 7/40
9/9 [==============================] - 0s 50ms/step - loss: 1.9511 - mean_squared_error: 1.9511 - mean_absolute_error: 1.1160 - mean_absolute_percentage_error: 180.2902 - cosine_proximity: 0.2040 - val_loss: 1.0432 - val_mean_squared_error: 1.0432 - val_mean_absolute_error: 0.8227 - val_mean_absolute_percentage_error: 148.5891 - val_cosine_proximity: 0.2881
Epoch 8/40
9/9 [==============================] - 0s 53ms/step - loss: 1.9320 - mean_squared_error: 1.9320 - mean_absolute_error: 1.1172 - mean_absolute_percentage_error: 181.0629 - cosine_proximity: 0.2039 - val_loss: 1.0244 - val_mean_squared_error: 1.0244 - val_mean_absolute_error: 0.8176 - val_mean_absolute_percentage_error: 147.0788 - val_cosine_proximity: 0.2923
Epoch 9/40
9/9 [==============================] - 0s 50ms/step - loss: 1.8996 - mean_squared_error: 1.8996 - mean_absolute_error: 1.1052 - mean_absolute_percentage_error: 178.8133 - cosine_proximity: 0.2068 - val_loss: 1.0027 - val_mean_squared_error: 1.0027 - val_mean_absolute_error: 0.8091 - val_mean_absolute_percentage_error: 145.6810 - val_cosine_proximity: 0.2994
Epoch 10/40
9/9 [==============================] - 0s 55ms/step - loss: 1.8453 - mean_squared_error: 1.8453 - mean_absolute_error: 1.0924 - mean_absolute_percentage_error: 176.6009 - cosine_proximity: 0.2150 - val_loss: 0.9818 - val_mean_squared_error: 0.9818 - val_mean_absolute_error: 0.7998 - val_mean_absolute_percentage_error: 143.9818 - val_cosine_proximity: 0.3053
Epoch 11/40
9/9 [==============================] - 0s 49ms/step - loss: 1.7985 - mean_squared_error: 1.7985 - mean_absolute_error: 1.0709 - mean_absolute_percentage_error: 173.1026 - cosine_proximity: 0.2229 - val_loss: 0.9603 - val_mean_squared_error: 0.9603 - val_mean_absolute_error: 0.7918 - val_mean_absolute_percentage_error: 142.4577 - val_cosine_proximity: 0.3116
Epoch 12/40
9/9 [==============================] - 1s 59ms/step - loss: 1.7738 - mean_squared_error: 1.7738 - mean_absolute_error: 1.0663 - mean_absolute_percentage_error: 172.2866 - cosine_proximity: 0.2204 - val_loss: 0.9442 - val_mean_squared_error: 0.9442 - val_mean_absolute_error: 0.7839 - val_mean_absolute_percentage_error: 140.3565 - val_cosine_proximity: 0.3138
Epoch 13/40
9/9 [==============================] - 0s 48ms/step - loss: 1.7380 - mean_squared_error: 1.7380 - mean_absolute_error: 1.0517 - mean_absolute_percentage_error: 169.4559 - cosine_proximity: 0.2218 - val_loss: 0.9241 - val_mean_squared_error: 0.9241 - val_mean_absolute_error: 0.7788 - val_mean_absolute_percentage_error: 138.8956 - val_cosine_proximity: 0.3186
Epoch 14/40
9/9 [==============================] - 0s 51ms/step - loss: 1.6788 - mean_squared_error: 1.6788 - mean_absolute_error: 1.0250 - mean_absolute_percentage_error: 165.1332 - cosine_proximity: 0.2284 - val_loss: 0.9059 - val_mean_squared_error: 0.9059 - val_mean_absolute_error: 0.7684 - val_mean_absolute_percentage_error: 136.5821 - val_cosine_proximity: 0.3219
Epoch 15/40
9/9 [==============================] - 0s 48ms/step - loss: 1.6435 - mean_squared_error: 1.6435 - mean_absolute_error: 1.0037 - mean_absolute_percentage_error: 161.5218 - cosine_proximity: 0.2301 - val_loss: 0.8892 - val_mean_squared_error: 0.8892 - val_mean_absolute_error: 0.7601 - val_mean_absolute_percentage_error: 133.6558 - val_cosine_proximity: 0.3206
Epoch 16/40
9/9 [==============================] - 0s 48ms/step - loss: 1.5958 - mean_squared_error: 1.5958 - mean_absolute_error: 0.9735 - mean_absolute_percentage_error: 156.3252 - cosine_proximity: 0.2277 - val_loss: 0.8723 - val_mean_squared_error: 0.8723 - val_mean_absolute_error: 0.7477 - val_mean_absolute_percentage_error: 130.0504 - val_cosine_proximity: 0.3181
Epoch 17/40
9/9 [==============================] - 0s 48ms/step - loss: 1.5637 - mean_squared_error: 1.5637 - mean_absolute_error: 0.9413 - mean_absolute_percentage_error: 150.6482 - cosine_proximity: 0.2253 - val_loss: 0.8570 - val_mean_squared_error: 0.8570 - val_mean_absolute_error: 0.7380 - val_mean_absolute_percentage_error: 126.7575 - val_cosine_proximity: 0.3150
Epoch 18/40
9/9 [==============================] - 0s 47ms/step - loss: 1.5360 - mean_squared_error: 1.5360 - mean_absolute_error: 0.9153 - mean_absolute_percentage_error: 145.9605 - cosine_proximity: 0.2234 - val_loss: 0.8501 - val_mean_squared_error: 0.8501 - val_mean_absolute_error: 0.7266 - val_mean_absolute_percentage_error: 121.9472 - val_cosine_proximity: 0.3016
Epoch 19/40
9/9 [==============================] - 0s 47ms/step - loss: 1.4672 - mean_squared_error: 1.4672 - mean_absolute_error: 0.8738 - mean_absolute_percentage_error: 138.1582 - cosine_proximity: 0.2218 - val_loss: 0.8131 - val_mean_squared_error: 0.8131 - val_mean_absolute_error: 0.7146 - val_mean_absolute_percentage_error: 120.2033 - val_cosine_proximity: 0.3154
Epoch 20/40
9/9 [==============================] - 0s 48ms/step - loss: 1.4094 - mean_squared_error: 1.4094 - mean_absolute_error: 0.8309 - mean_absolute_percentage_error: 132.0216 - cosine_proximity: 0.2323 - val_loss: 0.8056 - val_mean_squared_error: 0.8056 - val_mean_absolute_error: 0.7065 - val_mean_absolute_percentage_error: 114.9189 - val_cosine_proximity: 0.2977
Epoch 21/40
9/9 [==============================] - 0s 48ms/step - loss: 1.3868 - mean_squared_error: 1.3868 - mean_absolute_error: 0.7726 - mean_absolute_percentage_error: 120.9312 - cosine_proximity: 0.2106 - val_loss: 0.7999 - val_mean_squared_error: 0.7999 - val_mean_absolute_error: 0.6887 - val_mean_absolute_percentage_error: 107.3681 - val_cosine_proximity: 0.2720
Epoch 22/40
9/9 [==============================] - 0s 48ms/step - loss: 1.3509 - mean_squared_error: 1.3509 - mean_absolute_error: 0.7285 - mean_absolute_percentage_error: 112.1237 - cosine_proximity: 0.2075 - val_loss: 0.7598 - val_mean_squared_error: 0.7598 - val_mean_absolute_error: 0.6680 - val_mean_absolute_percentage_error: 105.2103 - val_cosine_proximity: 0.2937
Epoch 23/40
9/9 [==============================] - 0s 49ms/step - loss: 1.2797 - mean_squared_error: 1.2797 - mean_absolute_error: 0.7142 - mean_absolute_percentage_error: 110.3153 - cosine_proximity: 0.2279 - val_loss: 0.7379 - val_mean_squared_error: 0.7379 - val_mean_absolute_error: 0.6536 - val_mean_absolute_percentage_error: 100.8858 - val_cosine_proximity: 0.2894
Epoch 24/40
9/9 [==============================] - 0s 49ms/step - loss: 1.2263 - mean_squared_error: 1.2263 - mean_absolute_error: 0.6908 - mean_absolute_percentage_error: 105.9434 - cosine_proximity: 0.2330 - val_loss: 0.7043 - val_mean_squared_error: 0.7043 - val_mean_absolute_error: 0.6518 - val_mean_absolute_percentage_error: 101.1484 - val_cosine_proximity: 0.3076
Epoch 25/40
9/9 [==============================] - 0s 48ms/step - loss: 1.1199 - mean_squared_error: 1.1199 - mean_absolute_error: 0.6755 - mean_absolute_percentage_error: 103.3860 - cosine_proximity: 0.2533 - val_loss: 0.6826 - val_mean_squared_error: 0.6826 - val_mean_absolute_error: 0.6372 - val_mean_absolute_percentage_error: 96.6132 - val_cosine_proximity: 0.3017
Epoch 26/40
9/9 [==============================] - 0s 49ms/step - loss: 1.1143 - mean_squared_error: 1.1143 - mean_absolute_error: 0.6481 - mean_absolute_percentage_error: 97.7604 - cosine_proximity: 0.2700 - val_loss: 0.6659 - val_mean_squared_error: 0.6659 - val_mean_absolute_error: 0.6234 - val_mean_absolute_percentage_error: 92.3578 - val_cosine_proximity: 0.2947
Epoch 27/40
9/9 [==============================] - 0s 49ms/step - loss: 1.0287 - mean_squared_error: 1.0287 - mean_absolute_error: 0.6319 - mean_absolute_percentage_error: 93.2537 - cosine_proximity: 0.3030 - val_loss: 0.6592 - val_mean_squared_error: 0.6592 - val_mean_absolute_error: 0.6248 - val_mean_absolute_percentage_error: 89.7779 - val_cosine_proximity: 0.2772
Epoch 28/40
9/9 [==============================] - 0s 50ms/step - loss: 0.9878 - mean_squared_error: 0.9878 - mean_absolute_error: 0.6198 - mean_absolute_percentage_error: 89.8617 - cosine_proximity: 0.3386 - val_loss: 0.6227 - val_mean_squared_error: 0.6227 - val_mean_absolute_error: 0.6086 - val_mean_absolute_percentage_error: 87.4411 - val_cosine_proximity: 0.3016
Epoch 29/40
9/9 [==============================] - 0s 49ms/step - loss: 0.8789 - mean_squared_error: 0.8789 - mean_absolute_error: 0.5985 - mean_absolute_percentage_error: 86.7106 - cosine_proximity: 0.3921 - val_loss: 0.5917 - val_mean_squared_error: 0.5917 - val_mean_absolute_error: 0.6035 - val_mean_absolute_percentage_error: 88.0363 - val_cosine_proximity: 0.3304
Epoch 30/40
9/9 [==============================] - 0s 49ms/step - loss: 0.9019 - mean_squared_error: 0.9019 - mean_absolute_error: 0.6005 - mean_absolute_percentage_error: 87.9545 - cosine_proximity: 0.3728 - val_loss: 0.5649 - val_mean_squared_error: 0.5649 - val_mean_absolute_error: 0.5990 - val_mean_absolute_percentage_error: 88.1851 - val_cosine_proximity: 0.3537
Epoch 31/40
9/9 [==============================] - 0s 47ms/step - loss: 0.8433 - mean_squared_error: 0.8433 - mean_absolute_error: 0.5953 - mean_absolute_percentage_error: 87.8061 - cosine_proximity: 0.3853 - val_loss: 0.5429 - val_mean_squared_error: 0.5429 - val_mean_absolute_error: 0.5878 - val_mean_absolute_percentage_error: 86.0464 - val_cosine_proximity: 0.3710
Epoch 32/40
9/9 [==============================] - 0s 47ms/step - loss: 0.7709 - mean_squared_error: 0.7709 - mean_absolute_error: 0.5805 - mean_absolute_percentage_error: 85.0713 - cosine_proximity: 0.4130 - val_loss: 0.5264 - val_mean_squared_error: 0.5264 - val_mean_absolute_error: 0.5797 - val_mean_absolute_percentage_error: 84.0811 - val_cosine_proximity: 0.3830
Epoch 33/40
9/9 [==============================] - 0s 48ms/step - loss: 0.7747 - mean_squared_error: 0.7747 - mean_absolute_error: 0.5732 - mean_absolute_percentage_error: 83.3853 - cosine_proximity: 0.4106 - val_loss: 0.5088 - val_mean_squared_error: 0.5088 - val_mean_absolute_error: 0.5744 - val_mean_absolute_percentage_error: 83.3128 - val_cosine_proximity: 0.4002
Epoch 34/40
9/9 [==============================] - 0s 48ms/step - loss: 0.7139 - mean_squared_error: 0.7139 - mean_absolute_error: 0.5643 - mean_absolute_percentage_error: 82.1959 - cosine_proximity: 0.4403 - val_loss: 0.4881 - val_mean_squared_error: 0.4881 - val_mean_absolute_error: 0.5697 - val_mean_absolute_percentage_error: 83.1491 - val_cosine_proximity: 0.4223
Epoch 35/40
9/9 [==============================] - 0s 48ms/step - loss: 0.6973 - mean_squared_error: 0.6973 - mean_absolute_error: 0.5630 - mean_absolute_percentage_error: 82.2550 - cosine_proximity: 0.4421 - val_loss: 0.4720 - val_mean_squared_error: 0.4720 - val_mean_absolute_error: 0.5641 - val_mean_absolute_percentage_error: 82.2098 - val_cosine_proximity: 0.4390
Epoch 36/40
9/9 [==============================] - 0s 49ms/step - loss: 0.6725 - mean_squared_error: 0.6725 - mean_absolute_error: 0.5558 - mean_absolute_percentage_error: 80.9887 - cosine_proximity: 0.4502 - val_loss: 0.4601 - val_mean_squared_error: 0.4601 - val_mean_absolute_error: 0.5581 - val_mean_absolute_percentage_error: 80.9147 - val_cosine_proximity: 0.4529
Epoch 37/40
9/9 [==============================] - 0s 47ms/step - loss: 0.6487 - mean_squared_error: 0.6487 - mean_absolute_error: 0.5498 - mean_absolute_percentage_error: 79.9795 - cosine_proximity: 0.4616 - val_loss: 0.4472 - val_mean_squared_error: 0.4472 - val_mean_absolute_error: 0.5519 - val_mean_absolute_percentage_error: 79.3101 - val_cosine_proximity: 0.4657
Epoch 38/40
9/9 [==============================] - 0s 46ms/step - loss: 0.6181 - mean_squared_error: 0.6181 - mean_absolute_error: 0.5401 - mean_absolute_percentage_error: 77.9781 - cosine_proximity: 0.4783 - val_loss: 0.4325 - val_mean_squared_error: 0.4325 - val_mean_absolute_error: 0.5466 - val_mean_absolute_percentage_error: 78.9317 - val_cosine_proximity: 0.4866
Epoch 39/40
9/9 [==============================] - 0s 48ms/step - loss: 0.6327 - mean_squared_error: 0.6327 - mean_absolute_error: 0.5372 - mean_absolute_percentage_error: 77.9582 - cosine_proximity: 0.4587 - val_loss: 0.4214 - val_mean_squared_error: 0.4214 - val_mean_absolute_error: 0.5419 - val_mean_absolute_percentage_error: 78.2079 - val_cosine_proximity: 0.5010
Epoch 40/40
9/9 [==============================] - 0s 48ms/step - loss: 0.6121 - mean_squared_error: 0.6121 - mean_absolute_error: 0.5339 - mean_absolute_percentage_error: 77.3403 - cosine_proximity: 0.4681 - val_loss: 0.4146 - val_mean_squared_error: 0.4146 - val_mean_absolute_error: 0.5320 - val_mean_absolute_percentage_error: 75.6217 - val_cosine_proximity: 0.5101
Positional Embedding Return Value
Tensor("transformer/positional_embedding_8/add:0", shape=(None, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_4/layer_normalization_20/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_4/sequential_8/dense_17/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_4/layer_normalization_21/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_9/positional_embedding_9/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_9/transformer_decoder_4/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_9/transformer_decoder_4/multi_head_attention_13/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_22/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_9/transformer_decoder_4/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_9/transformer_decoder_4/layer_normalization_24/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_10/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_10/add_1:0', description="created by layer 'positional_embedding_10'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_5/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_5/layer_normalization_25/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_5/sequential_10/dense_21/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_5/layer_normalization_26/add:0", shape=(None, 1, 200), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_10/Reshape:0', description="created by layer 'flatten_10'")
Positional Embedding Return Value
Tensor("positional_embedding_11/add:0", shape=(None, 200), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_11/add_1:0', description="created by layer 'positional_embedding_11'")
Decoder Inputs:
Tensor("transformer_decoder_5/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_5/multi_head_attention_16/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_5/layer_normalization_27/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer_decoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_5/layer_normalization_29/add:0", shape=(None, 1, 200), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='flatten_11/Reshape:0', description="created by layer 'flatten_11'")
Positional Embedding Return Value
Tensor("model_11/positional_embedding_11/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("model_11/transformer_decoder_5/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("model_11/transformer_decoder_5/multi_head_attention_16/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("model_11/transformer_decoder_5/layer_normalization_27/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("model_11/transformer_decoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("model_11/transformer_decoder_5/layer_normalization_29/add:0", shape=(None, 1, 200), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_10 (Positi (None, 200)          0           encoder_inputs[0][0]
__________________________________________________________________________________________________
transformer_encoder_5 (Transfor (None, 1, 200)       2107248     positional_embedding_10[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 200)          0           transformer_encoder_5[0][0]
__________________________________________________________________________________________________
model_11 (Functional)           (None, 200)          3392648     decoder_inputs[0][0]
                                                                 flatten_10[0][0]
==================================================================================================
Total params: 5,499,896
Trainable params: 5,499,896
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/40
Positional Embedding Return Value
Tensor("transformer/positional_embedding_10/add:0", shape=(None, 200), dtype=float64)
Tensor("transformer/positional_embedding_10/NotEqual:0", shape=(None, 200), dtype=bool)
Tensor("transformer/transformer_encoder_5/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_5/layer_normalization_25/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_5/sequential_10/dense_21/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_5/layer_normalization_26/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_11/positional_embedding_11/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_11/transformer_decoder_5/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_11/transformer_decoder_5/multi_head_attention_16/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_11/transformer_decoder_5/layer_normalization_27/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_11/transformer_decoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_11/transformer_decoder_5/layer_normalization_29/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_10/add:0", shape=(None, 200), dtype=float64)
Tensor("transformer/positional_embedding_10/NotEqual:0", shape=(None, 200), dtype=bool)
Tensor("transformer/transformer_encoder_5/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_5/layer_normalization_25/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_5/sequential_10/dense_21/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_5/layer_normalization_26/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_11/positional_embedding_11/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_11/transformer_decoder_5/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_11/transformer_decoder_5/multi_head_attention_16/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_11/transformer_decoder_5/layer_normalization_27/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_11/transformer_decoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_11/transformer_decoder_5/layer_normalization_29/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - ETA: 0s - loss: 2.3976 - mean_squared_error: 2.3976 - mean_absolute_error: 1.1582 - mean_absolute_percentage_error: 176.7521 - cosine_proximity: 0.0709
Positional Embedding Return Value
Tensor("transformer/positional_embedding_10/add:0", shape=(None, 200), dtype=float64)
Tensor("transformer/positional_embedding_10/NotEqual:0", shape=(None, 200), dtype=bool)
Tensor("transformer/transformer_encoder_5/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/transformer_encoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_5/layer_normalization_25/add:0", shape=(None, 1, 200), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_5/sequential_10/dense_21/BiasAdd:0", shape=(None, 1, 200), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_5/layer_normalization_26/add:0", shape=(None, 1, 200), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_11/positional_embedding_11/add:0", shape=(None, 200), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_11/transformer_decoder_5/strided_slice:0", shape=(None, 1, 200), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_11/transformer_decoder_5/multi_head_attention_16/attention_output/add:0", shape=(None, 1, 200), dtype=float32)
Decoder out_1
Tensor("transformer/model_11/transformer_decoder_5/layer_normalization_27/add:0", shape=(None, 1, 200), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/model_11/transformer_decoder_5/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Decoder Shape
Tensor("transformer/model_11/transformer_decoder_5/layer_normalization_29/add:0", shape=(None, 1, 200), dtype=float32)
9/9 [==============================] - 3s 144ms/step - loss: 2.3915 - mean_squared_error: 2.3915 - mean_absolute_error: 1.1573 - mean_absolute_percentage_error: 176.8483 - cosine_proximity: 0.0736 - val_loss: 1.2196 - val_mean_squared_error: 1.2196 - val_mean_absolute_error: 0.8813 - val_mean_absolute_percentage_error: 153.6891 - val_cosine_proximity: 0.2166
Epoch 2/40
9/9 [==============================] - 0s 50ms/step - loss: 2.1895 - mean_squared_error: 2.1895 - mean_absolute_error: 1.1520 - mean_absolute_percentage_error: 184.5856 - cosine_proximity: 0.1560 - val_loss: 1.1724 - val_mean_squared_error: 1.1724 - val_mean_absolute_error: 0.8723 - val_mean_absolute_percentage_error: 154.0978 - val_cosine_proximity: 0.2403
Epoch 3/40
9/9 [==============================] - 0s 57ms/step - loss: 2.1343 - mean_squared_error: 2.1343 - mean_absolute_error: 1.1408 - mean_absolute_percentage_error: 184.7617 - cosine_proximity: 0.1744 - val_loss: 1.1376 - val_mean_squared_error: 1.1376 - val_mean_absolute_error: 0.8565 - val_mean_absolute_percentage_error: 153.3017 - val_cosine_proximity: 0.2558
Epoch 4/40
9/9 [==============================] - 1s 65ms/step - loss: 2.0625 - mean_squared_error: 2.0625 - mean_absolute_error: 1.1356 - mean_absolute_percentage_error: 183.8825 - cosine_proximity: 0.1875 - val_loss: 1.1100 - val_mean_squared_error: 1.1100 - val_mean_absolute_error: 0.8463 - val_mean_absolute_percentage_error: 152.0730 - val_cosine_proximity: 0.2659
Epoch 5/40
9/9 [==============================] - 0s 57ms/step - loss: 2.0497 - mean_squared_error: 2.0497 - mean_absolute_error: 1.1349 - mean_absolute_percentage_error: 184.1436 - cosine_proximity: 0.1890 - val_loss: 1.0930 - val_mean_squared_error: 1.0930 - val_mean_absolute_error: 0.8384 - val_mean_absolute_percentage_error: 150.5549 - val_cosine_proximity: 0.2697
Epoch 6/40
9/9 [==============================] - 1s 58ms/step - loss: 1.9967 - mean_squared_error: 1.9967 - mean_absolute_error: 1.1257 - mean_absolute_percentage_error: 182.6755 - cosine_proximity: 0.1995 - val_loss: 1.0624 - val_mean_squared_error: 1.0624 - val_mean_absolute_error: 0.8301 - val_mean_absolute_percentage_error: 150.0727 - val_cosine_proximity: 0.2830
Epoch 7/40
9/9 [==============================] - 0s 53ms/step - loss: 1.9462 - mean_squared_error: 1.9462 - mean_absolute_error: 1.1195 - mean_absolute_percentage_error: 181.6553 - cosine_proximity: 0.1993 - val_loss: 1.0435 - val_mean_squared_error: 1.0435 - val_mean_absolute_error: 0.8257 - val_mean_absolute_percentage_error: 148.6611 - val_cosine_proximity: 0.2874
Epoch 8/40
9/9 [==============================] - 0s 52ms/step - loss: 1.9274 - mean_squared_error: 1.9274 - mean_absolute_error: 1.1127 - mean_absolute_percentage_error: 180.1210 - cosine_proximity: 0.2055 - val_loss: 1.0213 - val_mean_squared_error: 1.0213 - val_mean_absolute_error: 0.8181 - val_mean_absolute_percentage_error: 147.4916 - val_cosine_proximity: 0.2951
Epoch 9/40
9/9 [==============================] - 0s 54ms/step - loss: 1.8806 - mean_squared_error: 1.8806 - mean_absolute_error: 1.0992 - mean_absolute_percentage_error: 177.9769 - cosine_proximity: 0.2134 - val_loss: 1.0031 - val_mean_squared_error: 1.0031 - val_mean_absolute_error: 0.8063 - val_mean_absolute_percentage_error: 145.4762 - val_cosine_proximity: 0.2997
Epoch 10/40
2/9 [=====>........................] - ETA: 0s - loss: 1.8783 - mean_squared_error: 1.8783 - mean_absolute_error: 1.0935 - mean_absolute_percentage_error: 177.0483 - cosine_proximity: 0.2113
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 388, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 114, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 378, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
2/9 [=====>........................] - ETA: 0s - loss: 1.8783 - mean_squared_error: 1.8783 - mean_absolute_error: 1.0935 - mean_absolute_percentage_error: 177.0483 - cosine_proximity: 0.2113Error in callback <function _WandbInit._resume_backend at 0x7f8fd1d1f790> (for pre_run_cell):
Error in callback <function _WandbInit._pause_backend at 0x7f8fd1d1fee0> (for post_run_cell):
Error in callback <function _WandbInit._resume_backend at 0x7f8fd1d1f790> (for pre_run_cell):
Positional Embedding Return Value
Tensor("positional_embedding_12/add:0", shape=(None, 200), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name=None), name='positional_embedding_12/add_1:0', description="created by layer 'positional_embedding_12'")
Tensor("Placeholder_1:0", shape=(None, 200), dtype=bool)
Tensor("transformer_encoder_6/Cast:0", shape=(None, 1, 1, 200), dtype=float64)
Encoder reshaped inputs
Tensor("transformer_encoder_6/strided_slice_1:0", shape=(None, 1, 200), dtype=float32)
Error in callback <function _WandbInit._pause_backend at 0x7f8fd1d1fee0> (for post_run_cell):
Error in callback <function _WandbInit._resume_backend at 0x7f8fd1d1f790> (for pre_run_cell):