Positional Embedding Shape:
(200, 32)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_66/sequential_87/reshape_30/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_66/add:0", shape=(None, 200, 32), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float64, name=None), name='positional_embedding_66/add_1:0', description="created by layer 'positional_embedding_66'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_34/layer_normalization_137/add:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_34/sequential_88/dense_152/BiasAdd:0", shape=(None, 200, 32), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_34/layer_normalization_138/add:0", shape=(None, 200, 32), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float32, name=None), name='transformer_encoder_34/layer_normalization_138/add_1:0', description="created by layer 'transformer_encoder_34'")
Positional Embedding Shape:
(200, 32)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_67/sequential_89/reshape_31/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_67/add:0", shape=(None, 200, 32), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 32), dtype=tf.float64, name=None), name='positional_embedding_67/add_1:0', description="created by layer 'positional_embedding_67'")
Decoder Inputs:
Tensor("Cast:0", shape=(None, 200, 32), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_23/multi_head_attention_81/attention_output/add:0", shape=(None, 200, 32), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_23/layer_normalization_139/add:0", shape=(None, 200, 32), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 32), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_23/layer_normalization_141/add:0", shape=(None, 200, 32), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_156/BiasAdd:0', description="created by layer 'dense_156'")
Positional Embedding dense projection of inputs:
Tensor("model_46/positional_embedding_67/sequential_89/reshape_31/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("model_46/positional_embedding_67/add:0", shape=(None, 200, 32), dtype=float64)
Decoder Inputs:
Tensor("model_46/Cast_1:0", shape=(None, 200, 32), dtype=float32)
Decoder attention_output_1
Tensor("model_46/transformer_decoder_23/multi_head_attention_81/attention_output/add:0", shape=(None, 200, 32), dtype=float32)
Decoder out_1
Tensor("model_46/transformer_decoder_23/layer_normalization_139/add:0", shape=(None, 200, 32), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 32), dtype=float32)
Decoder Shape
Tensor("model_46/transformer_decoder_23/layer_normalization_141/add:0", shape=(None, 200, 32), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_66 (Positi (None, 200, 32)      1286400     encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_34 (Transfo (None, 200, 32)      2279616     positional_embedding_66[0][0]
__________________________________________________________________________________________________
model_46 (Functional)           (None, 200)          2767080     decoder_inputs[0][0]
                                                                 transformer_encoder_34[0][0]
==================================================================================================
Total params: 6,333,096
Trainable params: 6,333,096
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/4
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_66/sequential_87/reshape_30/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_66/add:0", shape=(None, 200, 32), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_34/layer_normalization_137/add:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_34/sequential_88/dense_152/BiasAdd:0", shape=(None, 200, 32), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_34/layer_normalization_138/add:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_46/positional_embedding_67/sequential_89/reshape_31/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_46/positional_embedding_67/add:0", shape=(None, 200, 32), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_46/Cast_1:0", shape=(None, 200, 32), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_46/transformer_decoder_23/multi_head_attention_81/attention_output/add:0", shape=(None, 200, 32), dtype=float32)
Decoder out_1
Tensor("transformer/model_46/transformer_decoder_23/layer_normalization_139/add:0", shape=(None, 200, 32), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_34/layer_normalization_138/add_1:0", shape=(None, 200, 32), dtype=float32)
Decoder Shape
Tensor("transformer/model_46/transformer_decoder_23/layer_normalization_141/add:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_66/sequential_87/reshape_30/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_66/add:0", shape=(None, 200, 32), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_34/layer_normalization_137/add:0", shape=(None, 200, 32), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_34/sequential_88/dense_152/BiasAdd:0", shape=(None, 200, 32), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_34/layer_normalization_138/add:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_46/positional_embedding_67/sequential_89/reshape_31/Reshape:0", shape=(None, 200, 32), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_46/positional_embedding_67/add:0", shape=(None, 200, 32), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_46/Cast_1:0", shape=(None, 200, 32), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_46/transformer_decoder_23/multi_head_attention_81/attention_output/add:0", shape=(None, 200, 32), dtype=float32)
Decoder out_1
Tensor("transformer/model_46/transformer_decoder_23/layer_normalization_139/add:0", shape=(None, 200, 32), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_34/layer_normalization_138/add_1:0", shape=(None, 200, 32), dtype=float32)
Decoder Shape
Tensor("transformer/model_46/transformer_decoder_23/layer_normalization_141/add:0", shape=(None, 200, 32), dtype=float32)

2/9 [=====>........................] - ETA: 55s - loss: 8.2862 - mean_squared_error: 8.2862 - mean_absolute_error: 2.2650 - mean_absolute_percentage_error: 346.1554 - cosine_proximity: 0.0970 Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_68/sequential_91/reshape_32/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_68/add:0", shape=(None, 200, 4), dtype=float64)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float64, name=None), name='positional_embedding_68/add_1:0', description="created by layer 'positional_embedding_68'")
Encoder reshaped inputs
Tensor("Cast:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_35/layer_normalization_142/add:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_35/sequential_92/dense_159/BiasAdd:0", shape=(None, 200, 4), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_35/layer_normalization_143/add:0", shape=(None, 200, 4), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='transformer_encoder_35/layer_normalization_143/add_1:0', description="created by layer 'transformer_encoder_35'")
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_69/sequential_93/reshape_33/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_69/add:0", shape=(None, 200, 4), dtype=float64)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float64, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float64, name=None), name='positional_embedding_69/add_1:0', description="created by layer 'positional_embedding_69'")
Decoder Inputs:
Tensor("Cast:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_24/multi_head_attention_84/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_24/layer_normalization_144/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_24/layer_normalization_146/add:0", shape=(None, 200, 4), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_163/BiasAdd:0', description="created by layer 'dense_163'")
Positional Embedding dense projection of inputs:
Tensor("model_48/positional_embedding_69/sequential_93/reshape_33/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("model_48/positional_embedding_69/add:0", shape=(None, 200, 4), dtype=float64)
Decoder Inputs:
Tensor("model_48/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("model_48/transformer_decoder_24/multi_head_attention_84/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("model_48/transformer_decoder_24/layer_normalization_144/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("model_48/transformer_decoder_24/layer_normalization_146/add:0", shape=(None, 200, 4), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_68 (Positi (None, 200, 4)       160800      encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_35 (Transfo (None, 200, 4)       329752      positional_embedding_68[0][0]
__________________________________________________________________________________________________
model_48 (Functional)           (None, 200)          340684      decoder_inputs[0][0]
                                                                 transformer_encoder_35[0][0]
==================================================================================================
Total params: 831,236
Trainable params: 831,236
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/4
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_68/sequential_91/reshape_32/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_68/add:0", shape=(None, 200, 4), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_35/layer_normalization_142/add:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_35/sequential_92/dense_159/BiasAdd:0", shape=(None, 200, 4), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_35/layer_normalization_143/add:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_48/positional_embedding_69/sequential_93/reshape_33/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_48/positional_embedding_69/add:0", shape=(None, 200, 4), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_48/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_48/transformer_decoder_24/multi_head_attention_84/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("transformer/model_48/transformer_decoder_24/layer_normalization_144/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_35/layer_normalization_143/add_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("transformer/model_48/transformer_decoder_24/layer_normalization_146/add:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_68/sequential_91/reshape_32/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_68/add:0", shape=(None, 200, 4), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_35/layer_normalization_142/add:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_35/sequential_92/dense_159/BiasAdd:0", shape=(None, 200, 4), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_35/layer_normalization_143/add:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_48/positional_embedding_69/sequential_93/reshape_33/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_48/positional_embedding_69/add:0", shape=(None, 200, 4), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_48/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_48/transformer_decoder_24/multi_head_attention_84/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("transformer/model_48/transformer_decoder_24/layer_normalization_144/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_35/layer_normalization_143/add_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("transformer/model_48/transformer_decoder_24/layer_normalization_146/add:0", shape=(None, 200, 4), dtype=float32)







9/9 [==============================] - ETA: 0s - loss: 2.6830 - mean_squared_error: 2.6830 - mean_absolute_error: 1.2839 - mean_absolute_percentage_error: 196.1756 - cosine_proximity: 0.2750 Positional Embedding dense projection of inputs:
Tensor("transformer/positional_embedding_68/sequential_91/reshape_32/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/positional_embedding_68/add:0", shape=(None, 200, 4), dtype=float64)
Encoder reshaped inputs
Tensor("transformer/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_input
Tensor("transformer/transformer_encoder_35/layer_normalization_142/add:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_output
Tensor("transformer/transformer_encoder_35/sequential_92/dense_159/BiasAdd:0", shape=(None, 200, 4), dtype=float32)
Encoder Shape
Tensor("transformer/transformer_encoder_35/layer_normalization_143/add:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding dense projection of inputs:
Tensor("transformer/model_48/positional_embedding_69/sequential_93/reshape_33/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("transformer/model_48/positional_embedding_69/add:0", shape=(None, 200, 4), dtype=float64)
Decoder Inputs:
Tensor("transformer/model_48/Cast_1:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("transformer/model_48/transformer_decoder_24/multi_head_attention_84/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("transformer/model_48/transformer_decoder_24/layer_normalization_144/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("transformer/transformer_encoder_35/layer_normalization_143/add_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("transformer/model_48/transformer_decoder_24/layer_normalization_146/add:0", shape=(None, 200, 4), dtype=float32)
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 388, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 170, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 114, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 378, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/stefan/opt/anaconda3/envs/Body2Eye/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_70/sequential_95/reshape_34/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_71/sequential_96/reshape_35/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
inputs["encoder_inputs"].shape: (48, 200)
inputs["decoder_inputs"].shape: (48, 200)
targets.shape: (48, 200)
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_72/sequential_97/reshape_36/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_73/sequential_98/reshape_37/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_74/sequential_99/reshape_38/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_74/add:0", shape=(None, 200, 4), dtype=float32)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='positional_embedding_74/add_1:0', description="created by layer 'positional_embedding_74'")
Encoder reshaped inputs
Tensor("Placeholder:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_36/layer_normalization_147/add:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_36/sequential_100/dense_170/BiasAdd:0", shape=(None, 200, 4), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_36/layer_normalization_148/add:0", shape=(None, 200, 4), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='transformer_encoder_36/layer_normalization_148/add_1:0', description="created by layer 'transformer_encoder_36'")
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_75/sequential_101/reshape_39/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_75/add:0", shape=(None, 200, 4), dtype=float32)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='positional_embedding_75/add_1:0', description="created by layer 'positional_embedding_75'")
Decoder Inputs:
Tensor("Placeholder:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_25/multi_head_attention_87/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_25/layer_normalization_149/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_25/layer_normalization_151/add:0", shape=(None, 200, 4), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_174/BiasAdd:0', description="created by layer 'dense_174'")
Positional Embedding dense projection of inputs:
Tensor("model_50/positional_embedding_75/sequential_101/reshape_39/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("model_50/positional_embedding_75/add:0", shape=(None, 200, 4), dtype=float32)
Decoder Inputs:
Tensor("model_50/positional_embedding_75/add_1:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("model_50/transformer_decoder_25/multi_head_attention_87/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("model_50/transformer_decoder_25/layer_normalization_149/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("model_50/transformer_decoder_25/layer_normalization_151/add:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_76/sequential_103/reshape_40/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_76/add:0", shape=(None, 200, 4), dtype=float32)
Encoder Inputs:
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='encoder_inputs'), name='encoder_inputs', description="created by layer 'encoder_inputs'")
x_encoder:
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='positional_embedding_76/add_1:0', description="created by layer 'positional_embedding_76'")
Encoder reshaped inputs
Tensor("Placeholder:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_input
Tensor("transformer_encoder_37/layer_normalization_152/add:0", shape=(None, 200, 4), dtype=float32)
Encoder proj_output
Tensor("transformer_encoder_37/sequential_104/dense_177/BiasAdd:0", shape=(None, 200, 4), dtype=float32)
Encoder Shape
Tensor("transformer_encoder_37/layer_normalization_153/add:0", shape=(None, 200, 4), dtype=float32)
encoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='transformer_encoder_37/layer_normalization_153/add_1:0', description="created by layer 'transformer_encoder_37'")
Positional Embedding Shape:
(200, 4)
Positional Embedding dense projection of inputs:
Tensor("positional_embedding_77/sequential_105/reshape_41/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("positional_embedding_77/add:0", shape=(None, 200, 4), dtype=float32)
decoder_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name='decoder_inputs'), name='decoder_inputs', description="created by layer 'decoder_inputs'")
encoded_seq_inputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name='decoder_state_inputs'), name='decoder_state_inputs', description="created by layer 'decoder_state_inputs'")
x_decoder
KerasTensor(type_spec=TensorSpec(shape=(None, 200, 4), dtype=tf.float32, name=None), name='positional_embedding_77/add_1:0', description="created by layer 'positional_embedding_77'")
Decoder Inputs:
Tensor("Placeholder:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("transformer_decoder_26/multi_head_attention_90/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("transformer_decoder_26/layer_normalization_154/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("transformer_decoder_26/layer_normalization_156/add:0", shape=(None, 200, 4), dtype=float32)
Flatten decoder_outputs
KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='dense_181/BiasAdd:0', description="created by layer 'dense_181'")
Positional Embedding dense projection of inputs:
Tensor("model_52/positional_embedding_77/sequential_105/reshape_41/Reshape:0", shape=(None, 200, 4), dtype=float32)
Positional Embedding Return Value
Tensor("model_52/positional_embedding_77/add:0", shape=(None, 200, 4), dtype=float32)
Decoder Inputs:
Tensor("model_52/positional_embedding_77/add_1:0", shape=(None, 200, 4), dtype=float32)
Decoder attention_output_1
Tensor("model_52/transformer_decoder_26/multi_head_attention_90/attention_output/add:0", shape=(None, 200, 4), dtype=float32)
Decoder out_1
Tensor("model_52/transformer_decoder_26/layer_normalization_154/add:0", shape=(None, 200, 4), dtype=float32)
Decoder encoder_outputs
Tensor("Placeholder_1:0", shape=(None, 200, 4), dtype=float32)
Decoder Shape
Tensor("model_52/transformer_decoder_26/layer_normalization_156/add:0", shape=(None, 200, 4), dtype=float32)
Model: "transformer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
encoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
positional_embedding_76 (Positi (None, 200, 4)       160800      encoder_inputs[0][0]
__________________________________________________________________________________________________
decoder_inputs (InputLayer)     [(None, 200)]        0
__________________________________________________________________________________________________
transformer_encoder_37 (Transfo (None, 200, 4)       329752      positional_embedding_76[0][0]
__________________________________________________________________________________________________
model_52 (Functional)           (None, 200)          340684      decoder_inputs[0][0]
                                                                 transformer_encoder_37[0][0]
==================================================================================================
Total params: 831,236
Trainable params: 831,236
Non-trainable params: 0
__________________________________________________________________________________________________