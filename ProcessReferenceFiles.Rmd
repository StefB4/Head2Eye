---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import random
import numpy as np
import matplotlib.pyplot as plt

import pickle
import os
import pandas as pd
import json

import glob
```

```{python}
TIMESTAMP_DECIMALS = 2
RESAMPLE_STRATEGY = "MEAN" # "FILL" 
### MEAN: Resample using pandas' resample, fill holes with linear interpolation
### FILL: Round timestamps to closest 0.01s bucket, drop duplicate timestamps, fill holes with forward fill
```

```{python}
#### Description of the processing 
'''
The reference files are loaded and saved in seperate dataframes in seperate dictionaries. 
The scenedata files are used to extract the event start and stop timestamps. 
The input files contain the car position and rotation data.
Those input files are used to extract path segments that are not events. 
Using the timestamps from the scenedata files, the segments are labeled from 0 to 3;
the datapoints that belong to events are -9. 
The segments are extracted and stored seperately within the input files dictionary. 
The segments timestamps are rebased based on the last event's stop timestamp (or for first segment to 0).

Resampling: 
Since the existing data (without car world coordinates) and the new data need to be synched somehow,
datapoints' timestamps are rounded to 0.01s seconds. 
Additionally, missing holes are filled with linearly interpolated values. 
The 0.01s time delta is also useful as proper timeseries data for the model. 

Convenience Dictionary:
For convenient access of the reference paths.
'''
```

```{python}
def read_normalized_json_to_df(filepath):
    full_file_df = ""
    with open(filepath, 'r', encoding="utf-8") as json_file:
        json_full = json.load(json_file)
    full_file_df = pd.json_normalize(json_full)
    return full_file_df
def save_to_disk(data, filepath):
    with open(filepath, 'wb') as file:
        pickle.dump(data, file)
def load_from_disk(filepath):
    with open(filepath, 'rb') as file:
        data = pickle.load(file)
        return data
```

```{python}
def _read_raw_car_reference_files(reference_data_path):

    # Read post recorded reference data
    print("Total number of reference files: " + str(len(os.listdir(reference_data_path)))) 
    print("Loading reference files...")

    reference_input_files = {}
    reference_eyetracking_files = {}
    reference_scenedata_files = {}
    reference_participant_calibration_file = {}
    reference_participant_calibration_file['filename'] = glob.glob(reference_data_path + "/*ParticipantCalibrationData.txt")[0]
    reference_participant_calibration_file['full_df'] = read_normalized_json_to_df(glob.glob(reference_data_path + "/*ParticipantCalibrationData.txt")[0])
    for filename in glob.glob(reference_data_path + "/*_Input*.txt"):
        if "Westbrueck" in filename:
            token = "Westbrueck"
        elif "MountainRoad" in filename:
            token = "MountainRoad"
        elif "CountryRoad" in filename:
            token = "CountryRoad"
        elif "Autobahn" in filename:
            token = "Autobahn"
        else:  # not defined 
            continue # in the loop 
        reference_input_files[token] = {}
        reference_input_files[token]["filename"] = filename
        reference_input_files[token]["full_df"] = read_normalized_json_to_df(filename)
    for filename in glob.glob(reference_data_path + "/*_EyeTracking*.txt"):
        if "Westbrueck" in filename:
            token = "Westbrueck"
        elif "MountainRoad" in filename:
            token = "MountainRoad"
        elif "CountryRoad" in filename:
            token = "CountryRoad"
        elif "Autobahn" in filename:
            token = "Autobahn"  
        else:  # not defined 
            continue # in the loop     
        reference_eyetracking_files[token] = {}
        reference_eyetracking_files[token]["filename"] = filename
        reference_eyetracking_files[token]["full_df"] = read_normalized_json_to_df(filename)
    for filename in glob.glob(reference_data_path + "/*_SceneData*.txt"): 
        if "Westbrueck" in filename:
            token = "Westbrueck"
        elif "MountainRoad" in filename:
            token = "MountainRoad"
        elif "CountryRoad" in filename:
            token = "CountryRoad"
        elif "Autobahn" in filename:
            token = "Autobahn"     
        else:  # not defined 
            continue # in the loop  
        reference_scenedata_files[token] = {}
        reference_scenedata_files[token]["filename"] = filename
        reference_scenedata_files[token]["full_df"] = read_normalized_json_to_df(filename)

    print("Finished loading reference files.")
    
    return reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file
```

```{python}
def _extract_event_information(reference_data_path):
    
    # load raw files 
    reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file = _read_raw_car_reference_files(reference_data_path)
    
    
    # Extract most important event information 
    for area in ["Westbrueck","MountainRoad","CountryRoad","Autobahn"]:
        reference_scenedata_files[area]["number_of_events"] = len(reference_scenedata_files[area]["full_df"]["EventBehavior"][0])
        reference_scenedata_files[area]["events"] = {}
        for idx, event in enumerate(reference_scenedata_files[area]["full_df"]["EventBehavior"][0]):
            reference_scenedata_files[area]["events"][idx] = {'name':event["EventName"],'start':event["StartofEventTimeStamp"],'stop':event["EndOfEventTimeStamp"]}
                
    return reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file
```

```{python}
def _extract_path_segments(reference_data_path):
    
    # extract event information
    reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file = _extract_event_information(reference_data_path)
    
    
    # Copy of entire dataframe input dataframe to prepare processing
    for area in ["Westbrueck","MountainRoad","CountryRoad","Autobahn"]:
        reference_input_files[area]["processed_df"] = reference_input_files[area]["full_df"].copy(deep=True)
        reference_input_files[area]["processed_df"].drop(columns=["ReceivedInput","SteeringInput","AcellerationInput","BrakeInput"],inplace=True)
        reference_input_files[area]["processed_df"]["path_segment_label"] = -9 # event label 

    # Give label to individual path segments, -9 is event label 
    for area in ["Westbrueck","MountainRoad","CountryRoad","Autobahn"]:
        for event_idx in range(len(reference_scenedata_files[area]["events"]) + 1):
            cond = None 
            if event_idx == 0: # find all datapoints with timestamps before event start timestamp 
                cond = (reference_input_files[area]["processed_df"]["TimeStamp"] < reference_scenedata_files[area]["events"][event_idx]["start"])
            elif event_idx < len(reference_scenedata_files[area]["events"]): # find all datapoints with timestamp between prev and next event 
                cond = (reference_input_files[area]["processed_df"]["TimeStamp"] > reference_scenedata_files[area]["events"][event_idx - 1]["stop"]) & (reference_input_files[area]["processed_df"]["TimeStamp"] < reference_scenedata_files[area]["events"][event_idx]["start"])
            elif event_idx == len(reference_scenedata_files[area]["events"]): # find all datapoints with timestamp after last event
                cond = (reference_input_files[area]["processed_df"]["TimeStamp"] > reference_scenedata_files[area]["events"][event_idx - 1]["stop"])

            # Filter     
            reference_input_files[area]["processed_df"].loc[cond, "path_segment_label"] = event_idx

    # Extract path segments, add timestamps beginning at zero 
    for area in ["Westbrueck","MountainRoad","CountryRoad","Autobahn"]:
        reference_input_files[area]["path_segments_no_resample"] = {}
        for label in reference_input_files[area]["processed_df"]["path_segment_label"].unique():
            if (label != -9):

                # copy segment data 
                cond = (reference_input_files[area]["processed_df"]["path_segment_label"] == label)
                reference_input_files[area]["path_segments_no_resample"][label] = reference_input_files[area]["processed_df"].loc[cond].copy(deep=True)

                # add timestamp starting at zero 
                if label == 0: # take first recorded datapoint as base timestamp 
                    ref_timestamp = reference_input_files[area]["path_segments_no_resample"][label]["TimeStamp"].iloc[0]
                else: # take last event's stop time as base timestamp 
                    ref_timestamp = reference_scenedata_files[area]["events"][label - 1]["stop"]

                reference_input_files[area]["path_segments_no_resample"][label]["rebased_timestamp"] = reference_input_files[area]["path_segments_no_resample"][label]["TimeStamp"] - ref_timestamp

            else: # skip events 
                pass 
    
    return reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file
```

```{python}
# Resample path segments 

def _resample_reference_path_segments(reference_data_path):

    # extract path segments
    reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file = _extract_path_segments(reference_data_path)
    
    print("Resampled path segments (excl. events):")
    for area in ["Westbrueck","MountainRoad","CountryRoad","Autobahn"]:

        reference_input_files[area]["path_segments_resampled"] = {}
        for segment in reference_input_files[area]["path_segments_no_resample"]:
            # copy segments 
            reference_input_files[area]["path_segments_resampled"][segment] = reference_input_files[area]["path_segments_no_resample"][segment].copy(deep=True)

            # Hard match datapoints to closest timebin and fill arising holes by forward fill 
            if RESAMPLE_STRATEGY == "FILL":

                # round the timestamps to specified number of decimals 
                reference_input_files[area]["path_segments_resampled"][segment]["rebased_timestamp_rounded"] = reference_input_files[area]["path_segments_resampled"][segment]["rebased_timestamp"].round(TIMESTAMP_DECIMALS)

                # "resample" timestamps by reindexing with 0.01s steps and filling holes; first drop duplicate timestamps
                reference_input_files[area]["path_segments_resampled"][segment]["resampled_timestamp"] = reference_input_files[area]["path_segments_resampled"][segment]["rebased_timestamp_rounded"] 
                reference_input_files[area]["path_segments_resampled"][segment].drop_duplicates(subset="resampled_timestamp",keep="first", inplace=True)
                start_time = 0
                end_time = reference_input_files[area]["path_segments_resampled"][segment]["resampled_timestamp"].iloc[-1]
                time_delta = 0.01
                new_index = pd.Index(np.arange(start_time,end_time,time_delta), name="resampled_timestamp")
                reference_input_files[area]["path_segments_resampled"][segment] = reference_input_files[area]["path_segments_resampled"][segment].set_index("resampled_timestamp").reindex(new_index).reset_index()

                # keep track of where data was interpolated 
                reference_input_files[area]["path_segments_resampled"][segment]["is_interpolated"] = reference_input_files[area]["path_segments_resampled"][segment]["rebased_timestamp"].isnull()

                # fill nans ("interpolate") 
                exclude_columns = ["rebased_timestamp","rebased_timestamp_rounded","is_interpolated","TimeStamp","resampled_timestamp"]
                for column in reference_input_files[area]["path_segments_resampled"][segment].columns:  
                    if column not in exclude_columns:
                        reference_input_files[area]["path_segments_resampled"][segment][column].fillna(method='ffill', inplace = True)
                        reference_input_files[area]["path_segments_resampled"][segment][column].fillna(method='bfill', inplace = True)

                # drop unneeded columns
                reference_input_files[area]["path_segments_resampled"][segment].drop(columns=["TimeStamp","rebased_timestamp","rebased_timestamp_rounded","path_segment_label"], inplace = True)


            # Resample using pandas' resample, fill with mean 
            if RESAMPLE_STRATEGY == "MEAN":

                # copy timestamp 
                reference_input_files[area]["path_segments_resampled"][segment]["resampled_timestamp"] = reference_input_files[area]["path_segments_resampled"][segment]["rebased_timestamp"] 

                # create datetime from rebased timestamp
                reference_input_files[area]["path_segments_resampled"][segment]["rebased_datetime"] = pd.to_datetime(reference_input_files[area]["path_segments_resampled"][segment]['resampled_timestamp'],unit='s')

                # resample with 0.01s interval and keep track of holes in the data before interpolation
                reference_input_files[area]["path_segments_resampled"][segment] = reference_input_files[area]["path_segments_resampled"][segment].resample('0.01S',on="rebased_datetime").mean()
                reference_input_files[area]["path_segments_resampled"][segment]["is_interpolated"] = reference_input_files[area]["path_segments_resampled"][segment]["resampled_timestamp"].isnull()
                reference_input_files[area]["path_segments_resampled"][segment].reset_index(inplace=True)

                # interpolate linearly
                reference_input_files[area]["path_segments_resampled"][segment].interpolate(method="linear",inplace=True)

                # get resampled_timestamp from rebased_datetime again 
                reference_input_files[area]["path_segments_resampled"][segment]["resampled_timestamp"] = (reference_input_files[area]["path_segments_resampled"][segment]["rebased_datetime"] - pd.Timestamp("1970-01-01")) / pd.Timedelta('1s')

                # drop unneeded columns
                reference_input_files[area]["path_segments_resampled"][segment].drop(columns=["rebased_datetime","TimeStamp","rebased_timestamp","path_segment_label"], inplace = True)


            print("Area: " + area + " Segment: " + str(segment) + " Total datapoints (incl. resampled): " + str(len(reference_input_files[area]["path_segments_resampled"][segment]["is_interpolated"]))  + " Filled NaNs: " + str(reference_input_files[area]["path_segments_resampled"][segment]["is_interpolated"].values.sum()))

            
    
    return reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file
```

```{python}
def generate_reference_paths(reference_data_path):
    
    # get resampled path segments
    reference_input_files, reference_eyetracking_files, reference_scenedata_files, reference_participant_calibration_file = _resample_reference_path_segments(reference_data_path)
    
    reference_paths = {}
    for area in ["Westbrueck","MountainRoad","CountryRoad","Autobahn"]:
        reference_paths[area] = {}
        for segment in reference_input_files[area]["path_segments_resampled"]:
            reference_paths[area][segment] = reference_input_files[area]["path_segments_resampled"][segment].copy(deep = True)
            #reference_paths[area][segment].drop(columns=["path_segment_label","rebased_timestamp","rebased_timestamp_rounded"],inplace=True)

    return reference_paths
```

```{python}
# Generate the reference path cleaned data 
reference_data_path_some_failed_some_succeeded = "./post_recorded_reference_data/Build/Some_Failed_Some_Succeeded"
reference_data_path_all_failed = "./post_recorded_reference_data/Build/All_Failed"
reference_paths_some_events_failed = generate_reference_paths(reference_data_path_some_failed_some_succeeded)
reference_paths_all_events_failed = generate_reference_paths(reference_data_path_all_failed)

```

```{python}
# save generated data to disk 
some_failed_save_path = "./post_recorded_reference_data/reference_some_events_failed.pickle"
all_failed_save_path = "./post_recorded_reference_data/reference_all_events_failed.pickle"
save_to_disk(reference_paths_some_events_failed, some_failed_save_path)
save_to_disk(reference_paths_all_events_failed, all_failed_save_path)
```

```{python}

```

```{python}
print(reference_paths_all_events_failed["Westbrueck"][0].columns)
```

```{python}
fig, axs = plt.subplots(nrows=96, ncols=3, figsize=(20,160))

car_data_names = ["CarPosition.x","CarPosition.y","CarPosition.z","CarRotation.x","CarRotation.y","CarRotation.z"]
areas = ["Westbrueck", "MountainRoad","CountryRoad","Autobahn"]
segments = [0,1,2,3]
ncols = 3

for idx, ax in enumerate(axs.reshape(-1)):
    
        
        car_data_idx = (idx // ncols) % len(car_data_names)
        segments_idx = (idx // (ncols * len(car_data_names)) ) % len(segments)
        area_idx = (idx // (ncols * len(car_data_names) * len(segments))) % len(areas)
        
        if (idx % 3 == 0):
            ax.plot(reference_paths_some_events_failed[areas[area_idx]][segments_idx]["resampled_timestamp"], reference_paths_some_events_failed[areas[area_idx]][segments_idx][car_data_names[car_data_idx]])
            ax.set_title("Some failed; " + car_data_names[car_data_idx] + "; Segment: " + str(segments[segments_idx]) + "; Area: " + areas[area_idx])
        elif (idx % 3 == 1):
            ax.plot(reference_paths_all_events_failed[areas[area_idx]][segments_idx]["resampled_timestamp"], reference_paths_all_events_failed[areas[area_idx]][segments_idx][car_data_names[car_data_idx]])
            ax.set_title("All failed" + car_data_names[car_data_idx] + "; Segment: " + str(segments[segments_idx]) + "; Area: " + areas[area_idx])
        else:
            y = 0 # determine longer column 
            if (len(reference_paths_some_events_failed[areas[area_idx]][segments_idx][car_data_names[car_data_idx]]) > len(reference_paths_all_events_failed[areas[area_idx]][segments_idx][car_data_names[car_data_idx]])):
                x = reference_paths_some_events_failed[areas[area_idx]][segments_idx]["resampled_timestamp"]
            else:
                x = reference_paths_all_events_failed[areas[area_idx]][segments_idx]["resampled_timestamp"]
            ax.plot(x, reference_paths_some_events_failed[areas[area_idx]][segments_idx][car_data_names[car_data_idx]] - reference_paths_all_events_failed[areas[area_idx]][segments_idx][car_data_names[car_data_idx]])
            ax.set_title("Difference" + car_data_names[car_data_idx] + "; Segment: " + str(segments[segments_idx]) + "; Area: " + areas[area_idx])
                
        
fig.tight_layout()
plt.show()



```

```{python}

```
